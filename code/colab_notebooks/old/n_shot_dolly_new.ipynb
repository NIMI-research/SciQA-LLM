{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11r0-FEMO2UG7b2oZd4ySW0LpOjsly0mm","timestamp":1691515342412}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d7fcbf51d09446b08e80e86259d81bda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34eff9a8b464427795b4474ae92b23d0","IPY_MODEL_09e400e47950435787a565aabcd34fa8","IPY_MODEL_3f6c494382664869bc6560072bb25770"],"layout":"IPY_MODEL_958ba0a61bcf4a3aa7c18e0156f6fa55"}},"34eff9a8b464427795b4474ae92b23d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4548b4cbf3bc43c28420ce8cdfd86a54","placeholder":"​","style":"IPY_MODEL_48c8533b7608446997e3aeb910db5428","value":"Downloading (…)okenizer_config.json: 100%"}},"09e400e47950435787a565aabcd34fa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a79b4e8b71ff410c9d4e291c1a5f6159","max":450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c8e0a2fad0e46edae9a31e42b9b7647","value":450}},"3f6c494382664869bc6560072bb25770":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7471e5872b24744aadf5b2b420f971d","placeholder":"​","style":"IPY_MODEL_fb19e2977b694d3d83d28c1e47368dd7","value":" 450/450 [00:00&lt;00:00, 24.6kB/s]"}},"958ba0a61bcf4a3aa7c18e0156f6fa55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4548b4cbf3bc43c28420ce8cdfd86a54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c8533b7608446997e3aeb910db5428":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a79b4e8b71ff410c9d4e291c1a5f6159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c8e0a2fad0e46edae9a31e42b9b7647":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7471e5872b24744aadf5b2b420f971d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb19e2977b694d3d83d28c1e47368dd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d371fb36f1e4406db548b857268f0914":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ddba2893457440e819c3406d2a609cb","IPY_MODEL_e3d59431d6f644f7ad77cdf8c3c2e3c5","IPY_MODEL_f741d1dc701a4ae8a0b51ea69201cecb"],"layout":"IPY_MODEL_1ccb79cbc8684128984da118aa6b1a46"}},"8ddba2893457440e819c3406d2a609cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b324fadd4a3343389c5277b3d86e5d5e","placeholder":"​","style":"IPY_MODEL_24fc77e5dff74f6eb5cfe2d06baba1e0","value":"Downloading (…)/main/tokenizer.json: 100%"}},"e3d59431d6f644f7ad77cdf8c3c2e3c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_910f90c2383248b5988b7d8751841532","max":2114274,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3a9de58258a4aaf8806a4f58be19d76","value":2114274}},"f741d1dc701a4ae8a0b51ea69201cecb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_548279f7e22e4632a8f7f7dbd3283da4","placeholder":"​","style":"IPY_MODEL_776e3c00fb324a699cc99075e01df672","value":" 2.11M/2.11M [00:00&lt;00:00, 6.93MB/s]"}},"1ccb79cbc8684128984da118aa6b1a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b324fadd4a3343389c5277b3d86e5d5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24fc77e5dff74f6eb5cfe2d06baba1e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"910f90c2383248b5988b7d8751841532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a9de58258a4aaf8806a4f58be19d76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"548279f7e22e4632a8f7f7dbd3283da4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"776e3c00fb324a699cc99075e01df672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34e7ad0f1e664212a4b42b120ff8d522":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7173de877b55404aaeed6b9e77b607a0","IPY_MODEL_396dd6b2955a44c8a790da9ecbb9b522","IPY_MODEL_c49033513914478facd0cd2a555d9776"],"layout":"IPY_MODEL_900094fd77c34a27ac8555df5a4eaad8"}},"7173de877b55404aaeed6b9e77b607a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06b4878929a84d5bae28295b213ab7dc","placeholder":"​","style":"IPY_MODEL_7bf62e741e90475ca956216439f1c4d4","value":"Downloading (…)cial_tokens_map.json: 100%"}},"396dd6b2955a44c8a790da9ecbb9b522":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd989454006a431182389e986e5caa63","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf0c6346751d46c0be3a3e2281582bd7","value":228}},"c49033513914478facd0cd2a555d9776":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b06365aae7d2431bb83f82d90d3b99c0","placeholder":"​","style":"IPY_MODEL_f51e65e810834a9db6ff33c64ee9b7e0","value":" 228/228 [00:00&lt;00:00, 14.2kB/s]"}},"900094fd77c34a27ac8555df5a4eaad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06b4878929a84d5bae28295b213ab7dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf62e741e90475ca956216439f1c4d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd989454006a431182389e986e5caa63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0c6346751d46c0be3a3e2281582bd7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b06365aae7d2431bb83f82d90d3b99c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51e65e810834a9db6ff33c64ee9b7e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fe7f809ca7049f7a6d99a97b381eb54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb5714b64adb485e8521dc4b2f085897","IPY_MODEL_33d1845c7e9c41a892552c0336bd1550","IPY_MODEL_2ada513aa4fb46bc9c33b1172433c57e"],"layout":"IPY_MODEL_8fb4ee5e79ee4977a7a03e839cffce1d"}},"eb5714b64adb485e8521dc4b2f085897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a083b806e244b90a8f14fc4622bc623","placeholder":"​","style":"IPY_MODEL_8893ff1e5fa7466bb0cc596abd2d62a7","value":"Downloading (…)lve/main/config.json: 100%"}},"33d1845c7e9c41a892552c0336bd1550":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e2e0cbb702049f3ac0fe5ff31103ff4","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ac8869b15424a38a1eed158c3969439","value":819}},"2ada513aa4fb46bc9c33b1172433c57e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b30677bf96164e519de48b0b8be9b0a3","placeholder":"​","style":"IPY_MODEL_2ec08648d7a8496c986b1c04ecd3ba6d","value":" 819/819 [00:00&lt;00:00, 53.2kB/s]"}},"8fb4ee5e79ee4977a7a03e839cffce1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a083b806e244b90a8f14fc4622bc623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8893ff1e5fa7466bb0cc596abd2d62a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e2e0cbb702049f3ac0fe5ff31103ff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac8869b15424a38a1eed158c3969439":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b30677bf96164e519de48b0b8be9b0a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ec08648d7a8496c986b1c04ecd3ba6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f6f5615e3bd41298e1a46594f8277f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b5679a8ddf54b44b9ffad6ca307d5d9","IPY_MODEL_c021f62acd8a413c962003a74facb90c","IPY_MODEL_ca1b0c48c5df4942aa944b1c21d5ca71"],"layout":"IPY_MODEL_eb669c7c00c24b988f96471dc0067704"}},"1b5679a8ddf54b44b9ffad6ca307d5d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acfb866a9fbf4d68a9155dc460161f98","placeholder":"​","style":"IPY_MODEL_217963aa6f264fdd8b0e03114e861d88","value":"Downloading (…)instruct_pipeline.py: 100%"}},"c021f62acd8a413c962003a74facb90c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aad4b78b44674e73808f1ecf3f1ebe6a","max":9160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34584689b65f4336aa043f18406c9357","value":9160}},"ca1b0c48c5df4942aa944b1c21d5ca71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e2c56acfd3f434390c5f37f12f4dc50","placeholder":"​","style":"IPY_MODEL_6bd5ebdfb0dd4201b3823423b2f50b20","value":" 9.16k/9.16k [00:00&lt;00:00, 443kB/s]"}},"eb669c7c00c24b988f96471dc0067704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acfb866a9fbf4d68a9155dc460161f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"217963aa6f264fdd8b0e03114e861d88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad4b78b44674e73808f1ecf3f1ebe6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34584689b65f4336aa043f18406c9357":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e2c56acfd3f434390c5f37f12f4dc50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bd5ebdfb0dd4201b3823423b2f50b20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ec530ba613455887f5cc81374510ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25284b84e1de4fc1995368af27b35337","IPY_MODEL_959f2e9bf03140faac727099d12cf4f4","IPY_MODEL_8335789b07ba4ab395fbd5c2b230832e"],"layout":"IPY_MODEL_f8e79d5a5f5041089bf9427d341e3b6b"}},"25284b84e1de4fc1995368af27b35337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ae5605fb7248698a25b8487f78d944","placeholder":"​","style":"IPY_MODEL_6b8b7defa57a4702b7f2b44655e21723","value":"Downloading pytorch_model.bin: 100%"}},"959f2e9bf03140faac727099d12cf4f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6aa8ea9b77040d7a8bff1ff501700c6","max":5684548185,"min":0,"orientation":"horizontal","style":"IPY_MODEL_114b4cb7f8fd43608d19869827d5e140","value":5684548185}},"8335789b07ba4ab395fbd5c2b230832e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e588f3f3b1144e79d206c7c4340ca22","placeholder":"​","style":"IPY_MODEL_6472e9e15a80411fb5cbdb65aaae8f09","value":" 5.68G/5.68G [00:32&lt;00:00, 242MB/s]"}},"f8e79d5a5f5041089bf9427d341e3b6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ae5605fb7248698a25b8487f78d944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b8b7defa57a4702b7f2b44655e21723":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6aa8ea9b77040d7a8bff1ff501700c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"114b4cb7f8fd43608d19869827d5e140":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e588f3f3b1144e79d206c7c4340ca22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6472e9e15a80411fb5cbdb65aaae8f09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"113f72e106a9434aa7f2223da018965e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ea38042651c490d9d9d8e949db8396a","IPY_MODEL_4668cd7b9f5a40f4bcb691e2d6f29018","IPY_MODEL_3c5dd9984b1e43958015711df1668429"],"layout":"IPY_MODEL_04ee7f20080a4c7ebf08d5e33b0ff580"}},"6ea38042651c490d9d9d8e949db8396a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9cf38f0804f4b82879fa9b3eabf9f06","placeholder":"​","style":"IPY_MODEL_398c555bb4dd4e4fb1b411856edc27af","value":"Downloading builder script: 100%"}},"4668cd7b9f5a40f4bcb691e2d6f29018":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8aad3c80deb49d0a852fcac1178b577","max":6545,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab425a56d8394202a14faad20138c137","value":6545}},"3c5dd9984b1e43958015711df1668429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50df7cf0de0d4e658df20aa7229cd486","placeholder":"​","style":"IPY_MODEL_d49f74e7f95a47389c3f69040876cb06","value":" 6.54k/6.54k [00:00&lt;00:00, 262kB/s]"}},"04ee7f20080a4c7ebf08d5e33b0ff580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9cf38f0804f4b82879fa9b3eabf9f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"398c555bb4dd4e4fb1b411856edc27af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8aad3c80deb49d0a852fcac1178b577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab425a56d8394202a14faad20138c137":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50df7cf0de0d4e658df20aa7229cd486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d49f74e7f95a47389c3f69040876cb06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47569d409b3045e7834d191a2ce3f7b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e19a607471ae46239f15994a1f8f7a3f","IPY_MODEL_cd94c89bf84941b7bff7a4dbce34bc56","IPY_MODEL_75fb4849bd9a495480fa1387fd108172"],"layout":"IPY_MODEL_ab9518c4c9314d459dccb169e0fb3b90"}},"e19a607471ae46239f15994a1f8f7a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3963095099bd4434a6974115860fa8d9","placeholder":"​","style":"IPY_MODEL_6b906f6108d041f1ae29afb7d84721e9","value":"Downloading readme: 100%"}},"cd94c89bf84941b7bff7a4dbce34bc56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33e97f8383ad44d4af2e0466b6deb18d","max":6081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d416581e17c4ddf8dffc5a77ffa21fd","value":6081}},"75fb4849bd9a495480fa1387fd108172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b4982a377fa4485909af281bd841827","placeholder":"​","style":"IPY_MODEL_3546308977c14ae3b7c4320b96332f99","value":" 6.08k/6.08k [00:00&lt;00:00, 322kB/s]"}},"ab9518c4c9314d459dccb169e0fb3b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963095099bd4434a6974115860fa8d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b906f6108d041f1ae29afb7d84721e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33e97f8383ad44d4af2e0466b6deb18d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d416581e17c4ddf8dffc5a77ffa21fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b4982a377fa4485909af281bd841827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3546308977c14ae3b7c4320b96332f99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5df3283734c34e72b3b0e4139fec5c05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d03ce43e37924e1cbbf110068c430eb4","IPY_MODEL_f68ef0726a024c4fb30ae5038767b49e","IPY_MODEL_906a047a06134687b5a4b5a1f540604d"],"layout":"IPY_MODEL_d987b121549e48259be1a14ca133b209"}},"d03ce43e37924e1cbbf110068c430eb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46409c015e584a628ff079ea9163c568","placeholder":"​","style":"IPY_MODEL_b21e980bfca3471f91bd8894d0e5ceb5","value":"Downloading data: 100%"}},"f68ef0726a024c4fb30ae5038767b49e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f9e7621b3984a3b88c10e35ce1a9d5e","max":553459,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c2aadd693be497d9da535c19676791c","value":553459}},"906a047a06134687b5a4b5a1f540604d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8938bf13c14e2ba12260cd22eb7603","placeholder":"​","style":"IPY_MODEL_52960c227d40455f8053aa8d69015fca","value":" 553k/553k [00:01&lt;00:00, 437kB/s]"}},"d987b121549e48259be1a14ca133b209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46409c015e584a628ff079ea9163c568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b21e980bfca3471f91bd8894d0e5ceb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f9e7621b3984a3b88c10e35ce1a9d5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c2aadd693be497d9da535c19676791c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df8938bf13c14e2ba12260cd22eb7603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52960c227d40455f8053aa8d69015fca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a138dcce92c4363b497a4dc5c951cba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d3c9e8580814ff2be6d9a60b70beee1","IPY_MODEL_1276be8417184eb495ffeaabba21c878","IPY_MODEL_bbccb7447f064c8f8bf1649e2579611a"],"layout":"IPY_MODEL_cc7c6367922340fd8dfd006c9525f52c"}},"3d3c9e8580814ff2be6d9a60b70beee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a10cb62a3044892a1b3a9fee61487ff","placeholder":"​","style":"IPY_MODEL_686cf0acb4ff40278edd7fd2d3e41b46","value":"Generating train split: "}},"1276be8417184eb495ffeaabba21c878":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b6bc526fbb648eaa40517c27eeb448a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cf92ed318694572ad2c069010f45b3d","value":1}},"bbccb7447f064c8f8bf1649e2579611a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ec95f282fc400f932df6c7fddf65cc","placeholder":"​","style":"IPY_MODEL_b93fb38f69494303bce5dec0f5902fc0","value":" 1795/0 [00:00&lt;00:00, 3119.96 examples/s]"}},"cc7c6367922340fd8dfd006c9525f52c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a10cb62a3044892a1b3a9fee61487ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"686cf0acb4ff40278edd7fd2d3e41b46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b6bc526fbb648eaa40517c27eeb448a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8cf92ed318694572ad2c069010f45b3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15ec95f282fc400f932df6c7fddf65cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93fb38f69494303bce5dec0f5902fc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fdf613618e341ec8ad700bd673ca1a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db384aab313e403f896b7d3498284220","IPY_MODEL_020754b8d8cd4bf6b158f2c07db3c42b","IPY_MODEL_fa67bd65e12a4276a0107de07204f100"],"layout":"IPY_MODEL_2f75bd5356c44701974c5c4d57ce7861"}},"db384aab313e403f896b7d3498284220":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e73bcc17f574b8dbfd077df7bbbd5ef","placeholder":"​","style":"IPY_MODEL_9aa410f255a8429eaf3e65ea392d65ae","value":"Generating validation split: "}},"020754b8d8cd4bf6b158f2c07db3c42b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98224876951f421494507f6371ba021b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b03190606404c7da8c89e5b35dff8fa","value":1}},"fa67bd65e12a4276a0107de07204f100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2a292b7859645cfa43adeee9499b010","placeholder":"​","style":"IPY_MODEL_e8b85710440641d299d3e94b47493a9e","value":" 257/0 [00:00&lt;00:00, 3330.40 examples/s]"}},"2f75bd5356c44701974c5c4d57ce7861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e73bcc17f574b8dbfd077df7bbbd5ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa410f255a8429eaf3e65ea392d65ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98224876951f421494507f6371ba021b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3b03190606404c7da8c89e5b35dff8fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2a292b7859645cfa43adeee9499b010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b85710440641d299d3e94b47493a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81d9a9af03dc41e780f08d94434d36d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_462d084a3f1d4c28867cbd7b4cad7827","IPY_MODEL_5088ba4fad794338a7003896bdfd5597","IPY_MODEL_02479898d62e49dd91000a050eb24414"],"layout":"IPY_MODEL_df523a1322e04283941ee026ed9e9f14"}},"462d084a3f1d4c28867cbd7b4cad7827":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14fd6d16e90438c87f90dc7afde91b1","placeholder":"​","style":"IPY_MODEL_648ca6fc08174c62bfdb3c20cfdaa43d","value":"Generating test split: "}},"5088ba4fad794338a7003896bdfd5597":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab119a81b90b4a3a8ada6dfaeb7d4eb2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e27be2769614867b2a9b5492501940b","value":1}},"02479898d62e49dd91000a050eb24414":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1131279a2c1946889772036d2fe95f97","placeholder":"​","style":"IPY_MODEL_9e688a824b0644ecb3c96d8ad82f0003","value":" 513/0 [00:00&lt;00:00, 4765.75 examples/s]"}},"df523a1322e04283941ee026ed9e9f14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c14fd6d16e90438c87f90dc7afde91b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"648ca6fc08174c62bfdb3c20cfdaa43d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab119a81b90b4a3a8ada6dfaeb7d4eb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3e27be2769614867b2a9b5492501940b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1131279a2c1946889772036d2fe95f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e688a824b0644ecb3c96d8ad82f0003":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n","!pip -q install accelerate>=0.12.0\n","!pip install datasets"],"metadata":{"id":"zuwLc--q7RtP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691832128146,"user_tz":-120,"elapsed":50788,"user":{"displayName":"Antonello Meloni","userId":"09336063038722863523"}},"outputId":"df2f69dd-9aa5-4674-90e1-bfb587824a32"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/en2sparql"],"metadata":{"id":"YcU-KRrrF9JR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691832175135,"user_tz":-120,"elapsed":17661,"user":{"displayName":"Antonello Meloni","userId":"09336063038722863523"}},"outputId":"759faea4-7914-409a-81cd-7e1d6ddcdc4c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/en2sparql\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xF_bcVRM61-s","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7fcbf51d09446b08e80e86259d81bda","34eff9a8b464427795b4474ae92b23d0","09e400e47950435787a565aabcd34fa8","3f6c494382664869bc6560072bb25770","958ba0a61bcf4a3aa7c18e0156f6fa55","4548b4cbf3bc43c28420ce8cdfd86a54","48c8533b7608446997e3aeb910db5428","a79b4e8b71ff410c9d4e291c1a5f6159","1c8e0a2fad0e46edae9a31e42b9b7647","b7471e5872b24744aadf5b2b420f971d","fb19e2977b694d3d83d28c1e47368dd7","d371fb36f1e4406db548b857268f0914","8ddba2893457440e819c3406d2a609cb","e3d59431d6f644f7ad77cdf8c3c2e3c5","f741d1dc701a4ae8a0b51ea69201cecb","1ccb79cbc8684128984da118aa6b1a46","b324fadd4a3343389c5277b3d86e5d5e","24fc77e5dff74f6eb5cfe2d06baba1e0","910f90c2383248b5988b7d8751841532","e3a9de58258a4aaf8806a4f58be19d76","548279f7e22e4632a8f7f7dbd3283da4","776e3c00fb324a699cc99075e01df672","34e7ad0f1e664212a4b42b120ff8d522","7173de877b55404aaeed6b9e77b607a0","396dd6b2955a44c8a790da9ecbb9b522","c49033513914478facd0cd2a555d9776","900094fd77c34a27ac8555df5a4eaad8","06b4878929a84d5bae28295b213ab7dc","7bf62e741e90475ca956216439f1c4d4","cd989454006a431182389e986e5caa63","bf0c6346751d46c0be3a3e2281582bd7","b06365aae7d2431bb83f82d90d3b99c0","f51e65e810834a9db6ff33c64ee9b7e0","2fe7f809ca7049f7a6d99a97b381eb54","eb5714b64adb485e8521dc4b2f085897","33d1845c7e9c41a892552c0336bd1550","2ada513aa4fb46bc9c33b1172433c57e","8fb4ee5e79ee4977a7a03e839cffce1d","1a083b806e244b90a8f14fc4622bc623","8893ff1e5fa7466bb0cc596abd2d62a7","2e2e0cbb702049f3ac0fe5ff31103ff4","5ac8869b15424a38a1eed158c3969439","b30677bf96164e519de48b0b8be9b0a3","2ec08648d7a8496c986b1c04ecd3ba6d","9f6f5615e3bd41298e1a46594f8277f7","1b5679a8ddf54b44b9ffad6ca307d5d9","c021f62acd8a413c962003a74facb90c","ca1b0c48c5df4942aa944b1c21d5ca71","eb669c7c00c24b988f96471dc0067704","acfb866a9fbf4d68a9155dc460161f98","217963aa6f264fdd8b0e03114e861d88","aad4b78b44674e73808f1ecf3f1ebe6a","34584689b65f4336aa043f18406c9357","4e2c56acfd3f434390c5f37f12f4dc50","6bd5ebdfb0dd4201b3823423b2f50b20","b1ec530ba613455887f5cc81374510ec","25284b84e1de4fc1995368af27b35337","959f2e9bf03140faac727099d12cf4f4","8335789b07ba4ab395fbd5c2b230832e","f8e79d5a5f5041089bf9427d341e3b6b","e9ae5605fb7248698a25b8487f78d944","6b8b7defa57a4702b7f2b44655e21723","d6aa8ea9b77040d7a8bff1ff501700c6","114b4cb7f8fd43608d19869827d5e140","3e588f3f3b1144e79d206c7c4340ca22","6472e9e15a80411fb5cbdb65aaae8f09","113f72e106a9434aa7f2223da018965e","6ea38042651c490d9d9d8e949db8396a","4668cd7b9f5a40f4bcb691e2d6f29018","3c5dd9984b1e43958015711df1668429","04ee7f20080a4c7ebf08d5e33b0ff580","a9cf38f0804f4b82879fa9b3eabf9f06","398c555bb4dd4e4fb1b411856edc27af","e8aad3c80deb49d0a852fcac1178b577","ab425a56d8394202a14faad20138c137","50df7cf0de0d4e658df20aa7229cd486","d49f74e7f95a47389c3f69040876cb06","47569d409b3045e7834d191a2ce3f7b8","e19a607471ae46239f15994a1f8f7a3f","cd94c89bf84941b7bff7a4dbce34bc56","75fb4849bd9a495480fa1387fd108172","ab9518c4c9314d459dccb169e0fb3b90","3963095099bd4434a6974115860fa8d9","6b906f6108d041f1ae29afb7d84721e9","33e97f8383ad44d4af2e0466b6deb18d","7d416581e17c4ddf8dffc5a77ffa21fd","9b4982a377fa4485909af281bd841827","3546308977c14ae3b7c4320b96332f99","5df3283734c34e72b3b0e4139fec5c05","d03ce43e37924e1cbbf110068c430eb4","f68ef0726a024c4fb30ae5038767b49e","906a047a06134687b5a4b5a1f540604d","d987b121549e48259be1a14ca133b209","46409c015e584a628ff079ea9163c568","b21e980bfca3471f91bd8894d0e5ceb5","6f9e7621b3984a3b88c10e35ce1a9d5e","3c2aadd693be497d9da535c19676791c","df8938bf13c14e2ba12260cd22eb7603","52960c227d40455f8053aa8d69015fca","4a138dcce92c4363b497a4dc5c951cba","3d3c9e8580814ff2be6d9a60b70beee1","1276be8417184eb495ffeaabba21c878","bbccb7447f064c8f8bf1649e2579611a","cc7c6367922340fd8dfd006c9525f52c","3a10cb62a3044892a1b3a9fee61487ff","686cf0acb4ff40278edd7fd2d3e41b46","9b6bc526fbb648eaa40517c27eeb448a","8cf92ed318694572ad2c069010f45b3d","15ec95f282fc400f932df6c7fddf65cc","b93fb38f69494303bce5dec0f5902fc0","9fdf613618e341ec8ad700bd673ca1a5","db384aab313e403f896b7d3498284220","020754b8d8cd4bf6b158f2c07db3c42b","fa67bd65e12a4276a0107de07204f100","2f75bd5356c44701974c5c4d57ce7861","3e73bcc17f574b8dbfd077df7bbbd5ef","9aa410f255a8429eaf3e65ea392d65ae","98224876951f421494507f6371ba021b","3b03190606404c7da8c89e5b35dff8fa","a2a292b7859645cfa43adeee9499b010","e8b85710440641d299d3e94b47493a9e","81d9a9af03dc41e780f08d94434d36d5","462d084a3f1d4c28867cbd7b4cad7827","5088ba4fad794338a7003896bdfd5597","02479898d62e49dd91000a050eb24414","df523a1322e04283941ee026ed9e9f14","c14fd6d16e90438c87f90dc7afde91b1","648ca6fc08174c62bfdb3c20cfdaa43d","ab119a81b90b4a3a8ada6dfaeb7d4eb2","3e27be2769614867b2a9b5492501940b","1131279a2c1946889772036d2fe95f97","9e688a824b0644ecb3c96d8ad82f0003"]},"outputId":"460a5fda-bb40-4006-ebf2-ee7d58909534","executionInfo":{"status":"ok","timestamp":1691840058490,"user_tz":-120,"elapsed":7872295,"user":{"displayName":"Antonello Meloni","userId":"09336063038722863523"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7fcbf51d09446b08e80e86259d81bda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d371fb36f1e4406db548b857268f0914"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e7ad0f1e664212a4b42b120ff8d522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe7f809ca7049f7a6d99a97b381eb54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)instruct_pipeline.py:   0%|          | 0.00/9.16k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6f5615e3bd41298e1a46594f8277f7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["A new version of the following files was downloaded from https://huggingface.co/databricks/dolly-v2-3b:\n","- instruct_pipeline.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ec530ba613455887f5cc81374510ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"113f72e106a9434aa7f2223da018965e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47569d409b3045e7834d191a2ce3f7b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/553k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df3283734c34e72b3b0e4139fec5c05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a138dcce92c4363b497a4dc5c951cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdf613618e341ec8ad700bd673ca1a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d9a9af03dc41e780f08d94434d36d5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 1795\n","    })\n","    validation: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 257\n","    })\n","    test: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 513\n","    })\n","})\n","Error with key 10-None\n","513\n","0%  [[{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Story Cloze Test\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n\\t?dataset a orkgc:Dataset;\\n\\trdfs:label?dataset_lbl.\\n\\tFILTER (str(?dataset_lbl) = \"Word Level\")\\n\\t?benchmark orkgp:HAS_DATASET?dataset.\\n\\t?cont orkgp:HAS_BENCHMARK?benchmark.\\n\\t?paper orkgp:P31?cont;\\n\\trdfs:label?paper_lbl.\\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"UrbanSound8k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n\\n   ?dataset a orkgc:Dataset;\\n\\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"PTB\")\\n\\n   ?cont orkgp:HAS_BENCHMARK?benchmark\\n\\n   ?paper orkgp:P31?cont;\\n    rdfs:label?paper_lbl\\n\\n    }\\n\\n (English text): The following research papers have performed benchmarks on the RTE dataset:\\n - \"Neural Machine Translation for Mandarin Chinese to English with Strong Dependency Parsing\" (Joshi et al. 2019)\\n - \"WAN Enabling Multilingual Processing on Embedded Devices with Language-Agnostic Multimedia Communication\" (Chen et al. 2018)\\n - \"Empowering Self-Driving Cars with Vision and Language Skills\" (Mao et al. 2018)\\n - \"Inferring Linguistic Constraints with Neural Tensor Factorization\" (Sergios et al. 2018)\\n - \"Neural Machine Translation for Verbense Co-occurrence Tables\" (Chen et al. 2018)\\n - \"Language Model'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MAZEA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'The models that have been evaluated on the HoC dataset are:\\n- BiCNN\\n- ResNet50\\n- DarkNet-121\\n- MobileNetV2\\n- WideResNet-28-c\\n- Xception\\n- SE+CNN\\nThe models that have been evaluated on the WSC dataset are:\\n- MobileNetV2\\n- SE+CNN'}], [{'generated_text': 'Mean capacity of a carbon-based fuel:\\t880 metric tons of carbon dioxide equivalent'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): List the title and ID of research papers that contain a benchmark over the MLDoc Zero-Shot English-to-Russian dataset?\\n output (Sparql query): SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT16\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The top benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value is 0.556021.'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top-1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"VTAB-1k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nOr\\nSELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top-1\") { SELECT?model?'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"arXiv\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nOUTPUT\\n{\\n    \"paper\": [\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        },\\n        {\\n            \"paper_lbl\": \"arXiv\"\\n        }\\n    ]\\n}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TDM-tagged\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'The name of the top performing model is \"Parsec\"'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"FSNS - Test\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n\\t?dataset a orkgc:Dataset; \\n\\trdfs:label?dataset_lbl. \\n\\tFILTER (str(?dataset_lbl) = \"ImageNet64x64\")?benchmark orkgp:HAS_DATASET?dataset. \\n\\t?cont orkgp:HAS_BENCHMARK?benchmark. \\n\\t?paper orkgp:P31?cont; \\n\\trdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Classical music\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\n\\noutput (Sparql query): \\n{\\n  \"metric\" : {\\n    \"duration\" : 6.499,\\n    \"frame_duration\" : 0.0231367,\\n    \"sample_rate\" : 12000,\\n    \"tracks\" : 3\\n  },\\n  \"metric_lbl\" : \"Classical music\"\\n}'}], [{'generated_text': 'The code can be found in the repository at https://github.com/msau42/zscaler-models.'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Transformer-XL Base\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'Please refer to the paper \"Deep Learning Models for Authoring News\" and the GitHub repository https://github.com/opennews/opennews-models/blob/master/news/model-to-code/news_code_model.py'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ACE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code \\n    WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"PNDec\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CATTS-XSUM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<|endoftext|>Q:\\n\\nCutting down a balloon, without ripping it\\n\\nI have a 15ft long silk balloon, which is full of helium and needs to be cut in half without tearing it. I have some wire cutters, but is there a better way that will result in a more effective cut?\\n\\nA:\\n\\nHere\\'s a better way that will result in a better cut:\\n\\nStart by heating the balloon in a pan over medium heat on the stove.  Warm it up slightly but not so hot that it will burn your hands.\\nThen cut the silk with a pair of kitchen scissors so that it is ready to be ripped at the base of the balloon.  Take your time and make sure you'}], [{'generated_text': 'The top benchmark result (metric and value) over the dataset IMDb-B is http://data.imdb.com/dataset/RMzt5zM0/highest-scoring-result?metric=Title&metric.label=Screen%20Size&metric.sublabel=larger+than+ 1024&value=True'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code \\n    WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"SemExp\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nProvide a list of papers that have utilized the LSTM model and include the links to their code?'}], [{'generated_text': 'Common metrics used to evaluate models on the DDI dataset include:\\n1. MAE (Mean Absolute Error)\\n2. MSE (Mean Square Error)\\n3. R2 (Determination coefficient)'}], [{'generated_text': 'The best performing model in terms of F1 score when benchmarked on the Penn Treebank (Character Level) dataset is the neural network model from the paper \"DistMult: A Parallel Algorithm for Non-Local Attention Inserters\" by Gauthier, Champollion, Joulin, et al.\\nIf we select a metric that penalizes models for having a high number of parameters (which is also the case for F1 score), the best performing model with a high number of parameters is the neural network model from the paper \"DistMult: A Parallel Algorithm for Non-Local Attention Inserters\" by Gauthier, Champollion, Joulin, et al.'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Penn Treebank\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n} \\n\\nSELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Penn Treebank\" and?dataset_lbl not like \"Usenet%20Archive%20Tag%20Syndrome%20-%20Thesaurus%20Issue%20%20-%20March%202006%20-%20ICD-11%20Update.pdf\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkg'}], [{'generated_text': 'The following metrics are commonly used when benchmarking models on the DDI dataset:\\n- MaxIm DL (accuracy)\\n- Hinge loss\\n- Stacked LM loss (reported on Kaggle)'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top 1 Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet V2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'RDFL (Resource Description for Language)'}], [{'generated_text': 'http://sipi.uest.edu.tr/query/LCQuAD.zip'}], [{'generated_text': 'Name the datasets that have been used for benchmarking in the Graph Embedding research problem'}], [{'generated_text': 'select\\n   ?paper?paper_lbl\\n    where {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GAD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'List the title and ID of research papers that contain a benchmark over the DDI dataset?\\nrdfs:label databricks-eugENE-benchmark\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DDI\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nList the title and ID of research papers that contain a benchmark over the DTD dataset?\\nrdfs:label databricks-eugENE-benchmark\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DTD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Gibson PointGoal Navigation\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n} \\n\\nExample output:\\n\\nP31_Gibson_PointGoal_Navigation\\nP31_Gibson_PointGoal_Navigation\\nP31_Gibson_PointGoal_Navigation'}], [{'generated_text': '{ \"metric\" : \"language\", \"metric_lbl\" : \"language\", \"score\" : 4990.0 }'}], [{'generated_text': 'The best performing model on the DuIE dataset in terms of F1 metric is:\\nSELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DuIE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600CrazyClimber\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'select distinct?code\\nwhere\\n{\\n?model a orkgc:Model;\\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"VPN\")\\n?benchmark orkgp:HAS_DATASET?dataset.\\n?cont orkgp:HAS_BENCHMARK?benchmark.\\n?cont orkgp:HAS_MODEL?model;\\norkgp:HAS_SOURCE_CODE?code.\\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {\\n ?model a orkgc:Model;\\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"VPN\")\\n ?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?cont orkgp:HAS_MODEL?model;\\n  orkgp:HAS_SOURCE_CODE?code.\\n}\\nSELECT DISTINCT?code WHERE {\\n ?model a orkgc:Model;\\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"CGU\")\\n ?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?cont orkgp:HAS_MODEL?model;\\n  orkgp:HAS_SOURCE_CODE?code.\\n}\\nSELECT DISTINCT?code WHERE {\\n ?model a orkgc:Model;\\n  rdfs:label?'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DE-ENC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nResult:\\n\\nmetric     metric_lbl\\n-------   -----------\\nAP         accuracy\\nAUC        area under the receiver operating characteristics curve\\nAUPR       area under the precision-recall curve\\nAUPRC      area under the precision-recall curve incorporating class-imbalance\\nlogloss    logarithm of the negative log probability\\nrmse       root-mean-square error\\nROC AUC   receiver operating characteristic area under the curve\\nROC-AUC   receiver operating characteristic area under the curve incorporating class-imbalance\\nREL        relative earth pixel fraction\\nROC-R     receiver operating characteristic area under the curve with a replacement measure\\ntau'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PubMed_20kRCT_bmp\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nmodel          model_lbl    \\n-------------  -----------    \\nCaret      2 (NYT), F1    \\nDuIE    2 (DuIE), F1    \\nCartoDB_DBQ    Carto'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\n+---+----------------------------------------------------------------------------------------------------+\\n|?code|                                                                                                     |\\n+---+----------------------------------------------------------------------------------------------------+\\n| http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.211.7002&rep=rep1&type=pdf            |\\n| http://iris.ist.psu.edu/viewdoc/download?doi=10.1.1.211.7002&rep=rep1&type=pdf                   |\\n| https://github.com/ajayvinofficial/sdam-benchmark/blob/master/code/main.py                           |\\n| https://github.com/ajayv'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"FLOPS\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}]]\n","0 5\n","1 5\n","2 5\n","3 5\n","0 6\n","1 6\n","2 6\n","3 6\n","4 6\n","0 10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0 15\n","1 15\n","2 15\n","3 15\n","0 19\n","0 22\n","1 22\n","0 26\n","0 29\n","0 30\n","1 30\n","0 32\n","0 34\n","1 34\n","2 34\n","3 34\n","4 34\n","0 35\n","1 35\n","2 35\n","3 35\n","0 36\n","1 36\n","0 37\n","0 41\n","0 44\n","9.090909090909092%  [[{'generated_text': 'The highest score for the metric \"accessa-hits\" achieved on the WSC dataset is 1000.00.\\nThe highest score for the metric \"accessa-page-views\" achieved on the WSC dataset is 3000.00.'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\") \\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?paper orkgp:P31?cont; \\n    rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WOS-46985\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"SemEval 2013\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Supervised\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nBest performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric is \\nSELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str'}], [{'generated_text': '[\\n  {\\n    \"paper\": \"P31\",\\n    \"paper_lbl\": \"RTE\",\\n  }\\n]'}], [{'generated_text': '7.4 grams'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE { \\n  ?dataset a orkgc:Dataset; \\n   rdfs:label?dataset_lbl. \\n   FILTER (str(?dataset_lbl) = \"VTAB-1k\") \\n  ?benchmark orkgp:HAS_DATASET?dataset; \\n   orkgp:HAS_EVALUATION?eval. \\n  ?paper orkgp:HAS_BENCHMARK?benchmark. \\n   OPTIONAL {?paper orkgp:HAS_MODEL?model. \\n         ?model rdfs:label?model_lbl. } \\n}'}], [{'generated_text': 'The code references can be found in the following repositories:\\n- https://github.com/OpenLearnMetrics/OpenLearnMetrics/blob/master/CODE_REPOSITORY/OPENlearnmetrics/banner.py\\n- https://github.com/OpenLearnMetrics/OpenLearnMetrics/blob/master/CODE_REPOSITORY/OPENlearnmetrics/cuda_banner.py\\n- https://github.com/OpenLearnMetrics/OpenLearnMetrics/blob/master/CODE_REPOSITORY/OPENlearnmetrics/data_parallel_banner.py\\n- https://github.com/OpenLearnMetrics/OpenLearnMetrics/blob/master/CODE_REPOSITORY/OPENlearnmetrics/real_time_banner.py\\n- https://github.com/OpenLearnMetrics/OpenLearnMetrics/blob/master/CODE_REPOSITORY/OPENlearnmetrics/deep_learning_banner.py'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nA common metrics for evaluating DNN models on the Atari 2600 Freeway dataset is:\\n\\n1. Framerate (FR)\\n2. Accuracy (ACC)\\n3. Top-$n$ Accuracy (TNAC)\\n4. Time per epoch (TIME)\\n5. Training Success Rate (TSR)\\n\\nThe Atari 2600 Freeway dataset is publicly available at https://github.com/orango-lc/atari2600-benchmarks. The metrics can be viewed at https://github.com/orango-lc/atari2600-benchmarks/blob/master/docs/metrics.md'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"VPN\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"CGU\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rd'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"arXiv\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TENNIS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'The metrics used to evaluate models on the RTE dataset are the following: \\n\\n- AUC: Area under the receiver operating characteristic curve \\n- F1: F1 score, a harmonic mean of the precision and the recall of a decision tree classification algorithm.\\n- GBDT: Gradient-based boosting decision tree algorithm.\\n- NB: Naive Bayes.\\n- PROB: The probability of the class to which the observation belongs.\\n- ROC: Receiver operating characteristic curve.\\n- SVM: Support vector machine with linear kernel.\\n- WEKA: The k-nearest neighbors classifier (with the euclidean distance metric).'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DMControl500k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'The following models have been evaluated on the HoC, WSC, NYT, and DDI datasets:\\n- BERT\\n- BERT+AttnBait\\n- BERT+ATT\\n- BERT+ATT+MLM\\n- BERT+MLM\\n- GPT-3\\n- GPT-4\\n- RL\\n- ATMLM\\n- RNNLM\\n- Transfomer'}], [{'generated_text': 'Therapeutic effect of nanocarriers: nucleic acid, small interfering RNA, miRNA, miRNA mimic, PI3K inhibitor, Janus kinase inhibitor, TLR inhibitor, interferon alpha, interferon beta, target necrosis.'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"ROUGE-2\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CL-SciSumm\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"VPN\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n} \\nSELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"CGU\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n} \\nSELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rd'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Permuted Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Sequential MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a sciTLDR:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciTLDR\")?benchmark sciTLDR:HAS_DATASET?dataset; sciTLDR:HAS_EVALUATION?eval.?paper sciTLDR:HAS_BENCHMARK?benchmark. OPTIONAL {?paper sciTLDR:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'Common metrics that are used when benchmarking models on the CommonsenseQA dataset are:\\n- P@1\\n- Recall\\n- F1 Score\\n- MRR\\n- GAVE'}], [{'generated_text': 'SELECT \\n ?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n    { SELECT?metric?metric_lbl?value WHERE { \\n     ?dataset a orkgc:Dataset; \\n      rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"IMDb-M\")?benchmark orkgp:HAS_DATASET?dataset; \\n      orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } \\n     ?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } \\n    } \\n    ORDER BY DESC(?value) } \\n  } \\n  GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a roper:EntityUsageDetectionDataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Scholarly\")?benchmark roper:HAS_DATASET?dataset; roper:HAS_EVALUATION?eval.?eval roper:HAS_VALUE?value. OPTIONAL {?eval roper:HAS_METRIC?metric.?metric roper:LABEL?metric_lbl. }?cont roper:HAS_BENCHMARK?benchmark. OPTIONAL {?cont roper:HAS_MODEL?model.?model roper:LABEL?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a multiell:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MultiNLI\")?benchmark multiellp:HAS_DATASET?dataset; multiellp:HAS_EVALUATION?eval.?paper multiellp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper multiellp:HAS_MODEL?model.?model multiell:LanguageModel.?model_nlp multiell:NlpModel. rdfs:label?model_lbl. } } \\n input (English text): What are the models that have been benchmarked on the MultiNLI dataset?\\n output (Sparql query): SELECT DISTINCT?model?model_lbl WHERE {?dataset a multiell:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MultiNLI\")?benchmark multiellp:HAS_DATASET?dataset; multiellp:HAS_EVALUATION?eval.?paper multiellp:HAS'}], [{'generated_text': 'The following metrics are commonly used to evaluate models on the DDI dataset:\\n - DETDifference: computes the absolute value of the difference between the detection outputs of the model and the reference model, summing the absolute value of differences for all ground-truth boxes that the model misses (i.e., DETDifference[i] = |ground-truth box i output by the model - ground-truth box i output by the reference model|). The metric is commonly referred to as \"DetDifference.\" The higher this metric is, the more the model misses boxes.\\n - DIAdiff: computes the absolute value of the absolute value of the difference between the detection outputs of the model and the reference model, summing the absolute values of differences for all ground-truth boxes that the model misses. The metric is commonly referred to as \"DIAdiff.\" The higher this metric is, the more the model misses boxes.\\nThe following metrics are commonly used to evaluate models on the WSC dataset:\\n - Precision at 1: computes precision@1, which is the fraction of object-level positive detections that are also judged to be positively-scored object-level detections. Higher values mean better precision.\\n - Precision at 5: computes'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n   ?model a orkgc:Model; \\n    rdfs:label?model_lbl. \\n    FILTER (str(?model_lbl) = \"VPN\") \\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?cont orkgp:HAS_MODEL?model; \\n    orkgp:HAS_SOURCE_CODE?code. } \\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"CGU\") \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n\\nSELECT DISTINCT?code WHERE { \\n   ?model a orkgc:Model; \\n    rdfs:label?model_lbl. \\n    FILTER (str('}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NYT-single\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'Commonly used metrics for evaluation on RTE dataset include: \\n\\n- mae \\n- mean absolute error (MAE) \\n- mean absolute percent error (MAPE) \\n- root mean squared error (RMSE) \\n\\nCommonly used metrics for evaluation on WSC dataset include: \\n\\n- mae \\n- mean absolute error (MAE) \\n- mean absolute percent error (MAPE) \\n- root mean squared error (RMSE) \\n\\nCommonly used metrics for evaluation on GAD dataset include: \\n\\n- mae \\n- mean absolute error (MAE) \\n- mean absolute percent error (MAPE) \\n- root mean squared error (RMSE)'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016-ENG-DE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }\\n\\nThe query returns the following results:\\n\\n+--------+----------------+\\n|   model|model_lbl       |\\n+--------+----------------+\\n| LSTM   |lstm             |\\n| LSTM   |large-scale neural-   \\n| transformer-based language  \\n| transformer-based language  \\n+--------+----------------+\\n\\nNote that all the models have a `model_lbl`.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"FLOPS\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CIFAR-100\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': '{\\n  \"metric\" : \"Rank\",\\n  \"metric_lbl\" : \"Rank\",\\n  \"score\" : 24\\n}'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl100k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Assault\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"DQNMMCe+SR\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<|endoftext|>t r be (-1 + 0)/(-3 - -2). Let c be r/(1*2/22). Let l = c - 9. List the prime factors of l.\\n2\\nLet k(r) = 6*r**2 + 5*r + 5. List the prime factors of k(4).\\n3, 43\\nLet s(h) = -h**3 - 8*h**2 - 9*h + 7. Let b be s(-7). Let w = b + -21. List the prime factors of w.\\n13\\nSuppose -2*z + 24 = -0*z. List the prime factors of z.\\n2, 3\\nLet m(y'}], [{'generated_text': 'The top benchmark result achieved on the Ball in cup, catch (DMControl100k) dataset is the Catch value of the metric DMControl. The Catch value is 538.52.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NYT\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nI will be very grateful if you could also point me to a tutorial or any other resources you may have to help me better understand these SPARQL endpoints that are provided by Databricks.'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"MEMEN (single model)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nI/O\\nselect distinct code from'}], [{'generated_text': 'SELECT DISTINCT?code \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"yelp-5\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016-German-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The code used in the papers can be found on the repositories hosting the papers. \\nThey can be found under this path (assuming the code was hosted on GitHub): \\nhttps://raw.githubusercontent.com/eugened/datasets/master/vgprnn/vgprnn.tar.gz\\nhttps://raw.githubusercontent.com/eugened/datasets/master/vmemen/vmemen.tar.gz'}], [{'generated_text': 'SELECT DISTINCT?code \\n    WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Past Decode Reg. + AWD-LSTM-MoS + dyn. eval. model\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Assault\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"200k-ST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Street\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"enwiki8\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': '*  SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciERC\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}]]\n","0 0\n","0 5\n","0 6\n","1 6\n","2 6\n","3 6\n","4 6\n","0 8\n","0 13\n","0 15\n","0 16\n","1 16\n","2 16\n","3 16\n","4 16\n","0 21\n","0 25\n","0 29\n","1 29\n","2 29\n","3 29\n","4 29\n","0 32\n","0 36\n","0 43\n","18.181818181818183%  [[{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CommonsenseQA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SQuAD2.0\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Reading Comprehension\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. } \\n\\nname\\n- News Crawl\\n- Tencent News Dataset\\n- WikiPedia-Article Paragraph Linking Dataset\\n- CoNLL-2009 English Dataset\\n- CoNLL-2010 Chinese Dataset\\n- Stanford Question Answering Dataset\\n- SQuAD Dataset\\n- ATG Workshop on Reading Comprehension Datasets\\n- Microsoft Research SQuAD Dataset\\n- Multi-Genre Natural Language Generation Dataset\\n- MS Medium Dataset\\n- MS Facts Dataset\\n- ABC News Dataset\\n- IWSLT14 English Dataset\\n- IWSLT15 German Dataset\\n- IWSLT15 Arabic Dataset'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoNLL04\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code \\n    WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"XLNet (base)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GAD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'MySQL FullText Search - Recommender system for search engines - Improves results by incorporating information from other sources, such as user feedback. \\nLinear Regression - A mathematical model that fits data to predict outcomes. The model is tuned on the training set and evaluated on the testing set. \\nSVM (support vector machine) - Another type of statistical machine learning model that can be used for regression and classification tasks. \\nMulti-Layer Perceptron - A type of statistical machine learning model that is composed of many layers of neurons in artificial neural networks.'}], [{'generated_text': '3. The most common variables for the atmosphere models are:\\n- CO2\\n- N2\\n- O3'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"DDQNP-PC\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TREC-6\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Rational DQN Average\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The top performing model when benchmarked on the MLDoc Zero-Shot English-to-French dataset is the transformer-base model from the Transformers library.'}], [{'generated_text': 'Indicate the model that performed best in terms of 1-of-100 Accuracy metric on the PolyAI Reddit benchmark dataset?\\nThe best performing model on this benchmark is (modelName), achieving an Accuracy of 0.88'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Long Short Transformer\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The top performing model is a model based on BERT (Bidirectional Encoder Representations from A to Z) trained on LLM (Little Language Models).'}], [{'generated_text': 'Raman spectroscopy is a technique that analyzes chemical bonds in materials by using inelastic light scattering. In a Raman spectroscopy instrument, a laser creates a coherent light beam that is directed into a sample, and the light that is scattered by the sample is analyzed. Raman spectroscopy is used to study materials at the molecular scale, but it can also be used to study bio-molecules at the molecular scale.'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a dtd:Datatype; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DTD\")?benchmark dtd:HAS_DATASET?dataset; dtd:HAS_EVALUATION?eval.?eval dtd:HAS_VALUE?value. OPTIONAL {?eval dtd:HAS_METRIC?metric.?metric dtd:LABEL?metric_lbl. }?cont dtd:HAS_BENCHMARK dtd:BENCHMARK?benchmark. OPTIONAL {?cont dtd:HAS_MODEL?model.?model dtd:LABEL?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { \\n    SELECT?metric?metric_lbl?value WHERE { \\n     ?dataset a cnic:Dataset; \\n      rdfs:label?dataset_lbl. \\n      FILTER (str(?dataset_lbl) = \"CINIC-10\")?benchmark orkgp:HAS_DATASET?dataset; \\n      orkgp:HAS_EVALUATION?eval. \\n     ?eval orkgp:HAS_VALUE?value. \\n      OPTIONAL \\n      { \\n       ?eval orkgp:HAS_METRIC?metric. \\n       ?metric rdfs:label?metric_lbl. \\n      } \\n     ?cont orkgp:HAS_BENCHMARK?benchmark. \\n      OPTIONAL \\n      { \\n       ?cont orkgp:HAS_MODEL?model. \\n       ?model rdfs:label?model_lbl. \\n      } \\n    } \\n    ORDER BY DESC(?value) \\n  } \\n  { \\n    SELECT?metric?metric_lbl?'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SemEval-2018 Task 7\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"AG News\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NCBI_DISEASE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NCBI-disease\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"GCN Hybrid\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'zip\\nchemdner'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"CUB-200-2011\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"SEE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'So far, I was able to find the code used in the following paper: \\nOriol Vila, David Muetzer, Michael Neel, and Nikos Voytonis. \"Benchmarking Networked Databases with Large N-gram Models.\" International Conference on Knowledge Discovery and Data Mining. ACM, 2014.'}], [{'generated_text': 'select distinct metric metric_lbl (max(value) as score) where \\n  {  \\n    select metric metric_lbl, value from \\n    {   \\n      select distinct metric metric_lbl, value from \\n      {   \\n        select distinct metric metric_lbl, value from \\n        {   \\n          select distinct metric metric_lbl, value from \\n          {   \\n            select distinct metric metric_lbl, value from \\n            {   \\n              select distinct metric metric_lbl, value from \\n              {   \\n                select distinct metric metric_lbl, value from \\n                {   \\n                  select distinct metric metric_lbl, value from \\n                  {   \\n                    select distinct metric metric_lbl, value from \\n                    {   \\n                      select distinct metric metric_lbl, value from \\n                      {   \\n                        select distinct metric metric_lbl, value from \\n                        {   \\n                          select distinct metric metric_lbl, value from \\n                          {   \\n                            select distinct metric metric_lbl, value from \\n                            {   \\n                              select distinct metric metric_lbl, value from \\n                              {   \\n                                select distinct metric metric'}], [{'generated_text': 'The following code references can be found in the papers listed below:\\n  - [https://github.com/socharo/DeepLearningBook/blob/master/Learning%20from%20Caption%20Videos/Chapter%204-%20Deep%20Learning%20with%20Deep%20QN%20Layers.ipynb][1]\\n  - [https://github.com/tensorflow/models/tree/master/research/slim][2]\\n  - [https://github.com/kittenswithcodes/kitten-level-1-neural-nets-from-scratch][3]\\n  - [https://github.com/jakevdp/deeplab-rg-crf-keras-benchmark][4]'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GAD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"MMV\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nFrom the code provided I was able to find the following links to papers that have used the MMV model for benchmarking: \\n- https://papers.nips.cc/s/pDcVg2QzcyLnRrDtI2mN2VCKs2Q\\n- https://www.kyb.mpg.de/hintergrund/themen/nie-22/mmv-benchmark.html'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { \\n    { \\n      { \\n        { \\n          { \\n           ?dataset a orkgc:Dataset; \\n            rdfs:label?dataset_lbl. \\n            FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")?benchmark orkgp:HAS_DATASET?dataset; \\n            orkgp:HAS_EVALUATION?eval. \\n           ?eval orkgp:HAS_VALUE?value. \\n            OPTIONAL {?eval orkgp:HAS_METRIC?metric. \\n                      ?metric rdfs:label?metric_lbl. \\n                  } \\n           ?cont orkgp:HAS_BENCHMARK?benchmark. \\n            OPTIONAL {?cont orkgp:HAS_MODEL?model. \\n                    ?model rdfs:label?model_lbl. \\n                } \\n          } \\n          ORDER BY DESC(?value) \\n        } \\n        { \\n          { \\n           ?dataset a orkgc:Dataset; \\n            rd'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?research_problems,?research_problems_labels \\n  WHERE {?papers rdf:type orkgc:Paper.?papers orkgp:P30?research_fields.?research_fields rdfs:label?research_fields_labels. FILTER(REGEX(?research_fields_labels, \"cultural history\", \"i\"))?papers orkgp:P31?contrib.?contrib orkgp:P32?research_problems.?research_problems rdfs:label?research_problems_labels. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WLPC\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TempEval-3\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a scirec:dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciERC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoNLL 2012\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"yelp-14\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\nThe following code references can be found in papers that have utilized the VPN model for benchmarking purposes:\\n- VCGate: https://github.com/virtuaalipliances/v-CNN-GATE\\n- THINQ: https://github.com/thinq-research/THINQ\\n- Catch-ME: https://github.com/sherwood/Catch-Me-Algorithm'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\ninput (English text): Here is a list of models that have been tested on the RTE benchmark dataset:\\nModel\\tLabel\\nSVM\\tSupport vector machine\\nRF\\tRandom Forest\\nLR\\tLogistic regression\\nGBM\\tGradient Boosting Machine\\nTime Series\\tTime Series Regression\\nGaussian Process\\tGaussian Process Regression\\nNB\\tNaive Bayes'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WOS-5736\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': '#\\\\scan the dataset\\n# get the dataset label\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WebQuestions\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'Here are the metrics that are commonly used when evaluating models on the DDI dataset:\\n1.\\tMetric_1: Area under the ROC curve (AUC)\\n2.\\tMetric_2: log-loss\\n3.\\tMetric_3: accuracy\\n4.\\tMetric_4: normalized accuracy'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NaturalQuestions (short)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'The highest benchmark result, including the metric and score, for the WMT2014 French-English dataset is:\\nMetric: sentential-reasoning-french, sentential-reasoning-english, rel-reasoning-french, rel-reasoning-english, parse-task, parse-accuracy, span-alignment-root, span-alignment-core\\nScore: 6.6144, 7.457, 6.8994, 7.3679, 0.8858, 0.9301, 0.9628, 0.9704'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Test perplexity\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WikiText-2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model is orkgp:HAS_MODEL?model where Model has achieved the highest F1 score on the HoC benchmark dataset.'}]]\n","0 7\n","1 7\n","2 7\n","3 7\n","4 7\n","0 8\n","1 8\n","2 8\n","3 8\n","4 8\n","0 12\n","1 12\n","2 12\n","0 13\n","1 13\n","0 15\n","0 16\n","1 16\n","2 16\n","3 16\n","4 16\n","0 24\n","1 24\n","2 24\n","3 24\n","4 24\n","0 27\n","0 28\n","0 29\n","0 46\n","0 48\n","27.272727272727273%  [[{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"All-attention network - 18 layers\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nThis returns the following:'}], [{'generated_text': 'paper \"Disambiguating authors in citations on the web and authorship correlations\" employs cosine similarity'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"STS Benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Freeway\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DCASE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RTE dataset?\\noutput (Sparql query): SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): Give me a list of research'}], [{'generated_text': 'The following metrics are used to evaluate models on the DDI dataset:\\n- top-1: The percentage of times a model identifies the correct category for the top 1 result.\\n- top-5: The percentage of times a model identifies the correct category for the top 5 results.\\n- total: The percentage of total result that a model correctly identifies a category for.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RIVER_RAID\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BERT+BiLSTM+CRF\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Pearson Correlation\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MedSTS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"WSC\")?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?paper orkgp:P31?cont; \\n    rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?code \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<br />\\n<a href=\"http://courses.gla.org/courses/ENG120B/papers/2016/sire2013.pdf\">sire2013</a>, \\n<a href=\"http://www.cs.kent.ac.uk/people/staff/dbtrott/publications/practical_semantic_web_knowledge_management/semantic_web_knowledge_management.pdf\">semantic web knowledge management</a>, \\n<a href=\"http://resources.semanticweb.org/papers/20130623/plagiogau-iit-iiit-52-c.pdf\">plagiogau-iit-iiit'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SST-5_FGCM\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The evaluation metrics that are commonly used when benchmarking models on the DDI dataset are the mean average precision (mAP), the F1 score, the area under the precision recall curve (AUPR) and the area under the f1 score curve (A f1 SCUR).'}], [{'generated_text': 'DBLP\\ngeopolitics\\nTUSCUS\\ngeopolitics'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'List the title and ID of research papers that contain a benchmark over the GAD dataset?\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GAD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nList the title and ID of research papers that contain a benchmark over the DDI dataset?\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DDI\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nList the title and ID of research papers that contain'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"BUCC\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'The following metrics are commonly used when benchmarking models on the DDI dataset:\\n - RMSE \\n- R2\\n - R3'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SHARe\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ShARe/CLEF eHealth corpus dataset?\\n\\noutput (Sparql query):'}], [{'generated_text': 'For graphite'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_'}], [{'generated_text': 'The metrics that are commonly used when benchmarking models on the DDI dataset are:\\n1. Top-5 error (average per example)\\n2. Average model lag time (average number of timesteps)\\n3. Time per example (average)'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Number of params\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': '* TIE.'}], [{'generated_text': 'There are no code references included in this model in the papers that used it.'}], [{'generated_text': 'top_benchmark_result on Atari 2600 Star Gunner:\\n  metric  : INCREMENT\\n  metric_lbl: INCREMENT\\ntop_benchmark_result on NYT:\\n  metric  : TPR\\n  metric_lbl: F1\\ntop_benchmark_result on WSC:\\n  metric  : TPR\\n  metric_lbl: F1'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"NASCell\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"TCN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\n# TODO: Complete query with links to the referenced code'}], [{'generated_text': 'SELECT MAX(value) as score \\n       FROM \\n          ( SELECT  metric, metric_lbl, value \\n                FROM   (SELECT metric, metric_lbl, score, evaluation, dataset, cont, benchmark, model FROM  (SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. }) score ORDER BY score DESC }) group by metric, metric_lbl)'}], [{'generated_text': 'The highest benchmark result (metric and value) achieved over the SQuAD2.0 dataset, including the metric and its value, is:\\n- { \"score\": \"1.0\", \"metric\": \"squad:quad_label,extractor:wiki_label,NER:nd,dataset:wsc\" }\\nThe top benchmark result (metric and value) achieved over the WSC dataset, including the metric and its value, is:\\n- { \"score\": \"1.0\", \"metric\": \"squad:quad_label,extractor:wiki_label,dataset:wsc\" }\\nThe highest benchmark result (metric and value) achieved over the NYT dataset, including the metric and its value, is:\\n- { \"score\": \"0.9\", \"metric\": \"squad:quad_label,extractor:wiki_label,dataset:wsc\" }'}], [{'generated_text': 'select distinct?metric?metric_lbl (max(?value) as?score) where { \\n\\t{ select?metric?metric_lbl?value where {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC2GM\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }\\n\\t}\\n\\t{ order by desc(?value) }\\n}\\ngroup by?metric?metric_lbl'}], [{'generated_text': 'The following metrics are used to evaluate models on the RTE dataset:\\n* Brier score\\n* Confusion Matrix\\n* F-Score\\n* MAP'}], [{'generated_text': 'The largest number of articles about coronavirus has been contributed by'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DuIE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'The coolant used in the ASTRID reactor is distilled water.'}], [{'generated_text': 'top score was achieved on the metric \"frame count\" with a value of 1178432.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Skiing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'name: Text Summarization\\ndataset: datasets.ukc.ac.com/joblib-benchmark\\ndataset_lbl: Text Summarization\\ncont: datasets.ukc.ac.com/joblib-benchmark/Text Summarization\\ndataset_lbl: datasets.ukc.ac.com/joblib-benchmark\\nbenchmark: https://github.com/rajecs/joblib-benchmark\\ndataset_lbl: datasets.ukc.ac.com/joblib-benchmark/Text Summarization\\ncont: https://github.com/rajecs/joblib-benchmark'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ATARI2600TUTANN\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'The best performing model when benchmarking on the Atari 2600 Tutankham dataset is a model known as Sarsa-Dié.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PROTEINS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'The best performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset is the DuEE model.'}], [{'generated_text': 'The following are the common metrics used for evaluation on the DDI dataset:\\n\\n-  Binary Accuracy (Acc)\\n-  Cross Entropy Loss (Loss)\\n-  Log-Loss (Lg_Loss)\\n-  Mean Squared Error (MSE)\\n-  Root Mean Squared Error (RMSE)\\n-  Support Accuracy (Acc_Supp)\\n-  Support Rate (Supp_Rate)'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BiT-M\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"RE+ Micro F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ACE 2004\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a norkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Nottingham\")?benchmark norkgp:HAS_DATASET?dataset; norkgp:HAS_EVALUATION?eval.?eval norkgp:HAS_VALUE?value. OPTIONAL {?eval norkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont norkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont norkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Multi-Perspective Matching (single model)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'models: \\n- NiFi\\n- OctoPrint\\n- VDC\\n- OpNet\\n- Cora\\n- Seq2Seq\\n- DART\\n- BleuSpotter\\n- AdaBoost\\n- TATW'}]]\n","0 1\n","1 1\n","2 1\n","3 1\n","4 1\n","0 5\n","1 5\n","0 13\n","1 13\n","0 14\n","1 14\n","0 18\n","0 20\n","1 20\n","2 20\n","3 20\n","4 20\n","0 22\n","0 24\n","0 25\n","0 26\n","0 30\n","1 30\n","0 31\n","0 32\n","1 32\n","0 33\n","1 33\n","2 33\n","0 35\n","0 36\n","1 36\n","2 36\n","3 36\n","4 36\n","0 38\n","1 38\n","0 40\n","1 40\n","2 40\n","3 40\n","4 40\n","0 42\n","0 43\n","0 49\n","1 49\n","36.36363636363637%  [[{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WSC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FIL'}], [{'generated_text': 'Commonly used evaluation metrics are:\\n- Precision@K (equivalent to Area-Under-Roc).\\n- Normalized Caddylet Coverage.\\n- Normalized Model Time.\\n- Mean Square Error (MSE) between ground-truth and predicted model behavior.\\n- F1-score between ground-truth and predicted model behavior.\\n- R2-score between predicted and true gold-standard behavior.'}], [{'generated_text': 'As of 17/05/20, the following research papers contain benchmarks over the GAD dataset:\\n\\n- \"A Study of Self-supervised Learning and Implicit Bias with Implicit Adversarial Methods on Large-scale Semi-supervised Learning Datasets\", Ching-min Hsieh, Wai-Kit Li, Hung-Lin Chang, et al, URL: https://github.com/kmli/self-supervised/blob/master/docs/Papers/Self-supervised%20Learning%20and%20Implicit%20Bias%20with%20Implicit%20Adversarial%20Methods%20on%20Large-scale%20Semi-supervised%20Learning%20Datasets.pdf\\n- \"Machine Reading Comprehension via Regularized Guided Optimization on Large Vocabularies\", Qin Fang, Jiaming Shen, William T Ge, Kaige Lu, Paul H Institute for Data Sciences and Technology, University of South Florida, URL: https://arxiv.org/abs/2003.08798\\n- \"UNSEEN: Unsupervised Learning of Lexical Semantic Primitives by Empirical Risk Minimization\", Siddharth Kandula,'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"AxCell\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"AWD-LSTM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PubMedQA\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'Most commonly used benchmark datasets for the Text Generation research field include:\\n- SQuAD\\n- WikiSQL\\n- TACO'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Gibson_PointGoal_Navigation\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cheetah\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a pddl:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Dogs\")?benchmark pddl:HAS_DATASET?dataset; pddl:HAS_EVALUATION?eval.?eval pddl:HAS_VALUE?value. OPTIONAL {?eval pddl:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont pddl:HAS_BENCHMARK?benchmark. OPTIONAL {?cont pddl:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Supervised:\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Test perplexity\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WikiText-103\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016-EN-Ru\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'sample size'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Encudo\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n ?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. \\nWHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_B'}], [{'generated_text': 'The following code references can be found in papers that have utilized the VPN, Bi+, RNN and FABIR models:\\n\\n* GitHub repository: https://github.com/ovocomp/ovocomp-models/tree/master/models\\n* Code shared at: https://www.ovocomp.com/api/model/list.html?modelType=LanguageModel&pageSize=20\\n* Code shared at: https://www.ovocomp.com/api/model/code.html?modelType=LanguageModel&code='}], [{'generated_text': 'The emergency type is AMBER Alert'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoQA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ONTO\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThis query retrieves the top F1 model on the OntoNotes benchmark dataset, which is orkgp:HAS_MODEL?model.'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n ?dataset a orkgc:Dataset;\\n  rdfs:label?dataset_lbl.\\n  FILTER (str(?dataset_lbl) = \"Defender\")?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?paper orkgp:P31?cont;\\n  rdfs:label?paper_lbl.\\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Pointer + Coverage + EntailmentGen + QuestionGen\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"VPN\") \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n}\\n\\nSELECT DISTINCT?code WHERE { \\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"CGU\") \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n}\\n\\nSELECT DISTINCT?code WHERE { \\n?model a orkgc:Model; \\nrd'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a commonsenseqa:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"commonsenseqa\")?benchmark commonsenseqa:HAS_DATASET?dataset; commonsenseqa:HAS_EVALUATION?eval.?paper commonsenseqa:HAS_BENCHMARK?benchmark. OPTIONAL {?paper commonsenseqa:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'Commonly used metrics for evaluation on the Amazon-2 dataset are:\\n\\n-  AUC (Area Under the ROC curve)\\n-  F1 score\\n-  mean_absolute_error'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"A3C-CTS\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a hutterprize:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HutterPrize\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nAlthough there are several \"best performing\" models in terms of F1 score in the Sparql query above, you might want to consider just using the string literal string \"F1\" in your filter predicate to get more accurate results.'}], [{'generated_text': 'SELECT * FROM \\n<http://dbpedia.org/resource/>\\n<http://data.semanticweb.org/dataset/ontology-based-medical-writing/dataset>\\nWHERE \\n<http://data.semanticweb.org/dataset/ontology-based-medical-writing/dataset/hasParamScore>\\nAND \\n<http://data.semanticweb.org/dataset/ontology-based-medical-writing/dataset/value> = \"0.9789\"'}], [{'generated_text': 'SELECT DISTINCT?problem?problem_lbl WHERE {?rf a orkgc:ResearchField; rdfs:label?rf_label. FILTER (str(?rf_label) = \"Artificial Intelligence\")?paper orkgp:P30?rf; orkgp:P31?cont.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem.?problem rdfs:label?problem_lbl. }'}], [{'generated_text': 'The models that have been benchmarked on the HoC dataset include:\\n- XGboost\\n- Lightgbm\\n- XGBoost\\n- LightGBM'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {\\n ?model a orkgc:Model ;\\n  rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?cont orkgp:HAS_MODEL?model;\\n  orkgp:HAS_SOURCE_CODE?code.\\n}\\n\\nSELECT DISTINCT?code WHERE {\\n ?model a orkgc:Model ;\\n  rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"RNN\")?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?cont orkgp:HAS_MODEL?model;\\n  orkgp:HAS_SOURCE_CODE?code.\\n}\\n\\ninput (English text): The following papers utilize the Bi+ model:\\n- Baumgartner, Joachim, et al. \"Comparison'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"STS-Benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"SAM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The datasets that have been used for benchmarking in the Joint Entity and Relation Extraction research field are:\\nDatasets:\\n- CoNLL-2010\\n- SemEval-2010\\n- Europarl\\n- Dragon\\n- CoNLL-2007\\n- SemEval-2007\\n- MovieLens\\n- Englishdog\\n- MultiNLI\\n- RACE\\n- TurkText\\n- WikiLinkGraph\\n- ACGAN\\n- MSR-DBpedia'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MultiRC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model;\\n  rdfs:label?model_lbl.\\n  FILTER (str(?model_lbl) = \"SRU++ Base\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Asteroids\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014-DE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SearchQA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ONTO\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Defender\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE {\\n\\n    {\\n\\n      {\\n\\n        {\\n\\n         ?eval orkgp:HAS_VALUE?value.\\n\\n          OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }\\n\\n         ?cont orkgp:HAS_BENCHMARK?benchmark.\\n\\n         ?cont orkgp:HAS_MODEL?model.\\n\\n         ?model rdfs:label?model_lbl.\\n\\n        }\\n\\n      }\\n\\n    }\\n\\n    {\\n\\n     ?dataset a orkgc:Dataset;\\n\\n    }\\n\\n   ?dataset_lbl.\\n\\n    FILTER (str(?dataset_lbl) = \"WMT2014-ENG-DE\")\\n\\n   ?benchmark orkgp:HAS_DATASET?dataset;\\n\\n   ?benchmark orkgp:HAS_EVALUATION?eval.\\n\\n   ?eval orkgp:HAS_VALUE?value.\\n\\n    OPTIONAL {\\n\\n     ?eval orkgp:HAS_METRIC?metric.'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PWC-Leaderboards (Restricted)\")}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ENWK8\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'Common metrics used to evaluate models on the GAD benchmark dataset are as follows:\\n* F1 score - F1 score measures the accuracy of a model in making a prediction. F1 score = 2 * (precision * recall) / (precision + recall)\\n* Area Under the ROC Curve - Area Under the ROC Curve (also known as AUC) measures the accuracy of a model over a range of predicted labels. Higher values for area under the ROC curve means better classification\\n* Precision at k - Precision at k (also known as P@k) measures the proportion of instances for which the model predicts the k-th correct class. Higher values for precision at k mean better classification\\n* Recall at k - Recall at k (also known as R@k) measures the proportion of instances for which the model predicts the k-th class. Higher values for recall at k mean better classification\\n* Zero-shot learning - This metric measures the performance of a model in predicting an unseen category that was not present in the training set. Higher values for this metric means better performance.'}], [{'generated_text': 'Sample size'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n   ?model a orkgc:Model; \\n    rdfs:label?model_lbl. \\n    FILTER (str(?model_lbl) = \"BCN+ELMo\") \\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?cont orkgp:HAS_MODEL?model; \\n    orkgp:HAS_SOURCE_CODE?code. \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HMDB51\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}]]\n","0 1\n","0 2\n","0 6\n","1 6\n","2 6\n","3 6\n","0 13\n","0 16\n","0 17\n","1 17\n","2 17\n","3 17\n","4 17\n","0 24\n","1 24\n","2 24\n","3 24\n","0 30\n","0 35\n","0 46\n","0 47\n","1 47\n","2 47\n","3 47\n","4 47\n","45.45454545454546%  [[{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"classicalmusic5\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"IWSLT2014-DE\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'Common evaluation metrics include precision, recall, f1 score, and the Area Under the Curve. For Atari 2600 Skiing, we use the max sub-game victory count as our metric.'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nThere are three datasets in the datasets property of OntBoot: DDI, RTE, and Atari 2600 Frostbite. Research papers containing benchmarks for these datasets are listed below:\\n\\n*  \"Dataset-level Benchmarks for DDI\"  P31, RW02, RW05, RW09, and RW10\\n*  \"A Benchmarking Study of an Improved Terminase II Factorization Algorithm for RNA-Binding Site Prediction\"  RW03\\n*  \"A Benchmarking Study of a Cross-platform Java-based Subgraph-Based Approach to RNA-Binding Site Prediction\"  RW04\\n*  \"A Benchmarking Study of'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"COMET - Direct\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ATARI_2600_BOXING\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PennTreebank\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"IWSLT2015-GER\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Frostbite\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\n\\nThe metrics commonly used to evaluate the models on this dataset are:\\n- AverageFrameTime\\n- FalseAlarmRate\\n- FramesPerSecond\\n- AverageConfidence\\n- MaxConfidence\\n- MeanConfidence\\n- BkgndFrameTime'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MULTI-NLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'The model that achieves the highest F1 score on the HoC benchmark dataset is'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"KINETICS-600\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"YELP-5\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"Bi+\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n} \\n?model orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"RNN\") \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code.'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a nq:Dataset; rdfs:label nq:ShortLabel. FILTER (str( nq:ShortLabel) = \"short\") nq:Q1. nq:Q1 val. nq:Q1?value. } } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'Common metrics used to evaluate models on the DDI dataset are\\n- Accuracy (also known as sensitivity or recall)\\n- F1 Score (also known as effectiveness or harmonic mean of precision and recall)\\n- Precision\\n- Recall\\n- Miss Rate\\nCommon metrics used to evaluate models on the GAD dataset are\\n- F1 Score (also known as effectiveness or harmonic mean of precision and recall)\\n- Accuracy (also known as sensitivity or recall)\\n- Precision\\n- Recall\\n- Miss Rate'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MML-A\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'Name the datasets that have been used for benchmarking in the citation classification research problem?'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"VPN\")\\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n}\\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"CGU\")\\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"Bi+\")'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PubMed-20K-RCT\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. } \\n\\nWhich of the following papers have performed a benchmark on the RTE dataset?\\n\\nSELECT DISTINCT?paper WHERE {?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"arXiv\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The top performing model in terms of NLL score when benchmarked on the Nottingham dataset is: \\n<http://www.cs.toronto.edu/~pete/papers/EMNLP2011.pdf#page=35>'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n   ?model a orkgc:Model; \\n    rdfs:label?model_lbl. \\n    FILTER (str(?model_lbl) = \"DCN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; \\n    orkgp:HAS_SOURCE_CODE?code. \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top-1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"iNaturalist 2018\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Ice Hockey\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Sciencific Results Extraction\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'The datasets that have been used for benchmarking in the Word Embedding research problem include:\\n- MovieLens 20M\\n- SUTact20\\n- Megabank\\n- UD Teddy\\n- UD Fall\\n- UD CommonCrawl\\n- UD JRC crawled\\n- SIGHawk'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WIKITEXT-2\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nA:\\n\\nThis is the SPARQL query that I used to get the list of research papers that have performed benchmarks on the DDI dataset:\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DDI\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nAnd this is the query that I used to get the list'}], [{'generated_text': 'The metrics commonly used when benchmarking models on the DDI dataset are:\\n- Peak Signal-to-Noise-Ratio (PSNR)\\n- Mean Opinion Score (MOS)\\n- Bhattacharyya Coefficient (BC)\\n- Freeman-Bisi (F-B) Coefficient\\n- Correlation Coefficient (CC)\\n- Root Mean Square Error (RMSE)\\n- Signal-to-Noise-Ratio at 3 dB Slope (SNRE)'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Duel noop\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The datasets that have been used for benchmarking in the Graph Embedding research problem:\\n- Caltech-256\\n- Oxford-102\\n- CUB-200-2011\\n- AOD-20- NEWS\\n- FCV1\\n- FCV2\\n- FCV3\\n- ImageNet'}], [{'generated_text': \"The most common evaluation metric used on datasets like the RTE, WSC, and DDI datasets is the Area Under the ROC Curve (AUC). AUC is computed by performing a Receiver Operating Characteristics (ROC) analysis on each model's predictions against a particular ground-truth label. The area under the curve is a metric that evaluates how well a model is able to rank True Positive (correctly predicts the label) versus False Positive (incorrectly predicts the label) examples.\\n\\nAnother common metric used to evaluate models on datasets like the DDI dataset is the Precision-Recall curve, or the curve that plots the precision vs. recall for a model on different label thresholds. The area under the Precision-Recall curve is another common evaluation metric used to evaluate model performance on datasets like DDI.\\n\\nOther common evaluation metrics that are often used on datasets like the WSC dataset include the TPR at different thresholds (TPR@10, TPR@5, TPR@1, etc.), the F1 score, and the C-score.\"}], [{'generated_text': 'The following are the metrics that are commonly used when benchmarking models on the DDI dataset:\\n1. Total Accuracy (Acc): the proportion of correct predictions across all classes.\\n2. Class Accuracy (Acc): the proportion of correct predictions for a single class, e.g. for class \"cat\" Acc should be calculated as (correct predictions for cat class/total predictions for all classes) * 100.\\n3. Overall F1-score (F1): the harmonic mean of the precision (TPR) and recall (TNR).\\n4. Number of correct predictions for a single class.\\n5. Confusion matrix: this is a table where each cell represents the number of correct predictions for a particular pair of classes.'}], [{'generated_text': 'select distinct?model?model_lbl where {\\n ?metric a orkgc:Metric;\\n  rdfs:label?metric_lbl.\\n  FILTER (str(?metric_lbl) = \"Accuracy\")\\n  {\\n    SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset;\\n                                          rdfs:label?dataset_lbl.\\n                                          FILTER (str(?dataset_lbl) = \"Sequential CIFAR-10\")\\n                                         ?benchmark orkgp:HAS_DATASET?dataset;\\n                                          orkgp:HAS_EVALUATION?eval.\\n                                         ?eval orkgp:HAS_VALUE?value;\\n                                          orkgp:HAS_METRIC?metric.\\n                                         ?cont orkgp:HAS_BENCHMARK\\n                                         ?benchmark;\\n                                          orkgp:HAS_MODEL?model.\\n                                         ?model rdfs:label?model_lbl.\\n                                      }\\n    ORDER BY DESC(?value)\\n    LIMIT'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DTD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciCite\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nresults:'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n\\t?dataset a orkgc:Dataset; \\n\\trdfs:label?dataset_lbl. \\n\\tFILTER (str(?dataset_lbl) = \"Skiing\")?benchmark orkgp:HAS_DATASET?dataset. \\n\\t?cont orkgp:HAS_BENCHMARK?benchmark. \\n\\t?paper orkgp:P31?cont; \\n\\trdfs:label?paper_lbl. \\n} \\n\\nThe list of research papers that contain benchmarks over the GAD dataset:\\n\\n1\\tbenchmark over GAD dataset\\tP31\\tGAD\\tP31\\n2\\tRTE\\tHAS_DATASET\\tRTE\\tHAS_BENCHMARK\\tRTE\\n3\\tDTD\\tHAS_DATASET\\tDTD\\tHAS_BENCHMARK\\tDTD'}], [{'generated_text': 'The metrics commonly used when benchmarking models on the DDI dataset are: \\n\\nAccuracy (ACC): The accuracy of the model is computed as (TP + TN)/ (TP + TN + FP + FN).\\nSens (S): Sensitivity is computed as TP/ (TP + FN). \\n     where TP = True Positives and TN = True Negatives. \\n     The sensitivity measures the ability of a model to correctly identify positive examples.\\nSpec (SP): The specificity of the model is computed as TN/ (TN + FP).\\n     The specificity measures the ability of a model to correctly identify negative examples.\\nPPV (P): Positive Predictive Value (also called sensitivity) is computed as TP/ (TP + FN). \\n     where TP = True Positives.\\nNPV (N): Negative Predictive Value (also called Specificity) is computed as TN/ (TN + FP).\\n     where TN = True Negatives.'}], [{'generated_text': 'SELECT *\\nFROM   -- A data table created from the following (empty) query'}], [{'generated_text': 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"Rfa-Gate-arccos\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SHARe/CLEF eHealth\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'Commonly used metrics for evaluation on DDI dataset:\\n- AUROC\\n- AUPRC\\n- F1 score\\nCommonly used metrics for evaluation on GAD dataset:\\n- AUROC\\n- AUPRC\\n- F1 score'}], [{'generated_text': 'The best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric is'}], [{'generated_text': 'The most commonly used benchmark datasets for the Natural Language Inference research field are:\\n1. Wiki10k for testing supervised learning systems.\\n2. TACL for development of text generation systems.\\n3.Calibrated FSIQ for measuring the quality of spell checking.\\n4. TREC finals for testing word sense disambiguation.\\n5. NER 2014 for testing named entity recognition.'}], [{'generated_text': 'The following models have been evaluated on the HoC, WSC, NYT, DDI datasets:\\n\\n- BERT\\n- GPT-3\\n- GPT-2\\n- XLNet\\n- RoBERTa\\n- XLNet-base\\n- LASAGNA\\n- X-RACT\\n- STITCH'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"DeiT-Ti\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}]]\n","0 3\n","1 3\n","0 13\n","0 18\n","0 20\n","1 20\n","2 20\n","3 20\n","4 20\n","0 24\n","0 30\n","1 30\n","2 30\n","0 32\n","1 32\n","2 32\n","3 32\n","4 32\n","0 34\n","0 35\n","0 36\n","0 41\n","0 45\n","1 45\n","2 45\n","0 46\n","0 47\n","0 48\n","1 48\n","54.545454545454554%  [[{'generated_text': 'For the country of study Switzerland, overall prevalence of epilepsy is the highest'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"ShARe/CLEF eHealth\") \\n ?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. \\n ?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model. \\n ?model rdfs:label?model_lbl. } \\n}'}], [{'generated_text': 'Sven Nowry\\n\\n tack (Sparql query): SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HMDB51\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nThe models that have been tested on the HMDB51 benchmark dataset are:\\n\\nNFLFLVRBPEGVL\\nLFKAKEFKNMEEISK\\nVPSIGLYDLWDIIPR\\nHISQADVLLSAPFKE\\nSTTLRAVLSIVPVT\\nSTTLRAVLSIVPVT2\\nKTRDALQSAGNFNRR\\nKTRDALQSAGNFNRR2\\nQYTIENPYDRIDNHK\\nQYTIENPYDRIDNHK2'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n\\t?dataset a orkgc:Dataset;\\n\\trdfs:label?dataset_lbl.\\n\\tFILTER (str(?dataset_lbl) = \"Venture\")\\n\\t?benchmark orkgp:HAS_DATASET?dataset.\\n\\t?cont orkgp:HAS_BENCHMARK?benchmark.\\n\\t?paper orkgp:P31?cont;\\n\\trdfs:label?paper_lbl.\\n}'}], [{'generated_text': 'Commonly used metrics on the Content Selection benchmark dataset are:\\n- METRIC_MRR - Mean Reciprocal Rank\\n- METRIC_R2 - Pearson correlation coefficient\\n- METRIC_ACL - Accuracy'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Tsetlin Machine\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nI would appreciate the links to the relevant papers.'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Bowling\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'The code for the FQF model can be found at https://github.com/rohit-ali-faruqui/fgfa and https://github.com/rohit-ali-faruqui/fgf, respectively.\\n\\nA list of papers that have utilized the RNN model can be found at https://www.open Jennings.org/models/RNN.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"SequenceError\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"FSNS Test\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ARC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Scirex\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nScirex, P31'}], [{'generated_text': 'The following are commonly used metrics for models on the TSE-NER dataset:\\n- F1 score\\n- Precision @ 1;\\n- Precision @ 5;\\n- Recall @ 1;\\n- Recall @ 5;\\n- $H@10$;\\n- $H@20$;\\n- $H@30$;\\n- $H@40$;\\n- $A$;\\n- $D$;\\n- $C$;\\n- $M$;\\n- $N$;\\n- $P$;\\n- $E$;\\n- $G$;\\n- $A^{2}$;\\n- $D^{2}$;\\n- $C^{2}$;\\n- $M^{2}$;\\n- $N^{2}$;\\n- $P^{2}$;\\n- $E^{2}$;\\n- $G^{2}$;\\n\\nThe following are commonly used metrics for models on the RTE dataset:\\n- Accuracy\\n- R-precision\\n- R-recall\\n- R-f1\\n- F-score\\n- F-measure\\n- Accuracy\\n- R-precision\\n- R-recall\\n- R-f1\\n- F-score\\n- F-measure\\n- Accuracy\\n- R'}], [{'generated_text': 'select distinct?code where \\n?model a orkgc:Model\\nrdfs:label?model_lbl.\\nFILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.\\n?cont orkgp:HAS_BENCHMARK?benchmark.\\n?cont orkgp:HAS_MODEL?model;\\norkgp:HAS_SOURCE_CODE?code.'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"OTF\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {\\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code WHERE {\\n?model a orkgc:Model; \\nrdfs:label?model_lbl. \\nFILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?cont orkgp:HAS_MODEL?model; \\norkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code WHERE {\\n?model a orkgc:Model; \\nrdfs:label?model_l'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Percentage error\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SVHN\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"LayerNorm HM-LSTM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<|endoftext|>Q:\\n\\nDynamically name variables based on conditions in R\\n\\nI have dataframe in R with 4 columns as below:\\nname    city   value\\n1       a      100\\n2       b      200\\n3       c      300\\n4       d      400\\n\\nI want to dynamically name variables based on the first 5 characters of city column using for loop. for example variables should be named as \"city.1\",\"city.2\",\"city.3\",\"city.4\" accordingly. So the final variables should be as follows:\\ncity.1   value\\ncity.2  value\\ncity.3  value\\ncity.4  value\\n\\nThe loop should keep running till the end. What'}], [{'generated_text': 'name of datasets that have been used for benchmarking in the Text Generation research problem\\nGraph Embedding'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Amazon-2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {\\n   ?model a orkgc:Model;\\n    rdfs:label?model_lbl. \\n    FILTER (str(?model_lbl) = \"Temporal Convolutional Network\")\\n   ?benchmark orkgp:HAS_DATASET?dataset.\\n   ?cont orkgp:HAS_BENCHMARK?benchmark.\\n   ?cont orkgp:HAS_MODEL?model;\\n    orkgp:HAS_SOURCE_CODE?code.\\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BiT-S (ResNet)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n     :  \\n     : SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"RNN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n     :'}], [{'generated_text': 'The highest benchmark result achieved on the WNLI dataset, including the metric and its value is {score: 34.0, metric: entailment, metric_lbl: \"WNLI entailment\"}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"AAPD\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'The models that have been evaluated on the HoC dataset include:\\n- BiDAF \\n- eXtreme Deducer (XD) \\n- Knowledge joint model (KJME) \\n- Metaferator'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Percentage error\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CIFAR-10\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WALK\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': \"Common metrics used to evaluate models on the DDI and SciGEN datasets include: R2, ROC, and F1 scores. R2 and F1 are single values that summarize the model's classification accuracy and are commonly used to evaluate binary classification models. ROC is a performance metric used to evaluate binary classification and multiclass models.\"}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Tennis\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nIndicate the model that performed best in terms of Score metric on the Breakout benchmark dataset?\\n\\nSELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FIL'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"UCF101\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MPQA\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The highest benchmark result, including the metric and score, for the Paper Field dataset is:\\n(SUM(?value) AS?score) WHERE { {?dataset a orkgc:Dataset; rdfs:label \"Paper Field\" } }\\n\\nNote: As the result is coming back as an average, it is not possible to get the maximum value.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The highest benchmark result achieved on the Atari 2600 Double Dunk dataset, including the metric and its value is 7.\\nSense-Consensus Directional Perception'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<p><a href=\"https://github.com/sensisa/nlp-benchmarks/tree/master/ensemble/BenchmarkingBiDAF+SelfAttention+ELMo\" style=\"color:blue\" >BenchmarkingBiDAF+SelfAttention+ELMo</a></p>'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a cheetaHR:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DMControl500k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n?dataset a orkgc:Dataset; \\nrdfs:label?dataset_lbl. \\nFILTER (str(?dataset_lbl) = \"GAD\")?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?paper orkgp:P31?cont; \\nrdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ALIEN\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BIRDSNAPP\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cars\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RotoWire\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model in terms of F1 score on the RotoWire dataset was the Glow model (Glow ML).'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SQuAD1.1\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nThere are two evaluation metrics commonly used on the DDI dataset: Accuracy and mAP (Mean Average Precision).'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Large mLSTM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ACL Anthology\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nmodels:\\ndaili:GLAM 3.0'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"YARSR\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ncbi-diseases\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}]]\n","0 0\n","1 0\n","2 0\n","3 0\n","0 4\n","0 8\n","0 12\n","0 13\n","0 18\n","1 18\n","2 18\n","3 18\n","4 18\n","0 22\n","1 22\n","2 22\n","3 22\n","0 24\n","0 27\n","0 34\n","1 34\n","0 36\n","63.63636363636365%  [[{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Softcite\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'The following are the metrics used to evaluate models on the RTE dataset:\\n- Percentage of mistakes made on the validation set\\n- Confusion matrix over the validation set\\n- Recall at different confidence levels\\n- Root Mean Squared Error\\nThe following are the metrics used to evaluate models on the WSC dataset:\\n- Confusion matrix over the validation set\\n- Root Mean Squared Error\\nThe following are the metrics used to evaluate models on the GAD dataset:\\n- Percentage of mistakes made on the validation set\\n- Confusion matrix over the validation set'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"ROUGE-2\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"X-Sum\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': \"Risto Karmila: P31 RotoWire (Relation Generation) Benchmark; http://www.cis.sutd.edu.sg/~cis305/Papers/P31%20RotoWire%20(Relation%20Generation).pdf\\nBryan O'Sullivan: DDI RotoWire (Relation Generation) Benchmark; http://www.cis.sutd.edu.sg/~cis305/Papers/DDI%20RotoWire%20(Relation%20Generation).pdf\\nAli Ghodsi: GAD RotoWire (Relation Generation) Benchmark; https://web.stanford.edu/class/2020/sp15/papers/ghodsi.pdf\\nMatt Thornton: GAD RTE Benchmark; https://web.stanford.edu/class/2020/sp15/papers/thornton.pdf\"}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Fine-Grained Gating\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"NoOp\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MontezumasRevenge\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code \\n WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"VPN\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n }'}], [{'generated_text': 'The model that achieved the highest F1 score on the WMT English-Russian dataset benchmark is the MultilingualgRAM model.'}], [{'generated_text': 'SELECT * FROM \\n  (SELECT distinct?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top-1 Error Rate\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }) as t1'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"RTE\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'The following models have been evaluated on the Penn Treebank dataset:'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"RNN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"ANODE\")?benchmark orkgp:HAS_DAT'}], [{'generated_text': 'SELECT DISTINCT?code \\n  WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nSELECT DISTINCT?code \\n  WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nSELECT DISTINCT?code \\n  WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"RNN\")?benchmark'}], [{'generated_text': 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE {\\n\\n\\t{\\n\\t\\t{\\n\\t\\t\\t{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\"FC77\"@en, 43.142857142857142\\n\\t\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t}\\n\\t}\\n\\n\\t{\\n\\t\\t{\\n\\t\\t\\t{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\"FC77\"@en, 43.142857142857142\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t}\\n\\t}\\n\\n\\t{\\n\\t\\t{\\n\\t\\t\\t{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\"FC77\"@en, 43.142857142857142\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t}\\n\\t}\\n\\n\\t{\\n\\t\\t{\\n\\t\\t\\t{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\"FC77\"@en, 43.142857142857142\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t}\\n\\t}\\n\\n\\t{\\n\\t\\t{\\n\\t\\t\\t{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\"FC77\"@en, 43.'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"MPAD-path\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BoolQ\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n input (English text): What are the models that have been benchmarked on the BoolQ dataset?\\n output (Sparql query): \\n SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BoolQ\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC_GER\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } \\n  GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DMControl100k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Multi-Perspective Matching\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nThis query returns the following result set:\\n+-------------------+\\n| code               |\\n+-------------------+\\n| https://github.com/ |\\n| senza/ensembleCode |\\n+-------------------+'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BitsPerDim\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet64x64\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE {\\n\\n    {\\n\\n    SELECT?metric?metric_lbl?value WHERE {\\n\\n   ?dataset a commonsenseqa:Dataset;\\n\\n    rdfs:label?dataset_lbl.\\n\\n    FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\\n\\n   ?benchmark commonsenseqa:HAS_DATASET?dataset;\\n\\n    commonsenseqa:HAS_EVALUATION?eval.\\n\\n   ?eval commonsenseqa:HAS_VALUE?value.\\n\\n    OPTIONAL {\\n\\n   ?eval commonsenseqa:HAS_METRIC?metric.\\n\\n   ?metric rdfs:label?metric_lbl.\\n\\n    }\\n\\n   ?cont commonsenseqa:HAS_BENCHMARK?benchmark.\\n\\n    OPTIONAL {\\n\\n   ?cont commonsenseqa:HAS_MODEL?model.\\n\\n   ?model rdfs:label?model_lbl.\\n\\n    }\\n\\n    }\\n\\n    ORDER BY DESC(?value)\\n\\n    }\\n\\n    }\\n\\n GROUP BY?metric?metric'}], [{'generated_text': 'sample_size\\n1\\noutput (English text):'}], [{'generated_text': 'The highest benchmark result achieved on the CoQA dataset, including the metric and its value is 80.5048:'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n    { SELECT?metric?metric_lbl?value WHERE { \\n           ?dataset a imagenet:Dataset; \\n            rdfs:label?dataset_lbl. \\n            FILTER (str(?dataset_lbl) = \"V2\")?benchmark imagenet:HAS_DATASET?dataset;\\n            imagenet:HAS_EVALUATION?eval.\\n           ?eval imagenet:HAS_VALUE?value. \\n            OPTIONAL {?eval imagenet:HAS_METRIC?metric.\\n                   ?metric imagenet:LABEL?metric_lbl. \\n            } \\n           ?cont imagenet:HAS_BENCHMARK?benchmark. \\n            OPTIONAL {?cont imagenet:HAS_MODEL?model.\\n                   ?model imagenet:LABEL?model_lbl. \\n            } \\n        } \\n        ORDER BY DESC(?value) } \\n    } \\n    GROUP BY?metric?metric_lbl\\n}\\n\\nResults:\\n-----------------------------------------\\nmetric'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl500k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': \"The metrics that are commonly used when benchmarking models on the DDI dataset include:\\n-AUC\\n-Brier Score\\n-Coverage\\n-Mean Squared Error\\n-Pearson Correlation Coefficient\\n-ROC Curve\\n-Sklearn's Stratified Shuffle and Confusion Matrix\\n-Snign of Optimal Prediction\"}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PISA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'The most commonly used metrics for evaluating DNN models are:\\n- RMSE: Root Mean Square Error (also known as mean squared error, MSE) \\n- R2: The coefficient of determination, or the squared correlation coefficient, which is equivalent to the coefficient of determination\\n- PRR: Precision-Recall Curve, also known as the F1 measure\\n- Logloss: The log of the probability of correct prediction (inverse of log( Sensitivity + 1 ) )'}], [{'generated_text': 'SELECT MAX(value) AS metric_lbl, MAX(value) AS score WHERE {\\n    {\\n        SELECT metric AS metric_lbl, value AS score \\n        WHERE { \\n            dataset a orkgc:Dataset; \\n            rdfs:label dataset_lbl; \\n            FILTER (str(dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\\n        }\\n        OPTIONAL {\\n            eval orkgp:HAS_METRIC metric;\\n            cont orkgp:HAS_BENCHMARK benchmark;\\n            model model:Model {\\n                model:Name {\\n                    model:value \"ModelName\";\\n                }\\n            }\\n        }\\n    }\\n    ORDER BY score DESC\\n} GROUP BY metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'NAME\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--\\n--'}], [{'generated_text': 'Common evaluation metrics for content-order optimization are JLE, EICE, NDCG,  NDCG-SU4, ClickThroughRate (CTR).'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code \\n WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE { \\n ?dataset a medsts:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"MedSTS\") \\n ?benchmark medsts:HAS_DATASET?dataset; \\n ?benchmark medsts:HAS_EVALUATION?eval; \\n ?paper medsts:HAS_BENCHMARK?benchmark; \\n  OPTIONAL {?paper medsts:HAS_MODEL?model;?model rdfs:label?model_lbl } \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoNLL++\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"UCF101\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): List the title and ID of research papers that contain a benchmark over the CASIA dataset?\\noutput (Sparql query): SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CASIA\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\ninput (English text): List the title and ID of research papers that contain a'}], [{'generated_text': 'The titles and IDs of research papers that include a benchmark for the GAD dataset are:\\n\\nP31 GAD Benchmark \\nP31 DDI Benchmark \\nP31 RTE Benchmark'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"ImageNet+iNat\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\ninput (English text): Can you provide links to code used in papers that benchmark the RNN model?\\n\\noutput (Sparql query): \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"RNN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\n\\ninput (English text): Can you provide links to code used in papers that benchmark the'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"ROUGE-1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"AESLC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a model; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ModelNet40\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'The following metrics are used to evaluate models on the GAD benchmark dataset: perplexity, F1, RTE RM, WSC RM, NRC. The metrics used to evaluate models on the DDI dataset are: BLEU, RTE RM, NRC, WSC RM.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Reuters-21578\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Seaquest\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SEEL\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\noutput\\n{\\n  \"metric\" : {\\n    \"prediction\" : {\\n      \"auc\" : 0.974296,\\n      \"f1_ score\" : 0.977464\\n    }\\n  },\\n  \"metric_lbl\" : \"SEEL\"\\n}'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n  or'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ATARI2600HERO\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\n\\nCommon evaluation metrics used on the DDI and ATARI2600HERO datasets include:\\n\\n- Binary Accuracy (Accuracy of a model predicting a correct binary label)\\n- F1 Score (Composite measure of Precision and Recall that is typically used to evaluate classifiers or regression models)\\n- Log Loss (another metric used to evaluate binary classification models, this metric tends to be domain specific and is usually expressed in logs, where a higher value of Log Loss indicates a better model for the classification problem at hand)'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Amazon-2\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}]]\n","0 1\n","0 3\n","1 3\n","2 3\n","0 7\n","0 10\n","0 21\n","0 22\n","0 25\n","0 28\n","1 28\n","0 31\n","1 31\n","2 31\n","3 31\n","0 32\n","0 38\n","0 43\n","1 43\n","72.72727272727273%  [[{'generated_text': 'Select distinct?code where \\n{\\n ?model a orkgc:Model\\n  rdfs:label?model_lbl\\n  FILTER (str(?model_lbl) = \"CGU\")\\n ?benchmark orkgp:HAS_DATASET?dataset\\n ?cont orkgp:HAS_BENCHMARK?benchmark\\n ?cont orkgp:HAS_MODEL?model\\n ?cont orkgp:HAS_SOURCE_CODE?code\\n}'}], [{'generated_text': 'The best performing model in terms of accuracy (high) score when benchmarked on the RACE dataset is the model named \"DeepCQNGram\".'}], [{'generated_text': 'The titles and IDs of research papers that include a benchmark for the GAD dataset are: \\nP31 HAS_DATASET GAD \\nP31 HAS_BENCHMARK GAD \\nP31 HAS_DATASET DDI \\nP31 HAS_BENCHMARK DDI \\nP31 HAS_DATASET RTE \\nP31 HAS_BENCHMARK RTE \\nP31 HAS_DATASET DTD'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MUTAG\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\noutput:\\nRTE:HAS_DATASET,ROUTE_TIME,ROUTE_COUNT,NUM_TRACERS,NUM_FAILED_TRACERS,ALTERNATIVE_TRACER_COUNT,ALTERNATIVE_TRACER_TIME,ALTERNATIVE_TRACER_ERRORS,RESULT_CODE,RESULT_MESSAGE,KIND,DATASET_NAME,PREDICTED_ROUTE_TIME\\nWSC:HAS_DATASET,WSC_ROUTE_TIME,WSC_ROUTE_COUNT,NUM_TRACERS,NUM_FAILED_TRACERS,AL'}], [{'generated_text': 'The following metrics are commonly used when benchmarking models on the RTE dataset:\\n- rmse\\n- roc_auc\\n- f1_measure'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SQuAD1.1-dev\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'select distinct?model?model_lbl where {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HoC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RotoWire\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a atari:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Seaquest\")?benchmark atari:HAS_DATASET?dataset; atari:HAS_EVALUATION?eval.?eval atari:HAS_VALUE?value. OPTIONAL {?eval atari:HAS_METRIC?metric.?metric atari:LABEL?metric_lbl. }?cont atari:HAS_BENCHMARK?benchmark. OPTIONAL {?cont atari:HAS_MODEL?model.?model atari:LABEL?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GENIA - LAS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"YelpBinary\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'Indicate the model that performed best in terms of Accuracy metric on the Amazon benchmark dataset?\\n{\\n  \"result\":\"SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Amazon\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }\"}'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Bank Heist\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"A2\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Anli\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nBest performing model benchmarking the DuIE dataset in terms of F1 metric is  {SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"QNLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Asterix\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nA:\\n\\n1.GAD and DDI Datasets\\nBoth of the datasets you mentioned can be accessed through OGC\\'s OpenGIS Data Model (OGR) and are available on download pages. The GAD dataset contains gis features, and the DDI dataset contains statistical data.\\nFrom the datasets page, the titles of the datasets along with their IDs are:\\n\\nGAD: https://www.opengeospatial.org/standards/gad\\nDTD: https://www.opengeospatial.org/standards/dtd\\nRTE: https://www.opengeospatial.org/standards/rte\\n\\n2.Research Papers with Benchmarks on GAD and D'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"MFEC\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {\\n\\n ?model a orkgc:Model;\\n\\n ?model_lbl wcxid:CodeSystem;\\n\\n  rdfs:label?model_lbl ;\\n\\n  FILTER (str(?model_lbl) = \"VPN\")\\n\\n ?benchmark orkgp:HAS_DATASET?dataset.\\n\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n\\n ?cont orkgp:HAS_MODEL?model;\\n\\n ?model orkgp:HAS_SOURCE_CODE?code.\\n\\n}'}], [{'generated_text': 'rdfs:label \"re17.zip\"\\nrdfs:label \"seel.cse.lsu.edu/data/re17.zip\"\\nrdfs:label \"re17\"'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Montezuma\\'s Revenge\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Params\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet_ReaL\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"ResNet-152 (SAM)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The highest benchmark result achieved on the WSC dataset, including the metric and its value is?score=23.75'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl \\n    WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. \\n     FILTER (str(?dataset_lbl) = \"Walker\")?benchmark orkgp:HAS_DATASET?dataset. \\n    ?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; \\n     rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"REDDIT-B\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Softcite\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl \\n    WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SST-2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HEND\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"KD-LSTMreg\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<|endoftext|>require(\\'../../modules/es6.math.log1p\\');\\nmodule.exports = require(\\'../../modules/$.core\\').Math.log1p;<|endoftext|>The present invention relates to information recording media for recording and reproducing information such as an optical information recording medium, and more particularly to a tracking control device for an optical information recording medium.\\nOptical information recording media include an optical disk and an optical card, and the optical disk is represented by a compact disk (CD), a digital video disk (DVD), a video disk (BD), and a hard disk (HD). The tracking control is an important technique for recording and reproducing information of these optical information recording media. The tracking control is carried out based on a push-pull signal'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?paper orkgp:P31?cont; \\n    rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a clueweb09-b:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CLUEWEB09-B\")?benchmark clueweb09-b:HAS_DATASET?dataset; clueweb09-b:HAS_EVALUATION?eval.?paper clueweb09-b:HAS_BENCHMARK?benchmark. OPTIONAL {?paper clueweb09-b:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'The metrics commonly used on the DDI dataset are:\\n- CIDEr (created by the KBs team at Databricks) - https://github.com/keras-team/keras/blob/master/ losses.py#L95-L101\\n- METEOR (created by the KBs team at Databricks) - https://github.com/keras-team/keras/blob/master/ losses.py#L87-L89\\n- SPICE (created by the KBs team at Databricks) - https://github.com/keras-team/keras/blob/master/ losses.py#L106-L107'}], [{'generated_text': 'SELECT DISTINCT?code \\nWHERE { \\n\\t?model a orkgc:Model \\n\\trdfs:label?model_lbl. \\n\\tFILTER (str(?model_lbl) = \"VPN\") \\n\\t?benchmark orkgp:HAS_DATASET?dataset. \\n\\t?cont orkgp:HAS_BENCHMARK?benchmark. \\n\\t?cont orkgp:HAS_MODEL?model;\\n\\torkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code \\nWHERE { \\n\\t?model a orkgc:Model \\n\\trdfs:label?model_lbl. \\n\\tFILTER (str(?model_lbl) = \"CGU\") \\n\\t?benchmark orkgp:HAS_DATASET?dataset. \\n\\t?cont orkgp:HAS_BENCHMARK?benchmark. \\n\\t?cont orkgp:HAS_MODEL?model;\\n\\torkgp:HAS_SOURCE_CODE?code. \\n} \\n\\nSELECT DISTINCT?code \\nWHERE { \\n\\t?model a orkgc:Model'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"FG-FG\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT \\n DISTINCT \\n?metric \\n?metric_lbl (MAX(?value) AS?score) \\n WHERE { \\n SELECT \\n?metric \\n?metric_lbl \\n?value \\n WHERE \\n { \\n?dataset a orkgc:Dataset; \\n rdfs:label?dataset_lbl. \\n FILTER (str(?dataset_lbl) = \"NYT\") \\n orkgp:HAS_DATASET?dataset; \\n orkgp:HAS_EVALUATION?eval. \\n?eval orkgp:HAS_VALUE?value. \\n OPTIONAL \\n {?eval orkgp:HAS_METRIC?metric. \\n?metric rdfs:label?metric_lbl. \\n } \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n OPTIONAL \\n {?cont orkgp:HAS_MODEL?model. \\n?model rdfs:label?model_lbl. \\n } \\n } \\n ORDER BY DESC(?value) \\n } \\n GROUP BY \\n?metric \\n?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"QNLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"QNLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciERC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'Common metrics used to evaluate models on the GAD benchmark dataset are the following: \\n\\n- R2:  It is the coefficient of determination which is also known as the coefficient of variation. It is a statistic that measures the fit of a population forecast to an individual one. The higher the value, the better the model. It is reported for multiple repetitions and is usually expressed as a percentage.\\n- AUROC:  It is also called the area under the receiver operator characteristics curve. It is another statistic that measures the performance of a model. The closer the value is to 1.0, the better the model. It is reported for multiple repetitions and is usually expressed as a percentage.\\n- F1 score:  It is also known as the F measure. It is another model performance metric. It is computed by first calculating the harmonic mean of the precision and the recall. The closer the value is to 1.0, the better the model. It is reported for multiple repetitions and is usually expressed as a percentage.'}], [{'generated_text': 'The highest benchmark result, including the metric and score, for the Natural Questions (long) dataset is \\n\\nThe longest words'}], [{'generated_text': 'SELECT \\n    MAX(value)\\n    metric\\n    metric_lbl\\n    score\\nFROM\\n    (\\n    SELECT \\n       ?metric?metric_lbl (MAX(?value) AS?score) \\n    WHERE \\n        { \\n            { \\n                SELECT?metric?metric_lbl?value \\n                WHERE \\n                    { \\n                       ?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. \\n                        FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. \\n                        OPTIONAL { \\n                           ?eval orkgp:HAS_METRIC?metric. \\n                           ?metric rdfs:label?metric_lbl. \\n                        } \\n                       ?cont orkgp:HAS_BENCHMARK?benchmark. \\n                        OPTIONAL { \\n                           ?cont orkgp:HAS_MODEL?model. \\n                           ?model rdfs:label?model_lbl. \\n                        }'}], [{'generated_text': 'SELECT?graph?graph_label WHERE { \\n ?paper orkgp:P31?cont; \\n  rdfs:label?title. \\n  FILTER(REGEX(?title, \"ADANA\"))?cont orkgp:P5008?graph. \\n ?graph rdfs:label?graph_label. \\n}'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n?dataset a orkgc:Dataset;\\n rdfs:label?dataset_lbl. \\n FILTER (str(?dataset_lbl) = \"KINETICS-600\")?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont;\\n rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DTD\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nSELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RTE\")'}], [{'generated_text': '@prefix :      <http://example.com/ns#>.\\n@prefix rs :  <http://www.w3.org/2009/sparql-services/results-service#>.\\n\\n:  : a       rs:Query  ;\\n    rs:description \"What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request?\";\\n    rs:results *;\\n    rs:solution *;\\n    rs:statusCODE  200;\\n    rs:statusMESSAGE \"200 OK\";\\n\\n\\nSELECT?term\\n        (CONCATENATE(LIST_CONCAT(\\', \\',?term, \\', \\',?value))\\n        WHERE {\\n               ?term  a   rs:Query ;\\n                        rs:description \"What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request?\" ;\\n                       ?term a rs:QueryResults;\\n                       ?value  a  rs:Dataset}\\n        ORDER BY?'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DMLAB-30\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"WMT2016DE\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'The highest benchmark result achieved on the Cartpole dataset, including the metric and its value, is 7.27.'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Medline\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"LSTM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nLSTM code:\\nhttps://github.com/BaiJianLi/bai_lstm_model_2018_code/blob/master/lstm_code/train_lstm.py\\nTH\\nBai, Jian-Wei and Xiao-Jie Pan and Xiao-Ping Jin. \"An A-Star Approach to Reinforcement Learning for Multi-Armed Bandit Problems.\" 2018. https://github.com/BaiJianLi/bai_lstm_model_2018_code/blob/master/lstm_code/train_lstm.py'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}]]\n","0 0\n","0 1\n","0 2\n","0 4\n","0 6\n","0 18\n","1 18\n","2 18\n","3 18\n","4 18\n","0 22\n","0 31\n","0 37\n","1 37\n","2 37\n","0 38\n","0 46\n","1 46\n","2 46\n","3 46\n","81.81818181818183%  [[{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"XLNet-Large\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"EfficientNetV2-L\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n   ?dataset a orkgc:Dataset;\\n    rdfs:label?dataset_lbl.\\n    FILTER (str(?dataset_lbl) = \"WOS-46985\")\\n   ?benchmark orkgp:HAS_DATASET?dataset.\\n   ?cont orkgp:HAS_BENCHMARK?benchmark.\\n   ?paper orkgp:P31?cont;\\n    rdfs:label?paper_lbl.\\n}'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Supervised: \")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"A3\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ANLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'Following metrics are used to evaluate models on the DDI dataset:\\n- Accuracy (also known as loss or MSE)\\n- F1 score\\n- Area Under the Curve (AUC)\\n- Log loss\\n- Root Mean Square Error (RMSE)\\n- Spearman’s rank correlation coefficient\\n- Hazard ratio\\n\\nFollowing metrics are used to evaluate models on the GAD benchmark dataset:\\n- Accuracy (also known as loss or MSE)\\n- F1 score\\n- AUC\\n- RMSE\\n- Spearman’s rank correlation coefficient\\n- Hazard ratio'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a bleu:BLEU; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a bleu:LanguageModel; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT14\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cart Pole\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"VPN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"CGU\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BiDAF + Self Attention + ELMo\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nCode references that could be used for benchmarking the BiDAF + Self Attention + ELMo model can be found here:\\n\\nhttps://github.com/google-research/bert/blob/master/examples/quickstart_ranker.lua'}], [{'generated_text': \"The common metrics used to evaluate models on the DDI dataset are:\\n- Pearson's correlation coefficient\\n- Spearman's rank correlation coefficient\\n- Root mean square error (RMSE)\\n- Log loss\\n- Area under the receiver operating characteristic (ROC) curve\"}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"6-layer QRNN\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WOS-11967\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl \\n  WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NYT24\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'Name the datasets that have been used for benchmarking in the Text Generation research field: \\nGraph Embedding\\nMovie Review dataset\\nImageCLEF Medical dataset\\nSynth50\\nArtificial Intelligence for Machine Vision (AIMV)\\nWeatherTV Dataset'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a seel.cse.lsu.edu:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"refsq17.zip\")?benchmark seel.cse.lsu.edu:HAS_BENCHMARK?benchmark. OPTIONAL {?paper seel.cse.lsu.edu:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nModel           Model_lbl\\n------------------ ------------\\nRefine model    Refine model\\nGenetic model  Genetic model\\nAugmented model Augmented model'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"IMDb-M\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }\\n\\nResults:\\n+-------------+-----------------------+\\n|?model       |?model_lbl             |\\n+=============+=======================+\\n| YoutubeBase  | YoutubeBase           |\\n| YoutubeTS   | YoutubeTS             |\\n| ImdbModel   | ImdbModel             |\\n| ImdbTS      | ImdbTS                 |\\n| Flower104  | Flower104             |\\n| Flower103  | Flower103             |\\n| Imdb120     | Imdb120               |\\n| Flower122   | Flower122             |\\n| Imdb124     | Imdb'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"PEGASUS\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Audio Classification\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. } \\n\\nThe most commonly used benchmark datasets for the Text Generation research field are:\\n\\n* MovieLens-QLD\\n* Twoloop\\n* Megaface\\n* WeChatMessageStone\\n* MS dinner\\n* PubTator\\n\\nName the datasets that have been used for benchmarking in the Graph Embedding research problem:\\n\\n* PubTator\\n* WeChatMessageStone\\n* MS dinner\\n* Megaface\\n* MovieLens-QLD\\n* Twoloop'}], [{'generated_text': 'The highest benchmark result, including the metric and score, for the Cart Pole (OpenAI Gym) dataset is'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DMControl100k\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\ninput (English text): Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RTE dataset?\\n\\noutput (Sparql query):'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'The top benchmark result, including the metric and score, for the ACE 2005 dataset is:\\n3889.904349383865\\nThe metric is \"Query evaluation time in milliseconds\". The score is \"3889.904349383865\".'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DBpedia\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nList the metrics that are commonly used when benchmarking models on the DDI dataset.\\n\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DDI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nList the metrics that are commonly used when benchmarking models on the DB'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari_2600_Enduro\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HutterPrize\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'The highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/re17.zip dataset is:\\n(30544.6752779999997,20)'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WOW\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Transformer-XL\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Up and Down\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT?model?model_lbl WHERE {\\n\\t?dataset a orkgc:Dataset;\\n\\trdfs:label?dataset_lbl.\\n\\tFILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")?benchmark orkgp:HAS_DATASET?dataset;\\n\\torkgp:HAS_EVALUATION?eval.\\n\\t?paper orkgp:HAS_BENCHMARK?benchmark.\\n\\tOPTIONAL {?paper orkgp:HAS_MODEL?model.\\n\\t\\t?model rdfs:label?model_lbl.\\n\\t }\\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Jacquard\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ObjectNet\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'P31 de Bled - Benchmarking eNwik8 models for semantic role labeling, SemEval 2019, <https://doi.org/10.18653/v1/SPARQL-TR-2019-02>'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"PARAMS\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"FGVC_Aircraft\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Battle Zone\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Battle Zone\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Boxing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Bi+\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'The following are the models being benchmarked on the AESLC dataset:\\n\\n- adaptive deep learning\\n- adfnet\\n- asgprt\\n- bigml\\n- char\\n- chews\\n- daham\\n- drilldown\\n- gymml\\n- mkdirnlp\\n- mlm\\n- mgmtres\\n- nilearn\\n- openml\\n- spaARM\\n- spaConcept\\n- spaDecisionTree'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"HoC\")?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"PAR Transformer Large\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BERTwwm + SQuAD 2\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n<|endoftext|>The present invention relates to a fastening device and, more particularly, to a fastening device with an elongate body for insertion into a receiving opening in a support structure and at least two arcing heads arranged at both ends of the body, wherein the arcing heads include at least one contact element which can snap into a contact surface at the receiving opening, and a spring element which urges the contact elements in the direction away from each other.\\nFastening devices of this general type are used, for example, as retaining devices in the framework of a motor vehicle. The fastening device has an elongate body and at least two arcing heads arranged at both ends of the body, the arcing heads including at least one contact'}], [{'generated_text': 'select distinct?code where \\n{ \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"CL-Titles-Parser\")\\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code.\\n}'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\noutput\\nmodel\\tmodel_lbl\\n-----------------\\nModelNet-base-2018\\tModelNet-base-2018\\nOCV-Model-2017\\t\\tSemanticCommons-semantic-lingo\\tSemanticCommons-semantic-lingo\\nORB-SLAM2\\t\\t\\tORB-SLAM2\\t\\t\\t\\nORB-SLAM2\\t\\t\\tSemanticCommons-semantic-lingo\\tSemanticCommons-semantic-lingo\\nORB-SLAM2\\t\\t\\tFAN-U-REAL\\t\\t\\nKinectTF'}], [{'generated_text': 'Ianni\\nAtari 2600\\nNeural Network\\nNeural Network (Lateral)\\nNeural Network (Self Organizing Map)\\nNeural Network (Radial Basis Function)\\nNeural Network (Multilayer Perceptron)\\nSupport Vector Machine\\nSupport Vector Machine (Radial Basis Function)\\nSupport Vector Machine (K-Nearest Neighbors)'}], [{'generated_text': 'The highest score achieved on the Atari 2600 Freeway dataset, including the metric and its value is 27.405722.'}]]\n","0 5\n","0 11\n","0 15\n","1 15\n","2 15\n","3 15\n","4 15\n","0 20\n","1 20\n","2 20\n","3 20\n","4 20\n","0 23\n","0 27\n","1 27\n","0 34\n","0 42\n","1 42\n","2 42\n","0 46\n","0 48\n","0 49\n","90.90909090909092%  [[{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 River Raid\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n input (English text): The models that have been tested on the Atari 2600 River Raid benchmark dataset are Pong, Space Invaders, Breakout, Tempest, Missile, Asterix, Donkey Kong, Mario, Balloon Flight, E.T, Sherlock Holmes, Super Mario Land, Food Fight, Galaxian, Breakout Extend, Tetris.'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"AlexNet\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"MultiGrasp\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\n# HELPER #\\n def findCodeReferences(self,model):\\n    return self.executeQuery(\"\"\"\\n    SELECT DISTINCT?code \\n    WHERE {?model a orkgc:Model; rdfs:label?model_'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600MsPcMan\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet64x64\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNetCipher32\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\nSELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_'}], [{'generated_text': 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DBpedia\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"HRLRE\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nThe following papers have utilized the HRLRE model:\\n- \"Multiple Classifier Trick: A Re-Vision for Big Data Classification\"\\n- \"Ensemble Learning with Heterogeneous Record Embeddings\"\\n- \"A Hierarchical Softmax Approach for Large-Scale Multi-Label Classification\"\\n- \"Hierarchical Ranknet: Learning Ranking Models from Explicit SocialRanking Data\"\\n- \"Improving Neural Network-Based Classifiers with Meta Learning\"'}], [{'generated_text': 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"T-ConvS2S\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }'}], [{'generated_text': 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari2600Q*Bert\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }'}], [{'generated_text': 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WIC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}], [{'generated_text': 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Common Sense Reasoning\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. }\\n\\nname=GraphsDataset\\ndataset_lbl=Graph Embedding\\ndataset=omoplot\\ncont=omoplot\\nbenchmark=omoplot\\nproblem=omoplot'}], [{'generated_text': 'top-5\\nTRANSLATION: SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ACE 2004\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl'}]]\n"]}],"source":["import torch\n","import json\n","from transformers import pipeline, AutoTokenizer\n","from datasets import load_dataset\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", padding_side=\"left\")\n","\n","dolly = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n","raw_datasets = load_dataset(\"orkg/SciQA\")\n","print(raw_datasets)\n","\n","\n","def divide_chunks(l_, n_):\n","    for i_ in range(0, len(l_), n_):\n","        yield l_[i_:i_ + n_]\n","\n","\n","def clean(st):\n","    st = st.replace(\"\\n\", \" \")\n","    st = st.replace(\"?\", \" ?\")\n","    st = st.replace(\"{\", \" { \")\n","    st = st.replace(\"}\", \" } \")\n","    st = st.replace(\"\\\\'\", \"'\")\n","\n","    while \"  \" in st:\n","        st = st.replace(\"  \", \" \")\n","    return st\n","\n","\n","def get_key(q):\n","    t0 = q.get('template_id')\n","    if t0 is None:\n","        t0 = \"None\"\n","    t = str(q.get(\"number_of_patterns\")) + \"-\" + t0\n","    return t\n","\n","\n","def get_keys(n_):\n","    train = raw_datasets.get(\"train\")\n","    patterns = {}\n","    for q in train:\n","        t = get_key(q)\n","        query = clean(q[\"query\"][\"sparql\"])\n","        question = q[\"question\"][\"string\"]\n","        if t not in patterns:\n","            patterns[t] = [[query, question, len(query)]]\n","        else:\n","            patterns[t].append([query, question, len(query)])\n","\n","    for t in patterns:\n","        code = patterns.get(t)\n","        code = sorted(code, key=lambda x: x[2], reverse=False)\n","        patterns[t] = code[:n_]\n","    return patterns\n","\n","\n","def prepare_queries(n_):\n","    keys = get_keys(n_)\n","    data = raw_datasets.get(\"test\")\n","    queries = []\n","    for q in data:\n","        t = get_key(q)\n","        question = q[\"question\"][\"string\"]\n","        suggestion = keys.get(t)\n","        if suggestion is None:\n","            print(\"Error with key\", t)\n","            queries.append(\"translate the following English text '\" + question + \"' to a sparql query\")\n","        else:\n","            final_q = \"\"\n","            for i_, k in enumerate(suggestion):\n","                final_q += \"\\n input (English text): \" + k[1]\n","                final_q += \"\\n output (Sparql query): \" + k[0]\n","            # works better with gpt\n","            # final_q += \"\\n with this example what is the sparql query for:  \" + question\n","\n","            # works better with dolly\n","            final_q += \"\\n input (English text): \" + question\n","            final_q += \"\\n output (Sparql query): \"\n","\n","            queries.append(final_q)\n","    return queries\n","\n","\n","def save_json(filename,data):\n","    with open(filename, \"w\", encoding=\"utf-8\") as json_file:\n","        print(json.dumps(data), file=json_file)\n","\n","\n","shots = 4\n","query_list = prepare_queries(shots)\n","\n","print(len(query_list))\n","\n","n = 50\n","q_list = list(divide_chunks(query_list, n))\n","sparql = [clean(x[\"query\"][\"sparql\"]) for x in raw_datasets.get(\"test\")]\n","\n","gs = []\n","lens =[]\n","\n","i = 0\n","\n","for group in q_list:\n","    print(str(i) + \"%\", end=\"  \")\n","    i += 1/len(q_list)*100\n","\n","    res_ = [tokenizer.encode(question) for question in group]\n","    len_ = [len(x) for x in res_]\n","    warning = [x for x in len_ if x > 2048]\n","    if len(warning)>0:\n","      quit()\n","    lens += len_\n","\n","    res = dolly(group)\n","    print(res)\n","    gst = [x[0][\"generated_text\"] for x in res]\n","\n","    for ii, l in enumerate(gst):\n","        for iii in range(5):\n","            if \"SELECT\" not in l:\n","                print(iii,ii)\n","                res = dolly(group[ii])\n","                gst[ii] = res[0][\"generated_text\"]\n","                l = gst[ii]\n","            else:\n","                break\n","    gs += gst\n","\n","    result = {\"questions\": query_list, \"sparql\": sparql, \"generated_sparql\": gs, \"prompt_len\": lens}\n","    save_json(\"dolly_\"+str(shots)+\"_shot_results_tok.json\", result)\n","    # break\n","\n"]}]}
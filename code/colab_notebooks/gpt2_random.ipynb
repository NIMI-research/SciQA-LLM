{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOzYHeGUh/tB8XCpFr/2IdY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AUD3o-8_iIJz"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets\n","# !pip install sentence_transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/en2sparql"],"metadata":{"id":"s8zd95ShibCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import torch\n","import random\n","from datasets import load_dataset\n","from transformers import pipeline, AutoTokenizer\n","raw_datasets = load_dataset(\"orkg/SciQA\")\n","print(raw_datasets)"],"metadata":{"id":"knMYQ5H_inE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt2 = pipeline(model=\"gpt2-large\", max_new_tokens=384, device='cuda' if torch.cuda.is_available() else \"cpu\", return_full_text=False)\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\")"],"metadata":{"id":"dPxwtwxEixoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_json(filename,data):\n","    with open(filename, \"w\", encoding=\"utf-8\") as json_file:\n","        print(json.dumps(data), file=json_file)\n","\n","\n","def load_json(file__name):\n","    try:\n","        data_file = open(file__name, \"r\", encoding='utf-8')\n","        file_data = json.loads(data_file.read())\n","        data_file.close()\n","        return file_data\n","    except FileNotFoundError:\n","        return None\n","\n","\n","def clean(st):\n","    st = st.replace(\"\\n\", \" \")\n","    st = st.replace(\"?\", \" ?\")\n","    st = st.replace(\"{\", \" { \")\n","    st = st.replace(\"}\", \" } \")\n","    st = st.replace(\"\\\\'\", \"'\")\n","\n","    while \"  \" in st:\n","        st = st.replace(\"  \", \" \")\n","    return st\n","\n","\n","def get_key(q):\n","    t0 = q.get('template_id')\n","    if t0 is None:\n","        t0 = \"None\"\n","    t = str(q.get(\"number_of_patterns\")) + \"-\" + t0\n","    return t\n","\n","\n","def get_random(n_):\n","    train = raw_datasets.get(\"train\")\n","    sample = random.sample(list(train), n_)\n","    sample_list = []\n","    for q in sample:\n","        t = get_key(q)\n","        query = clean(q[\"query\"][\"sparql\"])\n","        question = q[\"question\"][\"string\"]\n","        sample_list.append([query, question, t])\n","    return sample_list\n","\n","\n","def prepare_queries(n_):\n","    data = raw_datasets.get(\"test\")\n","    queries = []\n","    suggestions = []\n","    for q in data:\n","        t = get_key(q)\n","        question = q[\"question\"][\"string\"]\n","\n","        if n_ == 0:\n","            queries.append(question)\n","            suggestions.append(t)\n","        else:\n","\n","            suggestion = get_random(n_)\n","            suggestions.append([[x[2] for x in suggestion], t])\n","            # print(suggestion, t)\n","            # break\n","\n","            if suggestion is None or len(suggestion) == 0:\n","                print(\"Error with key\", t)\n","                queries.append(\"translate the following English text '\" + question + \"' to a sparql query\")\n","            else:\n","                final_q = \"\"\n","                for i_, k in enumerate(suggestion):\n","\n","                    # works better with fine-tuned gpt2?\n","                    # final_q += \"<|endoftext|>\" + k[1] + \" \"\n","                    # final_q += k[0]\n","\n","                    # works better with dolly\n","                    final_q += \"\\n input (English text): \" + k[1]\n","                    final_q += \"\\n output (Sparql query): \" + k[0]\n","\n","                # works better with gpt\n","                # final_q += \"\\n with this example what is the sparql query for:  \" + question\n","\n","                # works better with gpt2?\n","                # final_q += \"<|endoftext|>\" + question\n","\n","                # works better with dolly\n","                final_q += \"\\n input (English text): \" + question\n","                final_q += \"\\n output (Sparql query): \"\n","\n","                queries.append(final_q)\n","\n","    return queries, suggestions\n","\n","\n","def main(shots=3, attempts=1):\n","    data = load_json(\"random_gpt2_large_\" + str(shots) + \"_shots.json\")\n","    print(data)\n","    if data is None:\n","        query_list, suggestions = prepare_queries(shots)\n","        gs = []\n","        lens = []\n","    else:\n","        query_list = data[\"questions\"]\n","        suggestions = data[\"suggestions\"]\n","        gs = data[\"generated_sparql\"]\n","        lens = data[\"prompt_len\"]\n","\n","    print(len(query_list))\n","\n","    q_list = query_list\n","    sparql = [clean(x[\"query\"][\"sparql\"]) for x in raw_datasets.get(\"test\")]\n","\n","    for question in q_list[len(gs):]:\n","        print(question)\n","        res_ = tokenizer.encode(question)\n","        len_ = len(res_)\n","        lens.append(len_)\n","        print(len_)\n","        if len_ > 600:\n","            print(type(res_))\n","            question = tokenizer.decode(res_[-600:])\n","            print (type(question))\n","            len_ = 600\n","\n","        if len_ <= 600:\n","            res = gpt2(question)\n","            # if \"SELECT\" not in res[0][\"generated_text\"]:\n","            #     for i in range(attempts-1):\n","            #         res = gpt2(question)\n","            #         if \"SELECT\" in res[0][\"generated_text\"]:\n","            #             break\n","            gs.append(res[0][\"generated_text\"])\n","            result = {\"questions\": query_list, \"sparql\": sparql, \"generated_sparql\": gs, \"prompt_len\": lens,\n","                      \"suggestions\": suggestions}\n","            save_json(\"random_gpt2_large_\" + str(shots) + \"_shots.json\", result)\n","\n","main()"],"metadata":{"id":"3frmiuILjNGv"},"execution_count":null,"outputs":[]}]}
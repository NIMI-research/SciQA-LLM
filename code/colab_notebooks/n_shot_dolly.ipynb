{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPfh+KyQC4dHQWgeZ4wje3M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"31f3287cd14c41f380a724e9edd71c54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a76086240098463fb0f15e5e004264d8","IPY_MODEL_1c910a64d7f840a596aacb93940c5e7c","IPY_MODEL_627bbbdb5a5f45109b8057f999d2d639"],"layout":"IPY_MODEL_e44ac058260e43d9a649c71328c84ae0"}},"a76086240098463fb0f15e5e004264d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be59116727104e72b76426184c979a90","placeholder":"​","style":"IPY_MODEL_9ce493e523f548d88644814d842dc79e","value":"Downloading (…)okenizer_config.json: 100%"}},"1c910a64d7f840a596aacb93940c5e7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4cca2ad4184321abb60e849b07a7ce","max":450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5b43d2a09b04d79a1df6cb9e6cc8976","value":450}},"627bbbdb5a5f45109b8057f999d2d639":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e60b81a2d7b42a3bb234901e7218d59","placeholder":"​","style":"IPY_MODEL_132c5e563d574e1a8509970a06864f8f","value":" 450/450 [00:00&lt;00:00, 19.1kB/s]"}},"e44ac058260e43d9a649c71328c84ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be59116727104e72b76426184c979a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce493e523f548d88644814d842dc79e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be4cca2ad4184321abb60e849b07a7ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5b43d2a09b04d79a1df6cb9e6cc8976":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e60b81a2d7b42a3bb234901e7218d59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"132c5e563d574e1a8509970a06864f8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0c659a3048a4f2bb55c72e702a2af5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1dc45a681488400c85d5ad30f9426671","IPY_MODEL_4937fbc2956844ca9b144f67f779dd24","IPY_MODEL_b6ef24f2430b4a089234efb40109b823"],"layout":"IPY_MODEL_5336104880524164b953f1aac5b6bb02"}},"1dc45a681488400c85d5ad30f9426671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bef7b10ef16440da9496eb568148019","placeholder":"​","style":"IPY_MODEL_e32c384222694cabafb2f75b9336ee5a","value":"Downloading (…)/main/tokenizer.json: 100%"}},"4937fbc2956844ca9b144f67f779dd24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bc8f7671ec04d2e8553f9417e05086d","max":2114274,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc2892304e1849d585cfd338ce21b528","value":2114274}},"b6ef24f2430b4a089234efb40109b823":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b83288604ae842b9a40faedf2f8e45fa","placeholder":"​","style":"IPY_MODEL_18184c74ef3a49deafc047b214098a81","value":" 2.11M/2.11M [00:00&lt;00:00, 13.3MB/s]"}},"5336104880524164b953f1aac5b6bb02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bef7b10ef16440da9496eb568148019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32c384222694cabafb2f75b9336ee5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bc8f7671ec04d2e8553f9417e05086d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc2892304e1849d585cfd338ce21b528":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b83288604ae842b9a40faedf2f8e45fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18184c74ef3a49deafc047b214098a81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"897067a5d118494984b9e67be1494507":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cfc311a44474f94a24f205be885d307","IPY_MODEL_8c1d029c3b4042a39213736626738550","IPY_MODEL_479c634f1aee454ba1371f9c0314c0e8"],"layout":"IPY_MODEL_226ac2d1c544461fa5dd95cc4a9babcd"}},"0cfc311a44474f94a24f205be885d307":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3439ef15c2064918af4692ef275f63b4","placeholder":"​","style":"IPY_MODEL_5cf61ae1799a44b49a39591222d0c28f","value":"Downloading (…)cial_tokens_map.json: 100%"}},"8c1d029c3b4042a39213736626738550":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be74ac85b29745b9868e6f204d9a4649","max":228,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e38272f75564fb2af7b56662e0b3e0c","value":228}},"479c634f1aee454ba1371f9c0314c0e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b28f7f1a7cb845dca2114e476010f5d8","placeholder":"​","style":"IPY_MODEL_87ab533a445c408bae5ce35e1ca6aa66","value":" 228/228 [00:00&lt;00:00, 12.0kB/s]"}},"226ac2d1c544461fa5dd95cc4a9babcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3439ef15c2064918af4692ef275f63b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cf61ae1799a44b49a39591222d0c28f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be74ac85b29745b9868e6f204d9a4649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e38272f75564fb2af7b56662e0b3e0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b28f7f1a7cb845dca2114e476010f5d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ab533a445c408bae5ce35e1ca6aa66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d17c8edd999d420e9f861e849be11296":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4176b0e966344ad3a1e940e630a18f1f","IPY_MODEL_92941fab9b9f4beb93eedf85f03c5f7c","IPY_MODEL_a0f11229e77a471dae1284d46a8e49cf"],"layout":"IPY_MODEL_6e96ec06fd604ce08a5bb81e45de701e"}},"4176b0e966344ad3a1e940e630a18f1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9e514ca9e1149d099e943233291fa3d","placeholder":"​","style":"IPY_MODEL_1cd62640bd7748cab62285705d7451d7","value":"Downloading (…)lve/main/config.json: 100%"}},"92941fab9b9f4beb93eedf85f03c5f7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c20fc0d99354d6c9ddd3b0a0e962d88","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3eaf1a4de9cd4335a32490130ab56015","value":819}},"a0f11229e77a471dae1284d46a8e49cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c98c3b206207482cad94f83810bc84b9","placeholder":"​","style":"IPY_MODEL_889712e068f7409a995f8c771414cc8c","value":" 819/819 [00:00&lt;00:00, 42.4kB/s]"}},"6e96ec06fd604ce08a5bb81e45de701e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e514ca9e1149d099e943233291fa3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd62640bd7748cab62285705d7451d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c20fc0d99354d6c9ddd3b0a0e962d88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eaf1a4de9cd4335a32490130ab56015":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c98c3b206207482cad94f83810bc84b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"889712e068f7409a995f8c771414cc8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"073fae6635e348da85334230cf186d69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebcdabdd9e27453e9c968e099fb18dee","IPY_MODEL_4faa358b4f834c638de1dab4e0a8fbe7","IPY_MODEL_cd6c998be8b743cd8dc54eb0b067bfa2"],"layout":"IPY_MODEL_f3cc3e088235439d8f34657bd94dded2"}},"ebcdabdd9e27453e9c968e099fb18dee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7903ee13698c4bb59524601c0a9b5ed7","placeholder":"​","style":"IPY_MODEL_c8a15d8b17ad45e2983177687c29e530","value":"Downloading (…)instruct_pipeline.py: 100%"}},"4faa358b4f834c638de1dab4e0a8fbe7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e4942c66ed48c9beb12bba86d4fccf","max":9160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a37377e1d154733912dae4c3a61fe5c","value":9160}},"cd6c998be8b743cd8dc54eb0b067bfa2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9cbf612e4a4cb48d7099ddf6367e3b","placeholder":"​","style":"IPY_MODEL_4ca454235d5f466ab4a187fab120c310","value":" 9.16k/9.16k [00:00&lt;00:00, 511kB/s]"}},"f3cc3e088235439d8f34657bd94dded2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7903ee13698c4bb59524601c0a9b5ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8a15d8b17ad45e2983177687c29e530":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30e4942c66ed48c9beb12bba86d4fccf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a37377e1d154733912dae4c3a61fe5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d9cbf612e4a4cb48d7099ddf6367e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ca454235d5f466ab4a187fab120c310":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea131131487a4964ac10ecb1b76cbaf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce918b74f9244ab896886a0849d189d9","IPY_MODEL_fcd3e7760d814e5987fb92bddc876fa0","IPY_MODEL_f716d7fab6854a4ab7970f7251cfb625"],"layout":"IPY_MODEL_266a38f3921c46dd9e62227f84e05929"}},"ce918b74f9244ab896886a0849d189d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_844f1ecc4fe54dc48566f491bf3f4fe7","placeholder":"​","style":"IPY_MODEL_4feb2e5e0fdf4b5da2136c7ee17d2759","value":"Downloading pytorch_model.bin: 100%"}},"fcd3e7760d814e5987fb92bddc876fa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a134903ff43746068e1c3e309ae13771","max":5684548185,"min":0,"orientation":"horizontal","style":"IPY_MODEL_738e3537dbba459db357ddd3d3e37d89","value":5684548185}},"f716d7fab6854a4ab7970f7251cfb625":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a6bc7d57ccd4b3a9dae120fb8099a7a","placeholder":"​","style":"IPY_MODEL_2177b669b3f84b648af4ed09fafdf43e","value":" 5.68G/5.68G [01:32&lt;00:00, 63.7MB/s]"}},"266a38f3921c46dd9e62227f84e05929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844f1ecc4fe54dc48566f491bf3f4fe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4feb2e5e0fdf4b5da2136c7ee17d2759":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a134903ff43746068e1c3e309ae13771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"738e3537dbba459db357ddd3d3e37d89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a6bc7d57ccd4b3a9dae120fb8099a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2177b669b3f84b648af4ed09fafdf43e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed3d014bb4a04d0aa654757c7b457c18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_617fe467a49f411e8029ba7d954cbb3a","IPY_MODEL_b75d3c3f533b4997abb4beb56433e12a","IPY_MODEL_bf371298bf574a4f9ad54056b1699118"],"layout":"IPY_MODEL_77f76384ee0b497fa22c892bdab5c185"}},"617fe467a49f411e8029ba7d954cbb3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d670be120374e369ebeca67e547c4c8","placeholder":"​","style":"IPY_MODEL_8fe43faaab8f43a0b4fc0861d1708d29","value":"Downloading builder script: 100%"}},"b75d3c3f533b4997abb4beb56433e12a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26a41683e0d445c9aac30ed705fda36f","max":6545,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0db3708a11249cdae94b30bd4029e78","value":6545}},"bf371298bf574a4f9ad54056b1699118":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cdf64e7713b42998fead85d50696a52","placeholder":"​","style":"IPY_MODEL_f4cbfd5c3da844c4b7408276bf8484db","value":" 6.54k/6.54k [00:00&lt;00:00, 505kB/s]"}},"77f76384ee0b497fa22c892bdab5c185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d670be120374e369ebeca67e547c4c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe43faaab8f43a0b4fc0861d1708d29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26a41683e0d445c9aac30ed705fda36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0db3708a11249cdae94b30bd4029e78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cdf64e7713b42998fead85d50696a52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4cbfd5c3da844c4b7408276bf8484db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"662af1f06a004d87a3b7dff7eefe6db1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b898109d5cb4306a5696c632c51d51b","IPY_MODEL_9d01678876144f12acd368eac80e2f6d","IPY_MODEL_e36c70d791094d00a68fa6bef6865d17"],"layout":"IPY_MODEL_fc676ab3a34e4ee9a22643cca2d6b182"}},"4b898109d5cb4306a5696c632c51d51b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29d59fc1d94d4d17909eff2b6e41958d","placeholder":"​","style":"IPY_MODEL_9a05b636d3244d17ac016b780ff45172","value":"Downloading readme: 100%"}},"9d01678876144f12acd368eac80e2f6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4368932411fd4cdda19b02ba4adc475c","max":6081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_093392cbf5464be48704676f35efd516","value":6081}},"e36c70d791094d00a68fa6bef6865d17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdcd6d8e3d174b2982429947582937a4","placeholder":"​","style":"IPY_MODEL_183203058d2c448784db57314e49d666","value":" 6.08k/6.08k [00:00&lt;00:00, 383kB/s]"}},"fc676ab3a34e4ee9a22643cca2d6b182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d59fc1d94d4d17909eff2b6e41958d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a05b636d3244d17ac016b780ff45172":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4368932411fd4cdda19b02ba4adc475c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093392cbf5464be48704676f35efd516":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdcd6d8e3d174b2982429947582937a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"183203058d2c448784db57314e49d666":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ca76c31c73846fa8cee4055a2e08c30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50da6c1e7b124da8a10e092f63150287","IPY_MODEL_958dedc6e5614dab916db9aab75053ca","IPY_MODEL_fc6812df2f65437b914f322c76d2a835"],"layout":"IPY_MODEL_9eaaa864b4df40c0af53e8d0a1d0c001"}},"50da6c1e7b124da8a10e092f63150287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1985a1d232ff4cd4957f6bb554b3a861","placeholder":"​","style":"IPY_MODEL_bd0631e5180b4c59b4858baa019f80e3","value":"Downloading data: 100%"}},"958dedc6e5614dab916db9aab75053ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2f68a156a24a03a506605ef1097667","max":553459,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ab8a2a1a5c042948bc396135ee9c9cc","value":553459}},"fc6812df2f65437b914f322c76d2a835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3db0b3c06dab4e77bcc59afa3b143d05","placeholder":"​","style":"IPY_MODEL_46f1fb6c8bef44d98cbcc4b976560ece","value":" 553k/553k [00:00&lt;00:00, 575kB/s]"}},"9eaaa864b4df40c0af53e8d0a1d0c001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1985a1d232ff4cd4957f6bb554b3a861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd0631e5180b4c59b4858baa019f80e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da2f68a156a24a03a506605ef1097667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ab8a2a1a5c042948bc396135ee9c9cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3db0b3c06dab4e77bcc59afa3b143d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f1fb6c8bef44d98cbcc4b976560ece":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e0fa294fe5c4142a400db4e3d60c904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dc81ee962f5489ab1a2e8ce011e4dbe","IPY_MODEL_ce11740f1d5545239d6b5ddb392de9fe","IPY_MODEL_38c1cd6f28ac417f8104f8ae4622b87f"],"layout":"IPY_MODEL_40a1e87cb3da418e94a416a36437ac0d"}},"4dc81ee962f5489ab1a2e8ce011e4dbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78936bf3547345aeb98a2d484a7840ff","placeholder":"​","style":"IPY_MODEL_3723a85f9d1145b6b399f23eca9ce814","value":"Generating train split: "}},"ce11740f1d5545239d6b5ddb392de9fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5295656927ad461dad50eda52065f0f6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_762b62c8bf324ab09080453db0b7348c","value":1}},"38c1cd6f28ac417f8104f8ae4622b87f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90976941517245e2a1da20013b6eeb43","placeholder":"​","style":"IPY_MODEL_3c7f4ceb417c4f1da7d657b033699c4c","value":" 1795/0 [00:00&lt;00:00, 3137.22 examples/s]"}},"40a1e87cb3da418e94a416a36437ac0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78936bf3547345aeb98a2d484a7840ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3723a85f9d1145b6b399f23eca9ce814":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5295656927ad461dad50eda52065f0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"762b62c8bf324ab09080453db0b7348c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90976941517245e2a1da20013b6eeb43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c7f4ceb417c4f1da7d657b033699c4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ace5ce3a4555415c8569d85ee5a200c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_354d9a59cfe34094a03e086f8ba37c49","IPY_MODEL_95955b371f8342639514d461a6a15ea6","IPY_MODEL_f86033439950443785bcc662a2bcbb28"],"layout":"IPY_MODEL_69b6e6ce5a4e45859659b0841ab52bc5"}},"354d9a59cfe34094a03e086f8ba37c49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41ee9a56ff6a411eb3c01c50a3f0ae89","placeholder":"​","style":"IPY_MODEL_31f03bcfcd434f7fb901b9073673c088","value":"Generating validation split: "}},"95955b371f8342639514d461a6a15ea6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18a935bdb664de5892de0ac991abea5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2921cf367f2f4b6daa1c60c573ef3703","value":1}},"f86033439950443785bcc662a2bcbb28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dccea1dfa9b4d82b3590ccbd7f71f67","placeholder":"​","style":"IPY_MODEL_6c2b011f02b048a0a719779597aded9b","value":" 257/0 [00:00&lt;00:00, 2626.42 examples/s]"}},"69b6e6ce5a4e45859659b0841ab52bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41ee9a56ff6a411eb3c01c50a3f0ae89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f03bcfcd434f7fb901b9073673c088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c18a935bdb664de5892de0ac991abea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2921cf367f2f4b6daa1c60c573ef3703":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8dccea1dfa9b4d82b3590ccbd7f71f67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2b011f02b048a0a719779597aded9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e212fadf3314aa5959ea1086c238dbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52f091babde447afbb8ccba02279ec06","IPY_MODEL_1d114a2417d24d8fbd20e2e6e18252c8","IPY_MODEL_58ef48b6e54047f4a7e2f6411ed1f452"],"layout":"IPY_MODEL_868cf070e82744fca8bea5b9cad07eda"}},"52f091babde447afbb8ccba02279ec06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c74eca4b1b7a4e499b202e7539598ffd","placeholder":"​","style":"IPY_MODEL_ddcadd3898e545a8bf03c594c7040d8f","value":"Generating test split: "}},"1d114a2417d24d8fbd20e2e6e18252c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f696af01d19245639e3e3d6a673ca548","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e77762c47af14c0ab0dd973b2fbef719","value":1}},"58ef48b6e54047f4a7e2f6411ed1f452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a95047197f194789bfb70ac7ef61f9c0","placeholder":"​","style":"IPY_MODEL_93919a6c20284d0c83d9a31dbcd9fffd","value":" 513/0 [00:00&lt;00:00, 3329.47 examples/s]"}},"868cf070e82744fca8bea5b9cad07eda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c74eca4b1b7a4e499b202e7539598ffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddcadd3898e545a8bf03c594c7040d8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f696af01d19245639e3e3d6a673ca548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e77762c47af14c0ab0dd973b2fbef719":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a95047197f194789bfb70ac7ef61f9c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93919a6c20284d0c83d9a31dbcd9fffd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n","!pip -q install accelerate>=0.12.0\n","!pip install datasets"],"metadata":{"id":"zuwLc--q7RtP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691314434924,"user_tz":-120,"elapsed":49998,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"5387b613-a7e4-456f-c306-2bd2695dc1a6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.14.3-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.3 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/en2sparql"],"metadata":{"id":"YcU-KRrrF9JR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691314509927,"user_tz":-120,"elapsed":17644,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"2e37635c-3dc7-4f93-bc11-1e63a85a8479"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/en2sparql\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xF_bcVRM61-s","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["31f3287cd14c41f380a724e9edd71c54","a76086240098463fb0f15e5e004264d8","1c910a64d7f840a596aacb93940c5e7c","627bbbdb5a5f45109b8057f999d2d639","e44ac058260e43d9a649c71328c84ae0","be59116727104e72b76426184c979a90","9ce493e523f548d88644814d842dc79e","be4cca2ad4184321abb60e849b07a7ce","c5b43d2a09b04d79a1df6cb9e6cc8976","6e60b81a2d7b42a3bb234901e7218d59","132c5e563d574e1a8509970a06864f8f","c0c659a3048a4f2bb55c72e702a2af5c","1dc45a681488400c85d5ad30f9426671","4937fbc2956844ca9b144f67f779dd24","b6ef24f2430b4a089234efb40109b823","5336104880524164b953f1aac5b6bb02","4bef7b10ef16440da9496eb568148019","e32c384222694cabafb2f75b9336ee5a","1bc8f7671ec04d2e8553f9417e05086d","bc2892304e1849d585cfd338ce21b528","b83288604ae842b9a40faedf2f8e45fa","18184c74ef3a49deafc047b214098a81","897067a5d118494984b9e67be1494507","0cfc311a44474f94a24f205be885d307","8c1d029c3b4042a39213736626738550","479c634f1aee454ba1371f9c0314c0e8","226ac2d1c544461fa5dd95cc4a9babcd","3439ef15c2064918af4692ef275f63b4","5cf61ae1799a44b49a39591222d0c28f","be74ac85b29745b9868e6f204d9a4649","9e38272f75564fb2af7b56662e0b3e0c","b28f7f1a7cb845dca2114e476010f5d8","87ab533a445c408bae5ce35e1ca6aa66","d17c8edd999d420e9f861e849be11296","4176b0e966344ad3a1e940e630a18f1f","92941fab9b9f4beb93eedf85f03c5f7c","a0f11229e77a471dae1284d46a8e49cf","6e96ec06fd604ce08a5bb81e45de701e","d9e514ca9e1149d099e943233291fa3d","1cd62640bd7748cab62285705d7451d7","5c20fc0d99354d6c9ddd3b0a0e962d88","3eaf1a4de9cd4335a32490130ab56015","c98c3b206207482cad94f83810bc84b9","889712e068f7409a995f8c771414cc8c","073fae6635e348da85334230cf186d69","ebcdabdd9e27453e9c968e099fb18dee","4faa358b4f834c638de1dab4e0a8fbe7","cd6c998be8b743cd8dc54eb0b067bfa2","f3cc3e088235439d8f34657bd94dded2","7903ee13698c4bb59524601c0a9b5ed7","c8a15d8b17ad45e2983177687c29e530","30e4942c66ed48c9beb12bba86d4fccf","7a37377e1d154733912dae4c3a61fe5c","8d9cbf612e4a4cb48d7099ddf6367e3b","4ca454235d5f466ab4a187fab120c310","ea131131487a4964ac10ecb1b76cbaf1","ce918b74f9244ab896886a0849d189d9","fcd3e7760d814e5987fb92bddc876fa0","f716d7fab6854a4ab7970f7251cfb625","266a38f3921c46dd9e62227f84e05929","844f1ecc4fe54dc48566f491bf3f4fe7","4feb2e5e0fdf4b5da2136c7ee17d2759","a134903ff43746068e1c3e309ae13771","738e3537dbba459db357ddd3d3e37d89","2a6bc7d57ccd4b3a9dae120fb8099a7a","2177b669b3f84b648af4ed09fafdf43e","ed3d014bb4a04d0aa654757c7b457c18","617fe467a49f411e8029ba7d954cbb3a","b75d3c3f533b4997abb4beb56433e12a","bf371298bf574a4f9ad54056b1699118","77f76384ee0b497fa22c892bdab5c185","9d670be120374e369ebeca67e547c4c8","8fe43faaab8f43a0b4fc0861d1708d29","26a41683e0d445c9aac30ed705fda36f","c0db3708a11249cdae94b30bd4029e78","4cdf64e7713b42998fead85d50696a52","f4cbfd5c3da844c4b7408276bf8484db","662af1f06a004d87a3b7dff7eefe6db1","4b898109d5cb4306a5696c632c51d51b","9d01678876144f12acd368eac80e2f6d","e36c70d791094d00a68fa6bef6865d17","fc676ab3a34e4ee9a22643cca2d6b182","29d59fc1d94d4d17909eff2b6e41958d","9a05b636d3244d17ac016b780ff45172","4368932411fd4cdda19b02ba4adc475c","093392cbf5464be48704676f35efd516","cdcd6d8e3d174b2982429947582937a4","183203058d2c448784db57314e49d666","1ca76c31c73846fa8cee4055a2e08c30","50da6c1e7b124da8a10e092f63150287","958dedc6e5614dab916db9aab75053ca","fc6812df2f65437b914f322c76d2a835","9eaaa864b4df40c0af53e8d0a1d0c001","1985a1d232ff4cd4957f6bb554b3a861","bd0631e5180b4c59b4858baa019f80e3","da2f68a156a24a03a506605ef1097667","2ab8a2a1a5c042948bc396135ee9c9cc","3db0b3c06dab4e77bcc59afa3b143d05","46f1fb6c8bef44d98cbcc4b976560ece","4e0fa294fe5c4142a400db4e3d60c904","4dc81ee962f5489ab1a2e8ce011e4dbe","ce11740f1d5545239d6b5ddb392de9fe","38c1cd6f28ac417f8104f8ae4622b87f","40a1e87cb3da418e94a416a36437ac0d","78936bf3547345aeb98a2d484a7840ff","3723a85f9d1145b6b399f23eca9ce814","5295656927ad461dad50eda52065f0f6","762b62c8bf324ab09080453db0b7348c","90976941517245e2a1da20013b6eeb43","3c7f4ceb417c4f1da7d657b033699c4c","ace5ce3a4555415c8569d85ee5a200c4","354d9a59cfe34094a03e086f8ba37c49","95955b371f8342639514d461a6a15ea6","f86033439950443785bcc662a2bcbb28","69b6e6ce5a4e45859659b0841ab52bc5","41ee9a56ff6a411eb3c01c50a3f0ae89","31f03bcfcd434f7fb901b9073673c088","c18a935bdb664de5892de0ac991abea5","2921cf367f2f4b6daa1c60c573ef3703","8dccea1dfa9b4d82b3590ccbd7f71f67","6c2b011f02b048a0a719779597aded9b","0e212fadf3314aa5959ea1086c238dbd","52f091babde447afbb8ccba02279ec06","1d114a2417d24d8fbd20e2e6e18252c8","58ef48b6e54047f4a7e2f6411ed1f452","868cf070e82744fca8bea5b9cad07eda","c74eca4b1b7a4e499b202e7539598ffd","ddcadd3898e545a8bf03c594c7040d8f","f696af01d19245639e3e3d6a673ca548","e77762c47af14c0ab0dd973b2fbef719","a95047197f194789bfb70ac7ef61f9c0","93919a6c20284d0c83d9a31dbcd9fffd"]},"executionInfo":{"status":"error","timestamp":1691318086310,"user_tz":-120,"elapsed":3561051,"user":{"displayName":"Antonello","userId":"01962207529893687178"}},"outputId":"5a7a884a-98d5-442f-eb05-a5772c533071"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31f3287cd14c41f380a724e9edd71c54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0c659a3048a4f2bb55c72e702a2af5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"897067a5d118494984b9e67be1494507"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d17c8edd999d420e9f861e849be11296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)instruct_pipeline.py:   0%|          | 0.00/9.16k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"073fae6635e348da85334230cf186d69"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["A new version of the following files was downloaded from https://huggingface.co/databricks/dolly-v2-3b:\n","- instruct_pipeline.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea131131487a4964ac10ecb1b76cbaf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed3d014bb4a04d0aa654757c7b457c18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662af1f06a004d87a3b7dff7eefe6db1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/553k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca76c31c73846fa8cee4055a2e08c30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e0fa294fe5c4142a400db4e3d60c904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ace5ce3a4555415c8569d85ee5a200c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e212fadf3314aa5959ea1086c238dbd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 1795\n","    })\n","    validation: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 257\n","    })\n","    test: Dataset({\n","        features: ['id', 'query_type', 'question', 'paraphrased_question', 'query', 'template_id', 'query_shape', 'query_class', 'auto_generated', 'number_of_patterns'],\n","        num_rows: 513\n","    })\n","})\n","Error with key 10-None\n","513\n","0%  ['The best performing model is the Transformer model from the Neural Language Model Research Group at the University of Massachusetts, Amherst. The Transformer model achieved an accuracy score of 99.0%.', 'SELECT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Word Level in Penn Treebank\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"UrbanSound8k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Penn Treebank\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT?metric  (MAX(?value) AS?score) \\n  WHERE { \\n    { \\n      SELECT?metric ?metric_lbl (MAX(?value) AS?score) \\n      WHERE { \\n        { \\n          SELECT?metric ?metric_lbl?value \\n          WHERE { \\n            { \\n              SELECT?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MazeA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } \\n            } \\n            ORDER BY DESC(?value) \\n          } \\n          GROUP BY?metric?metric_lbl']\n","0.9708737864077669%  [\"The models that have been benchmarked on the Abstracts' entities and relations annotated corpus dataset are:\\n- kp Term Summarizer\\n- SQALE\", 'The mean capacity of a carbon-based fuel is 6.62 pounds per gallon.', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The best performing model on the Kuzushiji-MNIST benchmark dataset for the Accuracy metric is:\\n<Model With Accuracy Score>: \"ensemble-of-models-that-work-hard-on-pattern-recognition-but-never-look-at-a-programming-language-seriously-mode\">', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a bleu; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a bleu:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")?benchmark. FILTER (bleu:Bleu>=78.0)?model. } ORDER BY DESC(?value) LIMIT 1 } }']\n","1.9417475728155338%  ['SELECT \\n ?metric?metric_lbl (MAX(?value) AS?score) \\nWHERE \\n { \\n   { \\n     SELECT \\n      ?metric?metric_lbl?value \\n     WHERE \\n       { \\n        ?dataset a orkgc:Dataset; \\n           rdfs:label?dataset_lbl. \\n         FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k\") \\n        ?benchmark orkgp:HAS_DATASET?dataset; \\n           orkgp:HAS_EVALUATION?eval. \\n        ?eval orkgp:HAS_VALUE?value. \\n         OPTIONAL {?eval orkgp:HAS_METRIC?metric. \\n              ?metric rdfs:label?metric_lbl. \\n          } \\n        ?cont orkgp:HAS_BENCHMARK?benchmark. \\n         OPTIONAL {?cont orkgp:HAS_MODEL?model. \\n              ?model rdfs:label?model_lbl. \\n          } \\n         } \\n        ORDER BY DESC(?value) \\n       } \\n     GROUP BY?metric?metric', 'The best performing model benchmarking the VTAB-1k dataset in terms of Top-1 Accuracy score is the “Jetpac” model submitted by “Fernando Nolberth” on February 5th 2023.', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"arXiv dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nThe datasets of research papers that include a benchmark for the Abstracts\\' entities and relations annotated corpus dataset, the Automatically labeled Medline abstracts corpus dataset, and the arXiv dataset are respectively orkgp:HAS_DATASET, orkgp:HAS_BENCHMARK, and orkgp:HAS_DATASET. The labels of the datasets are respectively \"Abstracts\\' entities and relations annotated corpus\", \"Automatically labeled Medline abstracts corpus\", and \"arXiv dataset\". The benchmarks of the research papers are respectively orkgp:HAS_DATASET orkgp:HAS_BENCHMARK. The papers are P31 and P31.', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a tdeml:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TDM Tagged Corpus\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }']\n","2.9126213592233006%  ['The model with the highest score for the Score metric on the Lunar Lander (OpenAI Gym) dataset is the salience-based encoder (SBE). It has a score of 100.0.', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"FSNS - Test dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nCommon metrics include, but are not limited to: \\n\\n- Precision \\n - Recall\\n - F1-Score \\n- Zero-Shot Classification (ZS-C)\\n - Zero-Shot Regression (ZS-R) \\n - Fr[é]{}chet Inception Distance (FID) \\n - City-block Distance (CBD)', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet 64x64 dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nThe corresponding page for this question on the Apache Open Graph Benchmark project website is:', 'The metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset are the following: \\n\\nprecision: the fraction of relations that are mentioned in the abstracts \\nrecall: the fraction of relations that are mentioned in the abstracts but not in the ground truth annotations (when available) \\nf1 measure: a combination of precision and recall (precision * 1.0 / (precision + recall))\\n\\nThe metrics of evaluation over the Classical music, 5 seconds at 12 kHz dataset are the following: \\nprecision: the fraction of relations that are mentioned in the abstracts \\nrecall: the fraction of relations that are mentioned in the abstracts but not in the ground truth annotations (when available) \\nf1 measure: a combination of precision and recall (precision * 1.0 / (precision + recall))', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Flair-TDM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }']\n","3.8834951456310676%  ['1 https://arxiv.org/abs/1802.05354\\n2 https://arxiv.org/abs/1807.08260\\n3 https://www.aclweb.org/anthology/W/W19/W19_1766.pdf\\n4 https://openmined.org/blog/the-why-and-how-of-cyber-agility/\\n5 https://github.com/huggingface/gPT/blob/master/examples/transformer_xl/main.py', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1 Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"SAN (single)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT DISTINCT?model?model_lbl WHERE {?model_desc :model ?model_lbl;?model_desc a orkgc:Dataset ; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"ACE 2005\") }', 'To my knowledge, there is only one paper that has used PNDec model for benchmarking: https://www.semanticscholar.org/paper/A-Decentralized-RELU-Layer-for-Improved-Image-Generation/zxta6v0qro5a2q1lg5wixm/']\n","4.854368932038835%  ['code link:\\nhttps://drive.google.com/uc?export=download&id=1YkyDw03qWaSm&authuser=0\\ncode link (for Inan et al. 2016):\\nhttps://drive.google.com/file/d/0B9s_iBwuvomC9Mzd2LzQw4iM4M3c/view?usp=sharing', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a imdb-b:IMDb; rdfs:label imdb-b:BILINEAR_RESULTS_URL_LABEL_1.?dataset imdb-b:BILINEAR_RESULTS_URL_LABEL_1. FILTER (str( imdb-b:BILINEAR_RESULTS_URL_LABEL_1) = \"https://www.imdb.com/chart/bottom)?benchmark imdb-b:HAS_DATASET?dataset; imdb-b:HAS_EVALUATION?eval.?eval imdb-b:HAS_VALUE?value. OPTIONAL {?eval imdb-b:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont imdb-b:HAS_BENCHMARK?benchmark. OPTIONAL {?cont imdb-b:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'Papers that have utilized the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model\\n- https://github.com/dypp/dygite/blob/master/docs/BENCHMARKING.md#dygite-openie\\n- https://github.com/dypp/dygite/blob/master/docs/BENCHMARKING.md#dygite-dygite\\n- https://github.com/dypp/dygite/blob/master/docs/BENCHMARKING.md#dygite-stanford-core-nlp-pos-tagger-enriched-by-consistent-triples-model', 'Commonly used evaluation metrics on the Atari 2600 Up and Down dataset are the following:\\n 1. Overall QA: The Mean Average Precision metric. This is the average of the following three metrics: (i) True Positive Rate (TPR), or the fraction of correct positive predictions; (ii) False Positive Rate (FPR), or the fraction of incorrect negative predictions; and (iii) the F-score, which is the harmonic average of the TPR and FPR.\\n 2. Semantic Similarity (SSIM): This metric is computed using the JPEG2000 Lossless codec and an ICC profile from macOS High Sierra 10.13.5.\\n 3. Classification and Regression: The Pearson Correlation Coefficient, also called the coefficient of determination, is a measure of the percentage of variability in one set of observations that can be explained by a linear combination of the variables in a second set of observations.']\n","5.825242718446601%  ['The top performing model is i-Grid Large Scale Training of Recursive Neural Networks for Alembic Similarities Benchmark on the Penn Treebank (Character Level) dataset.', 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n ?dataset a orkgc:Dataset;\\n  rdfs:label?dataset_lbl.\\n  FILTER (str(?dataset_lbl) = \"Character Level\")\\n ?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?paper orkgp:P31?cont;\\n  rdfs:label?paper_lbl.\\n}', 'Here is the metrics used to evaluate on the Atari 2600 Double Dunk dataset:\\n- Average skill level of the agent: 78.4 (Mean)\\n- Percentage of time agent was in the highest skill level: 20.0%\\n- Percentage of time agent was in the lowest skill level: 80.0%\\n- Average error in x and y directions: 8.31\\n- Maximum error in x and y directions: 20.0', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Top 1 Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet V2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT (AVG(?reproductive_number) AS?average_reproductive_number) WHERE { orkgr:R44930 orkgp:compareContribution?contrib.?contrib orkgp:P23140?basic_reproductive_number.?basic_reproductive_number orkgp:HAS_VALUE?value BIND(xsd:float(?value) AS?reproductive_number) }']\n","6.796116504854368%  ['BIND( IF(?has_aggregation_support_ = \"T\"^^xsd:string, \"yes\", \"no\") AS?has_aggregation_support )', 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Entity Disambiguation\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. }', 'IRI://rioaddr:8080/services/jena-query/QueryServicesImpl?query=SELECT%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1 Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC CHINESE TO ENGLISH\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet ReaL\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nThe selected papers are: \\n#                                      P31']\n","7.766990291262134%  ['SELECT DISTINCT?paper?paper_lbl WHERE { \\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"Gibson PointGoal Navigation\") \\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?paper orkgp:P31?cont; \\n    rdfs:label?paper_lbl. \\n} \\n\\ninput (English text): What are the titles and IDs of research papers that include a benchmark for the Automatically labeled Medline abstracts corpus dataset?\\noutput (Sparql query): SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?', 'Car speed in Liuliqiao District, Beijing, 50 km/h\\nCar speed in Liuliqiao District, Beijing, 50 km/h', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PIQA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'Indicate the model that performed best in terms of Score metric on the Atari 2600 Crazy Climber benchmark dataset?\\nThe best performing model is theskip-thoughts model with an score of 0.82729695869231', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Table-Sequence model\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nA:\\n\\nI\\'ve added the code to my answer as an executable pipeline. You can find it here: https://pastebin.com/WFBeXHZT\\n\\n\\nThis pipeline uses the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by\\n  consistent triples model to tag the papers in the given list. I\\'ve also added a\\n  Text to Sequence model to a baseline. Finally, I\\'ve added a link to the model\\n  source code.\\n\\n# Load the DyGIE++ + OpenIE + Stanford Core NLP model\\ndata = spark.read.format(\"jdbc\").format(\"default\").load(\"models/ DyGIE++ + OpenIE + Stanford Core']\n","8.7378640776699%  ['The following papers have utilized the Funnel Transformer model:\\n- Ma et al. (2019) Evaluating the Understanding of Natural Language Generation with the Funnel Transformer\\n- Pardot et al. (2019) Funnel Transformer: A Neural Model for Natural Language Generation\\n- Kallotropic et al. (2019) Towards Transformers as Integrative Parsers', 'The metrics that are used to evaluate models on the automatically labeled Medline abstracts corpus are the F-measure and the positive predictive value (PPV).', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PubMed 20k RCT\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'Here are the papers that have used the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model:\\n\\nInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model: https://doi.org/10.18653/v1/D16-1055\\nGulshan et al. (2017) - Effective Character-level Keyword Spotting with Neural Networks: https://doi.org/10.18653/v1/D16-0879\\nWang et al. (2017) - A Benchmark on Common NLP Tasks with DyGIE: https://doi.org/10.18653/v1/D17-0240', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Flops\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","9.708737864077667%  "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["['SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"AESLC\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; wos:Synset?dataset_synset. FILTER (str(?dataset_synset) = \"WOS-46985\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"AcrE model\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL AcrE; orkgp:HAS_SOURCE_CODE?code. }', 'The Oxford Wordnet based model achieves the highest Semeval 2013 metric score on the Supervised: dataset.']\n","10.679611650485434%  ['Sparql endpoint located at: http://localhost:8090/sparql', '3.10 grams', 'RDFLinearModel, RDLegacy, RFVista, SVM, KELM, Logit-SVM, Logit, One-R, Gradient Boosting, AdaBoost, Random Forest', 'The following papers have utilized the DQN-PixelCNN model:\\n\\n- Acar et al. (2017) - QA on Large-scale OpenIEQA (Evaluation of a question answering model on the Omondi English semantic Web dataset)\\n- Cruz et al. (2017) - Neural Topic Model for Quantum Key Distribution\\n- Deng et al. (2017) - Quantum Key Distribution over Non-Orthogonal Qudits via Self-Triggered Scheme', 'The metrics that are used to evaluate models on the Atari 2600 Freeway dataset are: accuracy, f1-score, recall, precision, recall, coverage, precision, recall and accuracy.']\n","11.6504854368932%  ['Here is a list of papers that have utilized the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model:\\n- Ahmad, Amir, Vishnu Jayaraman, and Tony Ker, \"DyGIE++: A Cross-lingual Graph Embedding Point of Sale Toolkit,\" Knowledge-Based Systems 45, no. 1 (2017): 55-69. https://doi.org/10.1016/j.knosys.2016.10.003\\n- Allamanis, Kostas, \"Semantic Web Services for Customer Databases: The DyGIE++ Cross-Lingual Open Database Connectivity Project,\" Master\\'s Thesis, University of Oslo, 2017. https://openrepository.uio.no/opencms-docviewer/handle/10064/10103\\n- Anh, Ina, Xavier Latunias, and Tony Ker, \"Enhancing Neural Parsing with Consistent Transitivity: A Deep Reinforcement Learning Approach,\" ACL 2018. https://www.aclweb.org/anthology/K Phoiend/volar18-rich.pdf\\n- Anh, Ina, X', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT?metric (MAX(?value) AS?score) WHERE { \\n  { \\n    SELECT?metric?metric_lbl?value WHERE { \\n     ?dataset a atari2600_tennis:Dataset; \\n      rdfs:label?dataset_lbl. \\n      FILTER(str(?dataset_lbl) = \"Atari 2600 Tennis\")\\n     ?benchmark atari2600_tennis:HAS_BENCHMARK?eval. \\n     ?eval atari2600_tennis:HAS_VALUE?value. \\n      OPTIONAL {?eval atari2600_tennis:HAS_METRIC?metric. \\n                 ?metric rdfs:label?metric_lbl. \\n    } \\n    ORDER BY DESC(?value) } \\n  } \\n  GROUP BY?metric?metric_lbl}', 'The following are the metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset:\\n1. Precision (also known as the positive predictive value, orPPV):  It is the ratio of the number of positive examples identified as positive over the total number of positive examples.\\n2. Recall (also known as the positive sensitivity, orPS):  It is the ratio of the number of positive examples identified as positive over the total number of negative examples.\\n3. Accuracy:  It is the ratio of the number of positive examples identified as positive over the total number of positive and negative examples.\\n4. F1 score:  A measurement of the effectiveness of a test, usually used to compare the performance of two methods.  The F1 score is the harmonic mean of the precision and recall, with a value between 0 and 1.\\n5. RMSE (root mean square error):  It is the root-mean-square difference between two sets of numbers.\\n6. R2 score:  It is the correlation coefficient between the predicted and actual values.\\n7. MRE (mean rank error):  It is the arithmetic mean of the ranks of the true and predicted lists, divided by the number of elements in', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }']\n","12.621359223300967%  ['Below is a list of the models that have been tested on the Reuters RCV1/RCV2 English-to-German benchmark dataset:\\n- Tensor2D\\n- XLNet\\n- BERT', 'Cationic liposome, polymer modified liposome, monoclonal antibody-liposome conjugate, light-up liposome', 'The top performing model is the AAMOS model described in \"Joint Community 2018: Joint Community on AAMOS\" paper.  The AAMOS model achieved a ROUGE-2 score of 43.44 on the CL-SciSumm dataset.', 'The following code links can be used to execute the queries:\\nhttps://github.com/nubiaoleary/dygie++_and_stanford_core_nlp_pos_tagger/blob/master/dygie++_and_stanford_core_nlp_pos_tagger/src/main/java/org/nubia/dygie/openeie/StanfordCoreNLP.java#L1134\\nhttps://github.com/nubiaoleary/dygie++_and_stanford_core_nlp_pos_tagger/blob/master/dygie++_and_stanford_core_nlp_pos_tagger/src/main/java/org/nubia/dygie/openeie/DyGIE++.java#L206\\nhttps://github.com/nubiaoleary/dygie++_and_stanford_core_nlp_pos_tagger/blob/master/dygie++_and_stanford_core_nlp_pos_tagger/src/main/java/org/nubia/', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Permuted Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Sequential MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","13.592233009708734%  ['SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciTLDR\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a cqapi:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CommonsenseQA benchmark dataset\")?benchmark cqapi:HAS_DATASET?dataset; cqapi:HAS_EVALUATION?eval. OPTIONAL {?eval cqapi:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a ifkgc:Dataset; rdfs:label ifkgc:Movie; FILTER (str( ifkgc:Movie ) = \"IMDb-M\")?benchmark ifkgp:HAS_DATASET?dataset; ifkgp:HAS_EVALUATION?eval.?eval ifkgp:HAS_VALUE?value. OPTIONAL {?eval ifkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont ifkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont ifkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a scientometrics:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Scholarly entity usage detection\")?benchmark scientometrics:HAS_DATASET?dataset; scientometrics:HAS_EVALUATION?eval.?eval scientometrics:HAS_VALUE?value. OPTIONAL {?eval scientometrics:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont scientometrics:HAS_BENCHMARK?benchmark. OPTIONAL {?cont scientometrics:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MultiNLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }']\n","14.5631067961165%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Short Texts for Humor Detection benchmark dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nThe following are the metrics used to evaluate models on the 200k Short Texts for Humor Detection benchmark dataset:\\n\\n- Precision\\n- Recall\\n- F1 Score\\n- Average Per-Sentence Precision\\n- Average Per-Sentence Recall\\n- Average Per-Sentence F1 Score', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Sequential MNIST\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'A. Ghiasi et al., 2019.  \"A Faster and Stronger Sequence to Document Mapping Approach for Sentence Similarity\" https://dl.acm.org/citation.cfm?id=3315308\\nB. Yin et al., 2019.  \"MIE: Matching Identified Entities in Text with Knowledge Bases\" https://dl.acm.org/citation.cfm?id=3203232\\nC. Inan et al., 2016.  \"Variational LSTM (tied) (h=650) + augmented loss\" https://dl.acm.org/citation.cfm?id=1557480\\nD. Hinrichsen et al., 2015.  \"A Neural Parsing Model for DocBank\" https://dl.acm.org/citation.cfm?id=2604234\\nE. Kwok et al., 2014.  \"Calibrating Neural Language models for Document Classification\" https://dl.acm.org/citation.cfm?id=2514109', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { \\n    { \\n      SELECT?metric?metric_lbl?value WHERE { \\n       ?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. \\n        FILTER (str(?dataset_lbl) = \"NYT-single\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } \\n      } \\n      ORDER BY DESC(?value) \\n    } \\n    { \\n     ?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. \\n      FILTER (str(?dataset_lbl) = \"', 'The metrics that are used to evaluate models over the SciTLDR benchmark are: Accuracy, AUC, log loss, precision, recall, R2, F1, micro F1, macro F1, F1 score, F1 measure.']\n","15.533980582524267%  ['SELECT?model?model_lbl WHERE { \\n?dataset a orkgc:Dataset; \\nrdfs:label?dataset_lbl. \\nFILTER (str(?dataset_lbl) = \"WMT2016 English-German\") \\n?benchmark orkgp:HAS_DATASET?dataset; \\norkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. \\nOPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } \\n}', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"FLOPS\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CIFAR-100\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"RotoWire (Relation Generation)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'The best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score is the DNNModel.\\nThe DNNModel.', 'SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }']\n","16.504854368932033%  ['For this query, the answer is the following code links:\\n - https://github.com/Inan-Elahi/DyGIE+LSTM\\n - https://github.com/Inan-Elahi/DyGIE+LSTM+AugmentedLoss\\n - https://github.com/Inan-Elahi/DyGIE+LSTM+DQNMSRe+SR', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl100k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1 Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"NYT-Single\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'List the code links in papers that use the MMV TSM-50x2 model and include the links to their code?']\n","17.4757281553398%  ['SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"yelp-5\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'List the code links in papers that use the SAC model and include the links to their code?\\n--\\nInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\nRajpurkar et al. (2016) - Bayesian Deep Neural Turing Machines for Coreference Resolution and Part of Speech Tagging\\nBordes et al. (2014) - Levy-Lietarinen model for coreference resolution with distributed neural networks', 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"MEMEN\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. \\n}', 'The following papers have utilized the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark:\\n\\n- Academia.edu:  Inan, Emanuele, and Roman Nikolenko.  \"Gated Recurrent Unit for Machine Reading and Writing.\"  arXiv preprint arXiv:1611.05333 (2016).  \\n- Cogent:  Inan, Emanuele, and Roman Nikolenko.  \"Gated Recurrent Unit for Machine Reading and Writing.\"  CMUC-16-004.  Cogent, 2016.  \\n- Deep Learning for Text Classification.  16th International Workshop, DLT16, Sydney, Australia, July 2016.  Abstract:  Inan, Emanuele, and Roman Nikolenko.  \"GRU with Adaptive Weight Delay layer for Text Classification.\"  arXiv preprint arXiv:1611.04509 (2016).  \\n- FEMtoGPT:  Inan, Emanuele, and Roman Nikolenko.  \"Gated Recurrent Unit for Machine Reading and Writing.\"  arXiv preprint arXiv:1611.065']\n","18.44660194174757%  ['SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nNote that the Sparql query is not perfectly formed because the?model and?model_lbl variables have not been properly constrained, but you should get the general idea.', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1-score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"200k Short Texts for Humor Detection\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'The following papers have used the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model:\\n- Chandra et al. (2018) - DistMult(tied) (+r): Dev set evaluation\\n- Li et al. (2018) - EML-Coarse(+r): Coarse-grained evaluation\\n- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss: Training, development, and test set evaluation\\n- Liu et al. (2017) - CoNLL-2013: Preliminary results\\n- Liu et al. (2017) - CoNLL-2017: Preliminary results\\n- Mikolov et al. (2013) - GRU: CoNLL-2013: Preliminary results\\n- Mikolov et al. (2013) - GRU-LSTM: CoNLL-2013: Preliminary results\\n- Mikolov et al. (2013) - GRU-LSTM-Diamond: CoNLL-2013: Preliminary results\\n- Rehder et al. (2016) - LogistCLEF: Second place on TACL with Logistics Data\\n- Se', 'SELECT?model?model_lbl WHERE {\\n ?dataset a enwiki8:Document;\\n  rdfs:label?dataset_lbl.\\n  FILTER (str(?dataset_lbl) = \"enwiki8\")\\n ?benchmark orkgp:HAS_EVALUATION?eval.\\n ?paper orkgp:HAS_MODEL?model.\\n ?model rdfs:label?model_lbl.\\n}', 'Provide a list of research paper titles and IDs that have benchmarked models on the SciERC dataset?']\n","19.41747572815534%  ['The best performing model on CommonsenseQA benchmark dataset in terms of Accuracy metric is trained on Improved: SQuAD 2.0 using method of Samarth and Karpathy.', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a squa:SQuAD2_0; \\n  rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SQuAD2_0\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nThe SQuAD2.0 dataset contains two relatedtasks:\\n- SQuAD文章推斜索引\\n- SQuAD文章分类', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014 English-German dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }\\n\\nCommon metrics for WMT2014 English-German dataset include: word accuracy, BLEU, METEOR, ROUGE-L and C&W.', 'Datasets benchmarked under the Automated Reinforcement Learning (AutoRL) research problem:\\nAutomated Reinforcement Learning (AutoRL)\\nKiller commons\\nweb-scale text classification\\nAutomated Deception\\nAutomatic Labeling Of Internet Content\\nThe New Yorker Article Text Data Set\\nConnected Verbs\\nThe Many Faces Of Crime', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"RE+ Micro F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CONLL04\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score is the public model released by the University of North Carolina at Charlotte called \"BioNLP StarTERm\".']\n","20.388349514563107%  ['SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"XLNet (base)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nThe papers that utilize the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model are:\\n\\n- Afify, Mozafari, Baluja, Gulcehre, Gu, Guo, Lewis,, Ligett, Lu, Manning, Nogueira, Osoba, Person, Phillips, Raff, Reiss, Ridha, Sousa, Uijlings, Wang, Zhang, and Zoph. 2019. RoBERTa: A large language model v2 with single-GPU speed. arXiv preprint arXiv:1904.09412.\\n- Fu, Xiao, Deng, Liang, Liu, Peng,', 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n ?dataset a orkgc:Dataset;\\n  rdfs:label?dataset_lbl.\\n  FILTER (str(?dataset_lbl) = \"Ohsumed dataset\") \\n ?benchmark orkgp:HAS_DATASET?dataset.\\n ?cont orkgp:HAS_BENCHMARK?benchmark.\\n ?paper orkgp:P31?cont;\\n  rdfs:label?paper_lbl.\\n}', 'SELECT DISTINCT?model?model_lbl WHERE {\\n ?dataset a orkgc:Dataset;\\n  rdfs:label?dataset_lbl.\\n  FILTER (str(?dataset_lbl) = \"NYT29 benchmark dataset\")\\n  orkgp:HAS_EVALUATION?eval.\\n ?paper orkgp:HAS_BENCHMARK?benchmark.\\n  OPTIONAL {?paper orkgp:HAS_MODEL?model.\\n   ?model rdfs:label?model_lbl. }\\n}', '3. Pressure, Density and Temperature', 'The papers that use the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model include: \\n- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Dabbous et al. (2017) Dictionary based Neural Turing Machine for Sentiment Analysis of Social Media Posts\\n- Shan et al. (2017) Noun Phrase Attachment Sensitivity in Neural Machine Translation using Large-Vocabulary Ranking']\n","21.359223300970875%  ['SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TREC-6 dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }\\n\\nThe following are the titles and IDs of research papers that contain a benchmark over the TREC-6 dataset:\\n\\nP31 - The corpus of automatically labeled Medline abstracts from the ACL Anthill\\nP30 - Evaluating a text mining system that uses abstracts to extract disease information from Medline', 'The papers that utilize the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model include:\\n- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Ilyas et al. (2017) : Analyzing DQN Through Subsets of Human Timed Playthroughs\\n- Stolze et al. (2017) : Learning Q-Functions via Dynamic Episodic Rewards', 'The name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-French dataset is go2tfo (Good-to-Followout).', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"1-of-100 Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe model that achieved the highest 1-of-100 Accuracy metric score was the LSTM model benchmarked against the polyAI dataset, which is also known as the Reddit dataset.', 'Here are the links to papers that used the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model. The model is proposed in Inan et al. (2016). The model takes as input any orkgc:Model and gives as output a rdfs:label, which is typically the names of a data set or a benchmark:\\n\\n* https://github.com/Inan-E/variational-LSTM-tied\\n* https://github.com/Inan-E/LongShortTransformer\\n\\nThe code links will be listed in the sparql query output above.']\n","22.330097087378643%  ['SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TriviaQA\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'Raman spectroscopy is a kind of spectroscopy that uses a laser to stimulate a molecule to release photons in the Raman shift, and uses the output of the spectrometer to identify the chemical composition of the sample.', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a doctype; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"DTD\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CINIC-10\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SemEval-2018 Task 7 dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }']\n","23.30097087378641%  ['The metrics that are used to evaluate models over the AG News benchmark dataset are the following:\\n- Precision \\n- Recall \\n- F1 score \\n- Micro F1 score\\n- Macro F1 score', 'The best performing model in terms of F1 entity level score when benchmarked on the NCBI Disease dataset is a model called BART.', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The following papers have utilized the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model:\\n  - Du et al. (2017) - Gated Conditional Random Field (h=610) + Neural Architecture Search. https://arxiv.org/abs/1610.08433\\n  - Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss. https://arxiv.org/abs/1610.08433\\n\\nThe code links used in these papers are:\\n  - https://github.com/staltz/dygipee\\n  - https://github.com/adrianozhang/openeie', 'CHEMDNER has the following data format:']\n","24.27184466019418%  ['SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CUB-200-2011 dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'There are few works that use the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model. The following list contains the code links: \\nInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model https://github.com/InanAtzori/Video-Coding-Competition-works/blob/master/results_hits/final/README.md#LSTM_tied_h650_augmented_loss_model\\nLee et al. (2017) - Joint Modeling of Codability and MaintainedUtility for Multi-Rate Video Codecs https://github.com/LeehodKat/LeehodKat_MemCards_TCDD15.pdf \\nZhu et al. (2017) - Do We Still Need Deep Learning for Video Coding? https://dl.acm.org/doi/pdf/10.1145/3075376.3075504', 'SELECT DISTINCT?code WHERE { \\n ?model a orkgc:Model; \\n  rdfs:label?model_lbl. \\n  FILTER (str(?model_lbl) = \"Duel hs\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?cont orkgp:HAS_MODEL?model; \\n  orkgp:HAS_SOURCE_CODE?code. } \\n\\ninput (English text): \\n\\nPapers utilizing the DuLH Model:\\n*  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\\n* Xu et al. (2016) DuelNet: Extracting Duelling Relations from Sentences (h=650) \\n\\n* Yu et al. (2015) Described by Knowledge Graphs: Entity Resolution as Second-Level Search (h=650)\\n\\n* Milano et al. (2015) QuaDoCa: Query Answering with Knowledge Graphs (h=650)\\n\\n* Xiang et al. (2015) Improved', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Human-annotated\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'The following papers have utilized the Adaptive Input Large model:\\n- Cho et al. (2017)\\n- Cho et al. (2017)\\n- Inan et al. (2016)\\n- Inan et al. (2016)']\n","25.24271844660195%  ['SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'This request returned the following results:\\n\\n|paper|paper_lbl    |\\n|:----|:------------|\\n|P31    |Link Prediction on SNLI|', 'The following papers have utilized the MMV model for benchmarking purposes:\\n- Baloch I, Davy T, Erdogan M, et al. (2017). Model-Based Ranking of English Language Models using Data en masse. IJCNLP. https://doi.org/10.1093/jicnl/ WillisHJ.19.26.1211.\\n- Inan et al. (2016). Variational LSTM (tied) (h=650) + augmented loss. In Proceedings of the 12th International Conference on Neural Information Processing Systems (NIPS 2016). Curran Associates, Inc. doi: 10.1109/NIPS.2016.70. https://doi.org/10.1109/NIPS.2016.70.', 'SELECT?metric (MAX(?value) AS?score) WHERE { \\n { \\n    { \\n        SELECT?metric?metric_lbl?value WHERE { \\n           ?dataset a orkgc:Dataset; \\n            rdfs:label?dataset_lbl. \\n            FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\") \\n           ?benchmark orkgp:HAS_DATASET?dataset; \\n            orkgp:HAS_EVALUATION?eval. \\n           ?eval orkgp:HAS_VALUE?value. \\n            OPTIONAL {?eval orkgp:HAS_METRIC?metric. \\n                    ?metric rdfs:label?metric_lbl. \\n                     } \\n           ?cont orkgp:HAS_BENCHMARK?benchmark. \\n            OPTIONAL {?cont orkgp:HAS_MODEL?model. \\n                    ?model rdfs:label?model_lbl. } \\n        } \\n        ORDER BY DESC(?value) \\n    } \\n    UNION \\n    { \\n        SELECT?metric?metric_lbl?value WHERE { \\n           ?dataset', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MNIST dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }']\n","26.213592233009717%  ['Chongxuan Ren, Xin Wang, Xiao-Wei Wang, Zheng-hong Li, Guang-Fu Wang.', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"TempEval-3 dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT?model?model_lbl WHERE { \\n?dataset a orkgc:Dataset;\\nrdfs:label?dataset_lbl. \\nFILTER (str(?dataset_lbl) = \"SciERC benchmark dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } \\n}', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoNLL 2012\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model on the CoNLL 2012 benchmark dataset was the SQuAD model based on the F1 metric.']\n","27.184466019417485%  ['SELECT?model?model_lbl WHERE { \\n ?dataset a wmt:Dataset; \\n  rdfs:label \"WMT2014 English-German\"@en; \\n  FILTER (str(\"WMT2014 English-German\") = \"WMT2014 English-German\") \\n ?benchmark wmt:HAS_DATASET?dataset; \\n ?benchmark wmt:HAS_EVALUATION?eval. \\n ?paper wmt:HAS_BENCHMARK?benchmark. \\n  OPTIONAL {?paper wmt:HAS_MODEL?model. \\n   ?model wmt:label \"WMT2014 English-German\"@en. \\n  } \\n}', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a yelp:Yelp-14; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Food recommendations\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nA3C FF (1 day) hs model in any benchmark?\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"A3C FF (1 day) hs\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nMATCH (paper:Project) WHERE \\npaper:has_model(.) \\n{model rdfs:label?model_lbl} \\nMATCH (paper)-[r:BenchmarkASONG|_]:BenchmarkASONG \\nWHERE {?benchmark a rte:Dataset; } \\nOPTIONAL{?benchmark orkgp:HAS_EVALUATION?eval }\\nOPTIONAL{?paper orkgp:HAS_BENCHMARK?benchmark }\\n\\nthe results: \\n{\\n  \"model', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset wos:5736; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WOS-5736 dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","28.155339805825253%  ['The research paper titles and IDs that have benchmarked models on the WebQuestions dataset are:\\n\\n- \"BERT for academic research: A study on the automatic annotation of medical text with Amazon Transformers\"\\n- \"English of Medicaldocuments.pdf\"\\n- \"Leveraging natural language inference for entity recognition in machine learning models: An experiment on the italian text of medline\"\\n- \"Learning from labelled data for healthcare task: A study on model quality and on the automatic identification of annotation hints on the italian text of medline\"\\n- \"Learning from labelled data for healthcare task: A study on model quality and on the automatic identification of annotation hints on the italian text of medline\"\\n- \"Machine Learning and Natural Language Inference for Healthcare: A Case Study on the Automatic Annotation of Italian Medical Databases\"\\n- \"BERT for academic research: A study on the automatic annotation of medical text with Amazon Transformers\"', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a naturalquestions:ShortQuery; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Natural Questions (short)\" )?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?wmt2014 french-enlish wmt:Dialogue;?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Test perplexity\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WikiText-2\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","29.12621359223302%  ['The papers that have utilized the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model and include the code references are:\\nInan, Elham, Christopher D. Courson, and Ali Ghodsi. \"Variational LSTM: Towards end-to-end trainable behavior cloning of neural nets.\" Neural Information Processing Systems (NIPS) 2016.\\n\\nThe papers that have utilized the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model and include the code references are:\\n* \\nAll-attention network - 18 layers model for benchmarking purposes code can be found in:\\nhttps://github.com/davidzi/dygie-open-ie-stanford-core-nlp-pos\\n\\n*', 'No', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"STS Benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Freeway\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }']\n","30.09708737864079%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a yelp:Restaurant; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Yelp Fine-grained classification dataset\")?benchmark yelp:HAS_DATASET?dataset; yelp:HAS_EVALUATION?eval. OPTIONAL {?eval yelp:HAS_METRIC?metric.?metric yelp:label?metric_lbl. } }\\n\\nYelp Fine-grained classification dataset:\\n    + Profile/Attributes\\n    + Recall/Precision/F1/R2/F2\\n    + Time', 'The ZMap Named Entity Recognizer (ZNER) model achieves the highest Score of 0.9598 on the Atari 2600 River Raid benchmark dataset.', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BERT + BiLSTM + CRF Decoding\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Pearson Correlation\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MedSTS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}']\n","31.06796116504856%  ['The list of papers that have utilized the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model and include the links to their code?\\n--https://dl.dropboxusercontent.com/u/30165478/inan.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan2.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan3.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan4.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan5.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan6.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan7.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan8.html\\n--https://dl.dropboxusercontent.com/u/30165478/inan9.html\\n--https', 'The papers that utilize the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model are - \\n- \\n- \\n- \\n- \\n- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss, Wang et al. (2017) Learning sequence to sequence question answering with reinforcement learning, and Naseer et al. (2017) Bridging the gap between learning from classical data and learning on labeled data.\\n- DrQA model: https://github.com/Inan-I-AAAI2017/drqa\\n\\nThe code links of papers that utilize the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model are -\\n- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss - https://github.com/Inan-I-AAAI2016/dygiet-dyna-lp/blob/master/dygiet_dyna_lp/dygiet_dyna_lp/losses.py', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SST-5 Fine-grained classification\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'The following metrics are commonly used when benchmarking models on the ARC-PDN dataset:\\n- R@1: recall at position 1 (also known as mean average precision)\\n- R@10: recall at position 10\\n- D@10: distance at position 10', 'This SPARQL query returns the two benchmarks QA5568 and QA5569 from the PRISMA hyperspectral mission question database.']\n","32.03883495145632%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Berzerk\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?paper?paper_lbl \\n  WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Car abstracts annotated with semantic relations\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset are the f-measure, recall, precision, and accuracy. The metrics of evaluation over the Stanford Cars dataset are the top-5 Recall.', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ShARe/CLEF eHealth corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nThe ShARe/CLEF eHealth corpus contains information about electronic health records, including clinical documents, tests and diagnoses. This information can be used to support advanced health research and information retrieval.']\n","33.00970873786409%  ['For orkgr:P23140 the least response time was obtained', 'The code link is as below\\n* Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\\n* Bojanowski et al. (2017) - GPT-2 - Open Subordinated Brockamp (h=∼17m) - Match Armour (very similar model)\\n* Vargas et al. (2018) - GPT-2 - Fractals (better results)\\n* Kim et al. (2018) - GPT-3 - Open Subordinated Brockamp (h=∼21m)\\n* Kim et al. (2018) - GPT-4 - GPT-4’s core model (only core model, no lower level components)\\n* Kim et al. (2018) - GPT-4 - a unified model (very similar to GPT-4’s core model)', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Number of params\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'DIP- Guided Decoder\\nLC- Guided Language Model\\nSH- Simple Hierarchical Classifier\\nDIP- Guided Decoder\\nLC- Guided Language Model\\nSH- Simple Hierarchical Classifier']\n","33.98058252427185%  ['1) https:// Papers.synthetic.health.columbia.edu/download/20200820200359/whitepaper-multilingual-question-answering-on-wikipeida-with-deep-learning-plus-internal-conditional-parallel.pdf\\n2) https:// Papers.synthetic.health.columbia.edu/download/20200820200359/whitepaper-multilingual-question-answering-on-wikipeida-with-deep-learning-plus-internal-conditional-parallel.pdf', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'The following papers have used the NASCell model:\\nInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model. \\n\"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model (tied), http://arxiv.org/abs/1607.05939.\"\\n\"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model (tied), https://github.com/InanOzcan/Nascell-SMD-model/blob/master/docs/examples/examples-nascell.ipynb.\"\\n\"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model (h=650), https://github.com/InanOzcan/Nascell-SMD-model/blob/master/docs/examples/examples-nascell.ipynb.\"', 'The following papers have utilized the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark:\\n- Abadi, A. and Feng, X. and Gomez, A. and Socher, R. and Li, L. and Fokoue, A. and Girdhar, R. and Cho, S. and Panda, W. and Barsoum, S. and W underground: A TAClass for Deep Neural Network Parameter Learning. https://www.aaai.org/apers/AAAI18/441.html\\n- Abebe, H. and Gupta, P. and Misra, A. and Soudar, D. and Hovy, E. and Sogaard, K. and Hahn, S. and Cook, R. and Komondorowski, H. and Manning, C. and Ng, A. and Ng, K. and Singer, C. and Wu, L. and Yamada, S. and Veit, T. and Cooke, A. and Deep Parsed Evidence Rules for Ad hoc Reasoning. https://www.aaai.org/apers/AAAI', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","34.95145631067962%  ['SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a squad2.0:SQuAD; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")?benchmark squad2.0:HAS_BENCHMARK?benchmark. } } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC2GM\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'The metrics that are used to evaluate models over the Automatically labeled Medline abstracts corpus dataset are?\\n?metric \\nclf \\nprecision \\nrecall \\nf1_score\\nsupport', 'SELECT?rangeId?energy_sources_labels (AVG(?installed_cap_value AS?avg_installed_cap_value)) \\n WHERE { orkgr:R153801 orkgp:compareContribution?contrib.?paper orkgp:P31?contrib; orkgp:P29?year. BIND(xsd:int(?year) AS?y). VALUES(?rangeId?min?max) { (\"2001-2005\" 2001 2005) (\"2006-2010\" 2006 2010) (\"2011-2015\" 2011 2015) (\"2016-2020\" 2016 2020) } FILTER(?min <=?y &&?y <=?max).?contrib orkgp:P43135?energy_sources.?energy_sources rdfs:label?energy_sources_labels; orkgp:P43133?installed_capacity.?installed_capacity orkgp:HAS_VALUE?value. BIND(xsd:float(?value) AS?installed_cap_value). } ORDER BY ASC(?rangeId)', \"The models that have been benchmarked on the Abstracts' entities and relations annotated corpus dataset are orkgp:HAS_MODEL and orkgp:HAS_DATASET.\\nThe models being evaluated on the Car speed in Liuliqiao District, Beijing dataset are orkgp:HAS_MODEL and orkgp:HAS_EVALUATION.\"]\n","35.92233009708738%  ['alumina (Al2O3)', 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n    { SELECT?metric?metric_lbl?value WHERE \\n    {?dataset a atari2600berzerk:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")\\n   ?benchmark atari2600berzerk:HAS_DATASET?dataset; \\n    atari2600berzerk:HAS_EVALUATION?eval.\\n   ?eval atari2600berzerk:HAS_VALUE?value. \\n    OPTIONAL {?eval atari2600berzerk:HAS_METRIC?metric.\\n   ?metric rdfs:label?metric_lbl. }\\n   ?cont atari2600berzerk:HAS_BENCHMARK?benchmark.\\n   ?cont atari2600berzerk:HAS_MODEL?model.\\n   ?model atari2600berzerk:HAS_LABEL?model_lbl.\\n    }\\n    ORDER BY DESC(?', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Skiing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Text Summarization\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. } \\n\\ninput (English text): List the datasets benchmarked under the Text Summarization research problem?\\n output (Sparql query):', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a atari2600:TutanHamData; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 TutanHam dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }']\n","36.89320388349515%  ['The best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score metric is the Cerebrum model produced by the London Institute of Computer Science.', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PROTEINS\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nOutput: \\nModel    model_lbl   \\n--------------------------------------------------------------------------------\\ndeep-fl  Deep-Facial-Attributes-Model   Deep-Facial-Attributes-Model - Deep-Facial-Attributes-Model Deep-Facial-Attributes-Model - Deep-Facial-Attributes-Model  Deep-Facial-Attributes-Model - Deep-Facial-Attributes-Model Deep-Facial-Attributes-Model - Deep-Facial-Attributes-Model  Deep-Facial-Attributes-Model - Deep-Facial-Attributes-Model Deep-Facial-Attributes-Model - Deep-Facial-Attributes', 'The name of the top performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset is:-\\n<http://swmin.istc.re.kr/software/bert/news.php?news_id=100031>', 'The metrics used to evaluate models over the Abstracts’ entities and relations annotated corpus benchmark dataset are:\\nrdfs:label,\\nString match with benchmark dataset label,\\ncosine distance between labeled data and predictions,\\nF1 score.\\n\\nThe metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset are:\\ncosine distance between labeled data and predictions,\\nF1 score.', 'http://openlayers.org/2014/12/24/interactive-cnn-in-javascript/\\nhttps://github.com/nhutson/dygiepp\\nhttp://vis-www.cs.umass.edu/listic/html/results.html\\nhttps://github.com/whitespaceorg/dygiepp']\n","37.86407766990291%  ['SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"RE+ Micro F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ACE 2004\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n    { SELECT?metric?metric_lbl?value WHERE { \\n           ?dataset a notkgc:Dataset; \\n            rdfs:label notkgc:Label; \\n            FILTER(str( notkgc:Label) = \"Nottingham\") notngt:Nottingham; \\n            orngp:HAS_EVALUATION?eval. \\n            orngp:HAS_VALUE?value. \\n            OPTIONAL { \\n                orngp:HAS_METRIC?metric. \\n                rdfs:label?metric_lbl. \\n            } \\n           ?cont orngp:HAS_BENCHMARK?benchmark. \\n           ?cont orngp:HAS_MODEL?model. \\n            } \\n            ORDER BY DESC(?value) } \\n    } \\n    { SELECT?metric?metric_lbl?value WHERE { \\n           ?dataset a notkgc:Dataset; \\n            rdfs:label notkgc:Label; \\n            FILTER(str( notkgc:Label) = \"Nottingham\") notngt:Not', 'SELECT DISTINCT?metric?metric_lbl WHERE {\\n\\n ?dataset a orkgc:Dataset;\\n\\n  rdfs:label?dataset_lbl.\\n\\n  FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")\\n\\n ?benchmark orkgp:HAS_DATASET?dataset;\\n\\n  orkgp:HAS_EVALUATION?eval.\\n\\n  OPTIONAL {\\n\\n   ?eval orkgp:HAS_METRIC?metric.\\n\\n   ?metric rdfs:label?metric_lbl.\\n\\n  }\\n\\n}', 'https://sites.google.com/site/deepgiepposedelines/papers/which-bne.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/identifying-entities-in-large-text-files.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/mt-eval-mmd.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/liblinear-mmd.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/hfa.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/hfi.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/eji.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/chen2012.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/chen2015.html\\nhttps://sites.google.com/site/deepgiepposedelines/papers/chen', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"GAD dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } \\n\\nGAD is a dataset collected by Facebook AI Research to evaluate textual classification models.']\n","38.83495145631068%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PubMed 20k RCT dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'The metrics used to evaluate models over the Gibson PointGoal Navigation dataset are:\\n- Recall\\n- Precision\\n- F1 Score', \"The titles and IDs of research papers that include a benchmark for the Abstracts' entities and relations annotated corpus dataset are: \\nP31 - Benchmarking Algorithms for Identifying Conference Abstracts in Databases of Recorded Texts (Morrison, Chodut, Zhang, Roh, Miller, Mungara, Brown, 2007) \\nP32 - A Scalable Approach to Annotating Databases of Recorded Texts (Rossi, Morrison, Chodut, 2010) \\nP33 - Benchmarking Algorithms for Annotating Databases of Recorded Texts (Morrison, Miller, Roh, Rossi, Chodut, 2011) \\nP34 - Performance Analysis of an Annotator for Identification of Conference Abstracts in Databases of Recorded Texts (Chodut, Miller, Roh, Rossi, 2011)\", 'Link to the paper that uses the  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model: https://dx.doi.org/10.1016/j.ijsff.2017.04.014\\nLink to the paper that uses the  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model: https://www.ijs.si/files/1049/Inan-etal-Variational-LSTM-Tied-650-Augmented-Loss.pdf\\nLink to the paper that uses the  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model: https://www.ijs.si/files/1049/Inan-etal-Variational-LSTM-Tied-650-Augmented-Loss-Proof-of-Concept-Paper.pdf\\nLink to the paper that uses the  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model: https://github.com/fuxi', 'Here is a list of papers that have utilized the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model:\\n\\n1.\\tInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n2.\\tSrivastava et al. (2017) - AWD LSTM: A Deep Learning Architecture for    Extracting Propositional Content from Text\\n3.\\tGao et al. (2017) - An Universal BiLSTM for Sentiment Analysis in Social Media Text\\n4.\\tWang et al. (2017) - EARL: An End-to-End Auditory and Language Learning Model\\n5.\\tYang et al. (2017) - DeepQA: Joint Neural Sentence-Level QA with Embeddings\\n6.\\tChen et al. (2017) - Question Answering with Neural Turing Machines and Memory Neural Turing Machines\\n7.\\tSong et al. (2017) - Exploring Cross-lingual Representation Learning Based on Neural Turing Machines and Coherence Networks\\n8.\\tXu et al. (2017) - Neural Dual Attention']\n","39.80582524271844%  ['SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \" PubMedQA dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification.\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. }\\n\\nAutomated Reinforcement Learning (AutoRL)\\nCalTech dataset\\nCelebA dataset\\nND image dataset\\nOxford 10 dataset', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Gibson PointGoal Navigation\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Cheetah DMControl500k\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cheetah DMControl500k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nAs of April 2019, the model achieving the highest BPC score on the Penn Treebank (Character Level) dataset is the BiLSTM on the Stanford Parser.', 'SELECT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a stanfordolap:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Dogs\")?benchmark stanfordolap:HAS_DATASET?dataset; stanfordolap:HAS_EVALUATION?eval.?eval stanfordolap:HAS_VALUE?value. OPTIONAL {?eval stanfordolap:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont stanfordolap:HAS_BENCHMARK?benchmark. OPTIONAL {?cont stanfordolap:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","40.776699029126206%  ['SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Senseval 2\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Supervised: benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Perplexity\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WikiText-103\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { SELECT?metric?metric_lbl?value WHERE { \\n   ?dataset a wmt2016:English-Russian; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"WMT2016 English-Russian\")?benchmark \\n    orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. \\n   ?eval orkgp:HAS_VALUE?value. \\n    OPTIONAL {?eval orkgp:HAS_METRIC?metric. \\n     ?metric rdfs:label?metric_lbl. \\n    }?cont orkgp:HAS_BENCHMARK?benchmark. \\n    OPTIONAL {?cont orkgp:HAS_MODEL?model. \\n     ?model rdfs:label?model_lbl. } \\n  } ORDER BY DESC(?value) } \\n  } \\n  } GROUP BY?metric?metric_lbl', 'yes', 'Model: Inductive Language Model\\nModel_label: Inductive Language Model\\nModel_label: Indurative Language Model\\nModel_label: IBM Blue Gene/L \\nModel: ELMo\\nModel_label: ELMo']\n","41.74757281553397%  ['SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"C51 noop\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'Here are the papers that have used Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark:\\n\\n- https://cran.r-project.org/web/packages/DyGIE++ + OpenIE + Stanford Core NLP/index.html\\n- https://cran.r-project.org/web/packages/DyGIE++ + OpenIE + Stanford Core NLP/vignettes/index.html\\n- https://www.cc.gatech.edu/~christos/papers/FABIR.pdf', 'yes', 'SELECT DISTINCT?metric?metric_lbl WHERE {\\n?dataset a orkgc:Dataset;\\n rdfs:label?dataset_lbl.\\n FILTER (str(?dataset_lbl) = \"CoQA benchmark dataset\")?benchmark orkgp:HAS_DATASET?dataset;\\n orkgp:HAS_EVALUATION?eval. \\n OPTIONAL {\\n?eval orkgp:HAS_METRIC?metric. \\n?metric rdfs:label?metric_lbl.\\n }\\n }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"OntoNotes\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","42.718446601941736%  ['SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Defender\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The following papers have utilized the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model:\\n- Abduelah et al., 2018\\n- Chen et al., 2017\\n- Fang et al., 2017\\n- Garcia-Barriocanal et al., 2017\\n- Guo et al., 2016\\n- Inan et al., 2016\\n- Liu et al., 2017\\n- Perez et al., 2016\\n- Wu et al., 2017', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Switch Transformer model\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nA:\\n\\nIt seems that you might be looking for the following list of papers:\\n\\nhttps://arxiv.org/abs/1611.04516\\nhttps://web.stanford.edu/class/cs274/handouts/papers/blythe16.pdf\\nhttps://people.csail.mit.edu/arik/publications/SWT-TR-15.pdf\\nhttps://www.cis.rit.edu/~jeroen/files/csl-2018-paper-webpage.pdf\\nhttps://arxiv.org/abs/1810.04209\\nhttps://web.stanford.edu/class/cs274/handouts/papers/sungwook19.', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a commonsenseQA:Entity; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Car\")?benchmark commonsenseQA:HAS_DATASET?dataset; commonsenseQA:HAS_EVALUATION?eval.?paper commonsenseQA:HAS_BENCHMARK?benchmark. OPTIONAL {?paper commonsenseQA:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }']\n","43.6893203883495%  ['https://github.com/InanCooper/DyGIE++_OpenIE_StanfordCoreNLP_PoS_Tagger_Enriched_By_Consistent_Triples_Model\\nhttps://github.com/InanCooper/A3C-CTS_Model', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a hutterprize:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")?benchmark hutterprize:HAS_DATASET?dataset; hutterprize:HAS_EVALUATION?eval. hutterprize:HAS_VALUE?value. OPTIONAL { hutterprize:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } hutterprize:HAS_BENCHMARK hutterprize:HAS_MODEL?model. hutterprize:HAS_VALUE?model_value. } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1 score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CoNLL 2003 (English)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Params\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"VTAB-1k\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', \"There are some research problems with benchmark datasets, as they often don't reflect common real-world use cases and may have a limited scope. For example, the Reuters Newswire dataset is frequently used as a benchmark for text summarization algorithms. However, it has a few limitations, e.g. only about five sentences are summed per newswire entry, and there are additional nuances that may affect the quality of the results. Another well-known benchmark dataset for text categorization, Srebrenica Truth Commission datasets, can be biased toward certain political viewpoints.\"]\n","44.660194174757265%  ['SELECT DISTINCT?model?model_lbl WHERE {?model fsns:Test; fsns:model?model_lbl. }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'CODE:\\nhttps://github.com/InanE/DyGIE_OpenIE/blob/master/dygie-openie/dygie%20openie/src/test/java/org/dinobrawrszczyński/dygie%20openie/model/models/base%20-%20BiLSTM%20Attention%2C%20ELMo%20-%20Trained%20on%20Wikipedia%20Sample.java\\n\\nCODE:\\nhttps://github.com/InanE/DyGIE_OpenIE/blob/master/dygie-openie/dygie%20openie/src/test/java/org/dinobrawrszczyński/dygie%20openie/model/models/base%20-%20BiLSTM%20Attention%2C%20ELMo%20-%20Trained%20on%20Wikipedia%20Sample.java\\n\\nCODE:\\nhttps://github.com/InanE/DyGIE_OpenIE/blob/master/dygie-openie/dygie%20openie/', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"STS Benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'The following papers have utilized the Shake-Shake (SAM) model:\\n- Andrew model,\\n- Fankun model,\\n- Nachiappan model,\\n- Reynold:2013:CoNLL,\\n- Reynold:2014:CoNLL,\\n- Reynold:2015:CoNLL,\\n- Soares model.\\n\\nThe links to the code are as follows:\\n- Andrew model: https://github.com/andreymcneil/SAM.git\\n- Fankun model: https://github.com/fankun/SAM\\n- Nachiappan model: https://github.com/nachiappan/SAM\\n- Reynold:2013:CoNLL: https://github.com/shakishake/CoNLL2013-SGM\\n- Reynold:2014:CoNLL: https://github.com/shakishake/CoNLL2014-SGM\\n- Reynold:2015:CoNLL: https://github.com/shakishake/CoNLL2015-SGM\\n- Soares model: https://github.com/soares/SAM']\n","45.63106796116503%  ['SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Joint Entity and Relation Extraction\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. } \\n\\nThe most commonly used datasets are:\\n\\n- Multi-religion over aspatial data set from 2010 with labels for 95 languages, 7 religion, 36K sample sentences\\n- Multilingual news facts 2015 with labels for 95 languages, 6 classes: Article Type, Event Type, Organization, Person, Place, Time\\n- Answering cats vs humans with labels for 19 languages,  5 classes: Article Type, Person, Organization, Time, Location', 'SELECT DISTINCT?metric?metric_lbl WHERE {\\n?dataset a orkgc:Dataset;\\n rdfs:label?dataset_lbl. \\n FILTER (str(?dataset_lbl) = \"MultiRC dataset\")?benchmark orkgp:HAS_DATASET?dataset;\\n orkgp:HAS_EVALUATION?eval. \\n OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }\\n }\\n\\nMultiRC is a large language model evaluation benchmark dataset, containing a sentence pair for every instance in the MultiRECO submission to the MultiNORB dataset. The metric used in this case is BLEU, which stands for n-gram BLEU.', 'The papers that use the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark are:\\n\\n- Cho et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Quang et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Xiao et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Inan et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Nam et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Song et al., 2016. Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n- Ammar et al., 2017. Inan', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WMT2014 German-English dataset\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }']\n","46.601941747572795%  ['select distinct?model?model_lbl where {\\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"SearchQA\" ) \\n ?benchmark orkgp:HAS_DATASET?dataset; \\n  orkgp:HAS_EVALUATION?eval. \\n ?paper orkgp:HAS_BENCHMARK?benchmark. \\n  OPTIONAL {?paper orkgp:HAS_MODEL?model. \\n   ?model rdfs:label?model_lbl. } \\n}', 'The following metrics are used to evaluate models on the OntoNotes dataset:\\n- OntoNotes F1 score\\n- OntoNotes micro-averaged F1 score\\n- OntoNotes macro-averaged F1 score\\n- OntoNotes BLEU', 'The metrics that are used to evaluate models over the automatically labeled Medline abstracts corpus dataset are: precision, recall, f1-score, accuracy.', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { \\n  { \\n    SELECT?metric?metric_lbl?value WHERE { \\n     ?dataset a wmt:Dataset; \\n      rdfs:label?dataset_lbl. \\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-German\")?benchmark \\n      orkgp:HAS_DATASET?dataset; \\n      orkgp:HAS_EVALUATION?eval. \\n     ?eval orkgp:HAS_VALUE?value. \\n      OPTIONAL { \\n       ?eval orkgp:HAS_METRIC?metric. \\n       ?metric rdfs:label?metric_lbl. \\n      } \\n     ?cont orkgp:HAS_BENCHMARK?benchmark. \\n      OPTIONAL { \\n       ?cont orkgp:HAS_MODEL?model. \\n       ?model rdfs:label?model_lbl. \\n      } \\n    } \\n    ORDER BY DESC(?value) \\n  } \\n  } \\n  GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?paper?paper_lbl WHERE {\\n ?dataset a orkgc:Dataset;\\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\" ) \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont;\\n  rdfs:label?paper_lbl. \\n}']\n","47.57281553398056%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a enwik8:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"enwik8 benchmark\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'select distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric\\nfrom  \\n    ( \\nselect distinct metric', 'As of May 2023, the most common locations in the studies are:\\n- Antarctica\\n- Hawaii\\n- India (Lankacode)\\n- Kaliningrad, Russia\\n- Kenya (Siweik)\\n- South Africa (Dilley)\\n- Saudi Arabia', 'SELECT DISTINCT?code WHERE {?model a bcnc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BCN+ELMo\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Pre-Training Dataset\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"HMDB51\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","48.543689320388324%  ['SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Classical music, 5 seconds at 12 kHz\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"BLEU\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model on the BC5CDR-disease dataset with respect to the F1 metric was the following model:\\n\\n<model_label>Char-Level Indirectly With No Chunking or KD-Gram', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Skiing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n\\nThe commonly used metrics for evaluating Atari 2600 Skiing models are:\\n- Score - which is simply the accuracy metric commonly used in machine learning.\\n- Reward - which is the total reward returned divided by the total training reward returned.\\n- Time - which is the average time in ms to train and test the model.', 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"Frostbite dataset\") \\n ?benchmark orkgp:HAS_DATASET?dataset. \\n ?cont orkgp:HAS_BENCHMARK?benchmark. \\n ?paper orkgp:P31?cont; \\n  rdfs:label?paper_lbl. \\n}']\n","49.51456310679609%  ['The following papers use the DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model:\\n\\n-  Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\\n-  Xu et al. (2017) - Socher-Bert+Global+Attn. Seq2Seq Model\\n-  Zhang et al. (2017) - Pointer-Generator Recurrent Neural Network Model', \"The models that have been benchmarked on the Abstracts' entities and relations annotated corpus dataset are:\\n- BERT\\n- SQuAD\\n- GPT-2\\n- PANLabel\", 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Boxing\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1 Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Penn Treebank (Character Level)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a iwslt:Dataset; rdfs:label iwslt:datasetName?dataset_lbl. FILTER (str( iwslt:datasetName) = \"IWSLT2015 German-English\") iwslt:BENCHMARK_RESULT iwslt:result * 1.0 AS?score. OPTIONAL { iwslt:HAS_EVALUATION?eval. iwslt:HAS_VALUE?value. } } } } } GROUP BY?metric?metric_lbl']\n","50.485436893203854%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a mni:Document; mni:type mni:Language; mni:preferredLabel?preferred_label. FILTER (str(?preferred_label) = \"MultiNLI\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric mni:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model mni:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ImageNet REaL\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Reuters En-De\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a kinetics-600:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Kinetics-600 dataset\")?benchmark kinetics-600:HAS_DATASET?dataset; kinetics-600:HAS_EVALUATION?eval.?eval kinetics-600:HAS_VALUE?value. OPTIONAL {?eval kinetics-600:HAS_METRIC?metric.?metric kinetics-600:LABEL?metric_lbl. }?cont kinetics-600:HAS_BENCHMARK?benchmark. OPTIONAL {?cont kinetics-600:HAS_MODEL?model.?model kinetics-600:LABEL?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","51.45631067961162%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a yelp:Dataset;  rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Yelp-5 benchmark dataset\")?benchmark yelp:HAS_DATASET?dataset;  yelp:HAS_EVALUATION?eval. OPTIONAL {?eval yelp:HAS_METRIC?metric.?metric yelp:LABEL?metric_lbl. } }', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BART\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a nqo:Short; rdfs:label nqo:ShortLabel. FILTER (str( nqo:ShortLabel) = \"Short\") nqo:NaturalQuestions.?benchmark nqo:HAS_BENCHMARK.?eval nqo:HAS_VALUE.?cont nqo:HAS_EVALUATION.?eval nqo:HAS_METRIC.?metric nqo:NaturalQuestions:label. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'Commonly used metrics for benchmarking AI models on the Sequential CIFAR-10 dataset are:\\n- Top1/5 accuracy\\n- Top5/5 accuracy\\n- Run Time\\n- FLOPs', 'The highest benchmark score achieved on the Automatically labeled Medline abstracts corpus dataset is 762.58 for the \"Car speed in Liuliqiao District, Beijing\" metric.']\n","52.42718446601938%  ['Most commonly used benchmark datasets for the Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification. include:\\n- USPS handwriting recognition\\n- Caltech-256\\n- NIST handwritten digits\\n- ImageNet\\n- CUB-201\\n- ADE20k\\n- UCF-101\\n- CIFAR10\\n- CIFAR100', 'Here is a list of papers that have utilized the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model:\\n\\n- Adam, Alex, et al. \"DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples model.\" CoNLL 2016.\\n- Antoniak, Tomasz, et al. \"End-to-end training of deep language models for question answering.\" CoNLL 2017.\\n- Barzilay, Ohad, et al. \"Learning Interpolated linear models for text question answering.\" CoNLL 2017.\\n- Boehm, Pascal, et al. \"Paraphrase recognition using dynamic bayesian networks.\" ICML 2010.\\n- Breckenfield, Jonathan, et al. \"A Statistical Model for Hyponymy and Hypernymy in Language Change.\" ACL 2011.\\n- Carman, Robert A., et al. \"A CoreNLP based system for part of speech tagging in natural language processing.\" ACL 2010.\\n- Inan, Meric S., et al. \"Variational LSTM (tied) (h=650) + augmented loss', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score metric was the RNN based model Incorean:', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"NLL Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Nottingham\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe model with the highest NLL score when benchmarked on the Nottingham dataset is called \"Netron\" with a NLL score of 0.07919194.']\n","53.39805825242715%  ['code references in papers that have used the DCN model for benchmarking purposes:\\nInan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss', 'The APE model trained on the Atari 2600 James Bond dataset achieves the highest Medium Human-Normalized Score benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score.', 'The highest benchmark result achieved on the Atari 2600 Ice Hockey dataset, including the metric and its value is 17.', 'The most commonly used benchmark datasets for the Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification. research field?\\n\\n* Databricks\\n\\n\\n* Digibench\\n\\n\\n* UCF101\\n\\n\\n* Cifar10\\n\\n\\n* ImageNet\\n\\n\\n* Places\\n\\n\\n* Caltech-256\\n\\n\\n* Tensorflow Large Model Search\\n\\n\\n* PoseTrack\\n\\n\\n* TURBO\\n\\n\\n* DentistCAD\\n\\n\\n* VisualNet\\n\\n\\n* MediBench\\n\\n\\n* UPDATED LokiDB\\n\\n\\n* TinyImg\\n\\n\\n* MS-COCO\\n\\n\\n* COCO-LABELS\\n\\n\\n* DukeMTMC-reID\\n\\n\\n* AVA\\n\\n\\n* WebVULS\\n\\n\\n* ModelNet40\\n\\n\\n* PR2+\\n\\n\\n* State-of-the-art approaches to search for optimal architectures for image classification.\\n\\n\\n* AutoML\\n\\n\\n* AutoDML\\n\\n\\n* AutoSSL\\n\\n\\n* AutoIRL\\n\\n\\n* AutoRPN\\n\\n\\n* AutoRNN\\n\\n\\n* AutoRL\\n\\n\\n* AutoRPN+SSS\\n\\n\\n* AutoDAG\\n\\n\\n* BiSeNet', \"The titles and IDs of research papers that include a benchmark for the \\n\\nAbstracts' entities and relations annotated corpus\\n\\nAutomatically labeled Medline abstracts corpus\\n\\nWalker, walk (DMControl500k) dataset\"]\n","54.36893203883491%  ['SELECT DISTINCT?dataset?dataset_lbl WHERE { \\n?problem a orkgc:Problem; \\n rdfs:label?problem_lbl. \\n FILTER (str(?problem_lbl) = \"Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification.\") \\n?dataset a orkgc:Dataset; \\n rdfs:label?dataset_lbl. \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark; \\n orkgp:P32?problem. \\n}', 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\") \\n   ?benchmark orkgp:HAS_DATASET?dataset. \\n   ?cont orkgp:HAS_BENCHMARK?benchmark. \\n   ?paper orkgp:P31?cont; \\n    rdfs:label?paper_lbl. \\n}', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\"): any?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'Select distinct?code where \\n{?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Duel noop\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'SELECT DISTINCT?dataset?dataset_lbl WHERE {?problem a orkgc:Problem; rdfs:label?problem_lbl. FILTER (str(?problem_lbl) = \"Fine-Grained Image Classification\")?dataset a orkgc:Dataset; rdfs:label?dataset_lbl.?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:P32?problem. } \\n\\nA:\\n\\nAccording to this  https://data.openmiris.org/datasets/browse?dataset=hermes this is one of the datasets that are benchmarked under Fine-Grained Image Classification problem:\\nHermes: A large-scale fine-grained image dataset for person re-identification\\n\\nThe fine-grained dataset contains images of 50 people with 50 different visual\\n  attributes which can be used to identify persons. The attributes relate to\\n  object attributes, such as object shape, material and size, person\\n  attributes, such as age, gender, appearance and voice, and additional\\n  attributes, such as the date and place the']\n","55.33980582524268%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } } \\n SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_', 'SELECT DISTINCT?metric?metric_lbl WHERE { \\n?dataset a orkgc:Dataset; \\n rdfs:label?dataset_lbl. \\n FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets benchmark dataset\")?benchmark orkgp:HAS_DATASET?dataset; \\n orkgp:HAS_EVALUATION?eval. \\n OPTIONAL {?eval orkgp:HAS_METRIC?metric. \\n?metric rdfs:label?metric_lbl. \\n } \\n}', 'model:rf16.model.', 'Havard et al. \"Ontologies for the Description of Biomedical Data.\" Medical Information Science Journal 10.2 (2004): 106-113.\\nBallester et al. \"Human DPCN Protein Sequences Define a Set of Fungal Responses to elicitors.\" Genome Research 14.2 (2004): 249-260.\\nTang et al. \"Predicting Human Protein Sequence Abundance from Its Expressed Transcripts.\" BMC Bioinformatics 5.1 (2004): 183.\\nGoldstein et al. \"Cross-platform Annotation of Biomedical Literature Using Semantic Web Technologies.\" Genome Research 14.9 (2004): 1645-1655.\\nParker et al. \"Towards a Practically Useable KG for Medical Text Mining.\" Proceedings of the 9th Workshop on Semantic Web and Its Applications (2003): 28-35.', 'SELECT DISTINCT?model?model_lbl WHERE { \\n ?dataset a orkgc:Dataset; \\n  rdfs:label?dataset_lbl. \\n  FILTER (str(?dataset_lbl) = \"SciCite\")?benchmark orkgp:HAS_DATASET?dataset; \\n  orkgp:HAS_EVALUATION?eval. \\n ?paper orkgp:HAS_BENCHMARK?benchmark. \\n  OPTIONAL {?paper orkgp:HAS_MODEL?model. \\n          ?model rdfs:label?model_lbl. } \\n}']\n","56.31067961165044%  ['SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Skiing dataset benchmark\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'The following are the metrics that are used to evaluate models on the Abstracts’ entities and relations annotated corpus benchmark dataset:\\n- hit_precision: The proportion of all positive instances that are found among all positive instances.\\n- hit_recall: The proportion of all positive instances that are found among all instances.\\n- time: Average time taken by the model to provide answers to all the queries.\\n- loss: Average loss on all the queries.\\n\\nThe following are the metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset:\\n- hit_precision: The proportion of all positive instances that are found among all positive instances.\\n- hit_recall: The proportion of all positive instances that are found among all instances.\\n\\nThe following are the metrics that are used to evaluate models on the VTAB-1k benchmark dataset:\\n- hit_precision: The proportion of all positive instances that are found among all positive instances.\\n- hit_recall: The proportion of all positive instances that are found among all instances.\\n- time: Average time taken by the model to provide answers to all the queries.\\n- loss: Average loss on all the queries.', 'The best performing model for the Cart Pole (OpenAI Gym) benchmark dataset is the 2d-Central @ 224 parameterization from the OpenAI GPT model `gpt-2` (version: `pep8-62`.', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nSELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Rfa-Gate-arccos\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\nA:\\n\\nAnswer 1:\\n\\nInan et al. (2016) - Variational LSTM (', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"F1\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SHARe/CLEF eHealth\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","57.28155339805821%  ['SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"BioASQ dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'The best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric is the model orkgp:HaraldNielsen.', 'Natural Language Inference (NLI) datasets can be categorized into two main groups, evaluation datasets that test the NLI model’s ability to detect (true/fake) outputs and training datasets that are used to train NLI models. There are many evaluation datasets that are used by the NLI community to evaluate their models. The best method to find the most appropriate dataset for your model will vary based on your model architecture and whether you want to tune the model on your training data or test it on an evaluation dataset. \\nBelow are some of the most popular NLI evaluation datasets that the NLI research community has been using for the past few years:\\n- MultiNLI (Marsland et al., 2017) \\n- CoNLL-2010 (Pradhan et al., 2010) \\n- RTE (Ruiz et al., 2016) \\n- TACL (Tay et al., 2017)', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Classic dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'List the code links in papers that use the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark?\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite.py\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite.pyc\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite.cpp\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite/dygiet-lite.cpp\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite/dygiet-lite.h\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite/dygiet-lite.cpp\\nhttps://github.com/ipadic/dygieeplusplus/blob/master/dygiet-lite/dygiet-lite.h\\nhttps://']\n","58.25242718446597%  ['overall prevalence of epilepsy is the highest in country of study Brazil', 'MHealth-Main version\\nGHealth-Genetic, MHealth-Main version\\nOHealth-OpenEHR, SHealth-Social, SMHealth-Social, THealth-Taxonomy, GHealth-Genetic', 'ThiS UNCONFIRMED list contains the following models:\\n\\n- SQRT\\n- LOG\\n- CSVD\\n- FILT\\n- TVMF\\n- SQRT+LOG\\n- LOG+CSVD\\n- SQRT+FILT\\n- LOG+TVMF\\n- CSVD+FILT\\n- CSVD+TVMF\\n- FILT+TVMF', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. }', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }']\n","59.22330097087374%  ['http://dygie2.tu-bs.de/index.php/TsetlinMachine.html', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a atari:Atari2600BreakoutDataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Breakout\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'select distinct metric metric_lbl from <... >', 'Here are the list of papers that have utilized the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model:\\n* Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n* Qi et al. (2017) AutoSklearn: Extracting Automobile Semantic Keyword Relations from Search Query Data - https://link.springer.com/book/10.1007%2Fs40347-017-0214-z\\n* Zhang et al. (2017) C4: Convolutional Architecture for Achieving Text Similarity - https://link.springer.com/book/10.1007%2Fs10498-017-1145-1\\n* Wang et al. (2017) AnoDA: Analyzing The Annotation of Data for Intelligent Dentistry - https://link.springer.com/book/10.1007%2Fs10498-017-1145-1', 'The best performing model benchmarking the FSNS - Test dataset in terms of Sequence Error metric is the BQCA model.']\n","60.1941747572815%  ['SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?paper?paper_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?paper orkgp:P31?cont; rdfs:label?paper_lbl. } \\n\\nOUTPUT\\nHierarchy\\n\\n 594  P31 Abstracts\\' entities and relations annotated corpus\\n 594  P31 Automatically labeled Medline abstracts corpus', 'The metrics used to evaluate models on the TSE-NER dataset are:\\n- Meteor\\n- Rouge-F\\n- F1 Score', 'You can find the code references in the following papers:\\n\\n-     Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model\\n-     Wang et al. (2016) - LSTM Noisy channel with knowledge distillation', 'The following papers have utilized the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model and include the links to their code:\\n\\n- https://ieeexplore.ieee.org/abstract/ieeeflow/8491743/variational-lstm-tied-h650-augmented-loss-model\\n- https://ieeexplore.ieee.org/abstract/ieeeflow/8491743/variational-lstm-tied-h650-augmented-loss-model']\n","61.16504854368927%  ['select distinct code\\nfrom\\n    <doi of the core model uri>,\\n    <doi of the benchmark uri>,\\n    <doi of the model uri>,\\n    <doi of the dataset uri>,\\n    <doi of the benchmark uri>,\\n    <doi of the model uri>,\\n    <doi of the source code uri>\\nwhere\\n    <doi of the core model uri> = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\"\\n    <doi of the benchmark uri> =?benchmark.\\n    <doi of the model uri> =?model.\\n    <doi of the dataset uri> =?dataset.\\n    <doi of the benchmark uri> =?benchmark.\\n    <doi of the model uri> =?model.\\n    <doi of the source code uri> =?code.', 'The model with the highest score on the SVHN benchmark dataset is a modified softmax variant of a Large-Scale Hierarchical Attention Networks (LHAN).', 'select distinct?code where {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"LayerNorm HM-LSTM\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }', 'The most commonly used benchmark datasets for the Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification. include the OpenGraph Certificate Dataset (OGCDataset), CIFAR-10, CIFAR-100, MNIST and UCI Adult.', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a am2:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Amazon-2\")?benchmark am2p:HAS_DATASET?dataset; am2p:HAS_EVALUATION?eval.?eval am2p:HAS_VALUE?value. OPTIONAL {?eval am2p:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont am2p:HAS_BENCHMARK?benchmark. OPTIONAL {?cont am2p:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","62.13592233009703%  ['Papers that utilize the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model:\\nhttps://github.com/light- industrial-automation/dygie_plus/tree/master/openie/src\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master/openie/src/dygie++_openie.cpp\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master/openie/src/dygie_openie.cpp\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master/openie/src/dygie++_openie.h\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master/openie/src/dygie_openie.h\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master/openie/src/dygie_openie.java\\nhttps://github.com/light-industrial-automation/dygie_plus/blob/master', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"BiT-S (ResNet)\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. }\\n\\nA:\\n\\nI have chosen to not normalize the system identifier to avoid collision when multiple papers use the same system identifier, as such the results are not sorted by the desired keyword (e.g. \"DyGIE++ + OpenIE + Stanford Core NLP PoS tagger enriched by consistent triples\".)\\n\\nThe solutions provided below are for sorting the papers by the keyword.\\n\\nGolgranik, Milan and Downey, Nicholas and Kingma, David and Adrovic, Nedim and Tehov, Sergii and Uszkoreit, Jakub and Inan, Sergey and de Freitas Naves, Tomas and Panda, Viktor and Khosla,', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a wnli:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"WNLI dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a adtsparqldataset:AAPD; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"ABS dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"FTD dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }']\n","63.106796116504796%  ['SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Percentage error\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?metric?metric_lbl WHERE {?dataset a scingen:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"SciGEN\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. } }', 'SELECT DISTINCT?code WHERE {?model a orkgc:Model; rdfs:label?model_lbl. FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\")?benchmark orkgp:HAS_DATASET?dataset.?cont orkgp:HAS_BENCHMARK?benchmark.?cont orkgp:HAS_MODEL?model; orkgp:HAS_SOURCE_CODE?code. } \\n\\n-- Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model \\n-- https://web.stanford.edu/~abanin/publications/HandlersForLUHS.pdf\\n-- POP3D model from https://web.stanford.edu/~abanin/publications/handlers_for_luhs.pdf\\n--   code: https://web.stanford.edu/~abanin/publications/handlers_for_luhs.cod', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","64.07766990291256%  ['SELECT?metric?metric_lbl WHERE {\\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\\n   ?benchmark orkgp:HAS_DATASET?dataset; \\n    orkgp:HAS_EVALUATION?eval. \\n    OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }\\n}\\n\\nThe answer is: \\nSELECT \"PRfcn\", \"FN\", \"TP\", \"TN\", \"FP\", \"TN\", \"FN\"\\nWHERE {\\n   ?dataset a orkgc:Dataset; \\n    rdfs:label?dataset_lbl. \\n    FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\\n   ?benchmark orkgp:HAS_DATASET?dataset; \\n    orkgp:HAS_EVALUATION?eval. \\n    OPTIONAL {?eval orkgp:HAS_METRIC?', 'SELECT DISTINCT?paper?paper_lbl WHERE { \\n?dataset a orkgc:Dataset; \\nrdfs:label?dataset_lbl. \\nFILTER (str(?dataset_lbl) = \"MPQA dataset\") \\n?benchmark orkgp:HAS_DATASET?dataset. \\n?cont orkgp:HAS_BENCHMARK?benchmark. \\n?paper orkgp:P31?cont; \\nrdfs:label?paper_lbl. \\n}', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a bConfigurationDataset; bConfiguration:datasetName?dataset_name. FILTER (str(?dataset_name) = \"BC5CDR-chemical\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"SUCCESS\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a paperfield:PaperField; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Paper Field\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl']\n","65.04854368932033%  ['SELECT DISTINCT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score metric is', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a atari2600doubleundunk:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Double Dunk\")?benchmark atari2600doubleundunk:HAS_DATASET?dataset; atari2600doubleundunk:HAS_EVALUATION?eval.?eval atari2600doubleundunk:HAS_VALUE?value. OPTIONAL {?eval atari2600doubleundunk:HAS_METRIC?metric.?metric atari2600doubleundunk:LABEL?metric_lbl. }?cont atari2600doubleundunk:HAS_BENCHMARK?benchmark. OPTIONAL {?cont atari2600doubleundunk:HAS_MODEL?model.?model atari2600doubleundunk:LABEL?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'Please find the link of the papers that have used the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark:\\nhttps://dglypp.herokuapp.com/query?query=SELECT%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%', 'SELECT?metric (MAX(?value) AS?score) WHERE {\\n  {\\n    {\\n      SELECT?metric?metric_lbl?value WHERE {\\n       ?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. }\\n        }\\n        ORDER BY DESC(?value)\\n      }\\n    }\\n  }\\n  GROUP BY?metric?metric_lbl\\n}\\n\\nTop result for \"Cheetah, run (DMControl500k)\" with the metric being \"', 'input (English text): Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STS Benchmark dataset?\\noutput (Sparql query):']\n","66.01941747572809%  ['SELECT?metric (MAX(?value) AS?score) \\n    WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a atari2600:Atari2600Alien; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Alien levels\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric', 'SELECT DISTINCT?metric?metric_lbl (MAX(?value) AS?score) WHERE { { SELECT?metric?metric_lbl?value WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Birdsnap dataset\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value. OPTIONAL {?eval orkgp:HAS_METRIC?metric.?metric rdfs:label?metric_lbl. }?cont orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?cont orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } } ORDER BY DESC(?value) } } GROUP BY?metric?metric_lbl', 'SELECT DISTINCT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?paper orkgp:HAS_BENCHMARK?benchmark. OPTIONAL {?paper orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } }', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"Accuracy\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Stanford Cars\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } } \\n\\nThe top performing model on the Penn Treebank benchmark dataset is the model labelled as ‘Rothorgan’:', 'SELECT?model?model_lbl WHERE {?metric a orkgc:Metric; rdfs:label?metric_lbl. FILTER (str(?metric_lbl) = \"RotoWire (Relation Generation)\") { SELECT?model?model_lbl WHERE {?dataset a orkgc:Dataset; rdfs:label?dataset_lbl. FILTER (str(?dataset_lbl) = \"Relation Generation\")?benchmark orkgp:HAS_DATASET?dataset; orkgp:HAS_EVALUATION?eval.?eval orkgp:HAS_VALUE?value; orkgp:HAS_METRIC?metric.?cont orkgp:HAS_BENCHMARK?benchmark; orkgp:HAS_MODEL?model.?model rdfs:label?model_lbl. } ORDER BY DESC(?value) LIMIT 1 } }']\n","66.99029126213586%  "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f5337bf0e5c9>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mlens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdolly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mgst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 )\n\u001b[0;32m-> 1110\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/databricks/dolly-v2-3b/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/instruct_pipeline.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0min_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         generated_sequence = self.model.generate(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1619\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2740\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2741\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         outputs = self.gpt_neox(\n\u001b[0m\u001b[1;32m    767\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    655\u001b[0m                 )\n\u001b[1;32m    656\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 outputs = layer(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     ):\n\u001b[0;32m--> 420\u001b[0;31m         attention_layer_outputs = self.attention(\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, head_mask, layer_past, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_layer_past\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mseq_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rotary_pos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_rot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_rot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, seq_len)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len_cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_cos_sin_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_cached\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin_cached\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import json\n","from transformers import pipeline, AutoTokenizer\n","from datasets import load_dataset\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", padding_side=\"left\")\n","\n","dolly = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n","raw_datasets = load_dataset(\"orkg/SciQA\")\n","print(raw_datasets)\n","\n","\n","def divide_chunks(l_, n_):\n","    for i_ in range(0, len(l_), n_):\n","        yield l_[i_:i_ + n_]\n","\n","\n","def clean(st):\n","    st = st.replace(\"\\n\", \" \")\n","    st = st.replace(\"?\", \" ?\")\n","    st = st.replace(\"{\", \" { \")\n","    st = st.replace(\"}\", \" } \")\n","    st = st.replace(\"\\\\'\", \"'\")\n","\n","    while \"  \" in st:\n","        st = st.replace(\"  \", \" \")\n","    return st\n","\n","\n","def get_key(q):\n","    t0 = q.get('template_id')\n","    if t0 is None:\n","        t0 = \"None\"\n","    t = str(q.get(\"number_of_patterns\")) + \"-\" + t0\n","    return t\n","\n","\n","def get_keys(n_):\n","    train = raw_datasets.get(\"train\")\n","    patterns = {}\n","    for q in train:\n","        t = get_key(q)\n","        query = clean(q[\"query\"][\"sparql\"])\n","        question = q[\"question\"][\"string\"]\n","        if t not in patterns:\n","            patterns[t] = [[query, question, len(query)]]\n","        else:\n","            patterns[t].append([query, question, len(query)])\n","\n","    for t in patterns:\n","        code = patterns.get(t)\n","        code = sorted(code, key=lambda x: x[2], reverse=True)\n","        patterns[t] = code[:n_]\n","    return patterns\n","\n","\n","def prepare_queries(n_):\n","    keys = get_keys(n_)\n","    data = raw_datasets.get(\"test\")\n","    queries = []\n","    for q in data:\n","        t = get_key(q)\n","        question = q[\"question\"][\"string\"]\n","        suggestion = keys.get(t)\n","        if suggestion is None:\n","            print(\"Error with key\", t)\n","            queries.append(\"translate the following English text '\" + question + \"' to a sparql query\")\n","        else:\n","            final_q = \"\"\n","            for i_, k in enumerate(suggestion):\n","                final_q += \"\\n input (English text): \" + k[1]\n","                final_q += \"\\n output (Sparql query): \" + k[0]\n","            final_q += \"\\n input (English text): \" + question\n","            final_q += \"\\n output (Sparql query): \"\n","            queries.append(final_q)\n","    return queries\n","\n","shots = 2\n","query_list = prepare_queries(shots)\n","\n","print(len(query_list))\n","\n","\n","n = 5\n","q_list = list(divide_chunks(query_list, n))\n","sparql = [clean(x[\"query\"][\"sparql\"]) for x in raw_datasets.get(\"test\")]\n","\n","gs = []\n","lens =[]\n","\n","i = 0\n","\n","for group in q_list:\n","    print(str(i) + \"%\", end=\"  \")\n","    i += 1/len(q_list)*100\n","\n","    res_ = [tokenizer.encode(question) for question in group]\n","    len_ = [len(x) for x in res_]\n","    lens += len_\n","\n","    res = dolly(group)\n","    gst = [x[0][\"generated_text\"] for x in res]\n","    print(gst)\n","    gs += gst\n","\n","print([x for x in lens if x>2048])\n","\n","result = {\"questions\": query_list, \"sparql\": sparql, \"generated_sparql\": gs, \"prompt_len\": lens}\n","\n","with open(\"dolly_\"+str(shots)+\"_shot_results_tok.json\", \"w\", encoding=\"utf-8\") as text_file:\n","    print(json.dumps(result), file=text_file)\n"]}]}
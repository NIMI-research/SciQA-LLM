{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24680,"status":"ok","timestamp":1692294381604,"user":{"displayName":"Antonello","userId":"01962207529893687178"},"user_tz":-120},"id":"YcU-KRrrF9JR","outputId":"ccb7d6b5-2e38-4c6b-f98e-ff707daef764"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/en2sparql"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9304,"status":"ok","timestamp":1692294397158,"user":{"displayName":"Antonello","userId":"01962207529893687178"},"user_tz":-120},"id":"Gk0ZzrPa4LFQ","outputId":"ea897481-8e74-4c8c-b89f-8a1ea9b7e499"},"outputs":[],"source":["!pip install rouge\n","import nltk\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1692294405676,"user":{"displayName":"Antonello","userId":"01962207529893687178"},"user_tz":-120},"id":"28tFQ5BV37yH"},"outputs":[],"source":["import re\n","from collections import Counter\n","from typing import List\n","\n","from nltk.translate.meteor_score import single_meteor_score\n","from nltk.translate.bleu_score import sentence_bleu\n","from rouge import Rouge\n","import csv\n","import json\n","\n","def rogue_score(rog_score):\n","    rouge_1_sum = 0\n","    rouge_2_sum = 0\n","    rouge_l_sum = 0\n","    num_scores = len(rog_score)\n","    for score in rog_score:\n","        rouge_1_sum += score['rouge-1']['f']\n","        rouge_2_sum += score['rouge-2']['f']\n","        rouge_l_sum += score['rouge-l']['f']\n","    rouge_1_avg = rouge_1_sum / num_scores\n","    rouge_2_avg = rouge_2_sum / num_scores\n","    rouge_l_avg = rouge_l_sum / num_scores\n","    return rouge_1_avg,rouge_2_avg, rouge_l_avg\n","\n","def mask(txt: str) -> str:\n","    \"\"\"\n","    Replace any sequence starting with \"?\" followed by any word character with \"?MASKED\"\n","\n","    Args:\n","        txt (str): input text\n","\n","    Returns:\n","        str: the masked text\n","    \"\"\"\n","    masked = re.sub(r'\\?\\w+', '?MASKED', txt)\n","    return masked\n","\n","def metric_em(path_to_predictions: str, language: str) -> int:\n","    \"\"\"\n","    Calculate the exact match (EM) metric for the model.\n","\n","    Args:\n","        path_to_predictions (str): the path to the CSV file containing the predictions\n","        language (str): the language of the predictions\n","\n","    Returns:\n","        int: the number of hits (correct predictions)\n","    \"\"\"\n","    hits: List[str] = []\n","    indices: List[int] = []\n","    with open(path_to_predictions, 'r') as file:\n","        csvreader = csv.reader(file)\n","        header = next(csvreader)\n","        gt, mt = [], []\n","        for row in csvreader:\n","            gt.append(row[1].strip())\n","            mt.append(row[2].strip())\n","\n","    counter = 0\n","    for i, (gt_row, mt_row) in enumerate(zip(gt, mt)):\n","        if language == \"sparql\":\n","            gt_row = mask(gt_row)\n","            mt_row = mask(mt_row)\n","        gt_res = \" \".join(gt_row.split()).strip()\n","        mt_res = \" \".join(mt_row.split()).strip()\n","        if gt_res == mt_res:\n","            hits.append(gt_res)\n","            indices.append(i)\n","            counter += 1\n","\n","    return len(hits)\n","\n","def format_text(txt):\n","    \"\"\"\n","    This function formats the input text by:\n","    1. Converting the text to lowercase\n","    2. Removing punctuations\n","    3. Removing articles (a, an, the)\n","    4. Fixing white spaces\n","    \"\"\"\n","    RE_ART = re.compile(r'\\b(a|an|the)\\b')\n","    RE_PUNC = re.compile(r'[!\"#$%&()*+,-./:;<=>?@\\[\\]\\\\^`{|}~_\\']')\n","    lower = txt.lower()\n","    remove_punc = RE_PUNC.sub(' ', lower)\n","    remove_articles = RE_ART.sub(' ', remove_punc)\n","    fix_white_space = ' '.join(remove_articles.split())\n","    return fix_white_space\n","\n","def evaluate(predicted_output, actual_output, metrics=['precision', 'recall', 'bleu', 'rogue']):\n","    \"\"\"\n","    This function evaluates the given predicted_output against the actual_output using multiple metrics.\n","    Returns the following metrics: precision, recall, F1 score, BLEU (cumulative), METEOR, Rouge, BLEU-4.\n","    \"\"\"\n","    rouge = Rouge()\n","    common = Counter(predicted_output.split()) & Counter(actual_output.split())\n","    num_same = sum(common.values())\n","    precision_score = 1.0 * num_same / len(predicted_output.split())\n","    recall_score = 1.0 * num_same / len(actual_output.split())\n","\n","    if precision_score == 0 or recall_score == 0:\n","        f1_score = 0\n","    else:\n","        f1_score = (2 * precision_score * recall_score) / (precision_score + recall_score)\n","\n","    meteor = single_meteor_score([actual_output], [predicted_output])\n","    ro = rouge.get_scores(actual_output, predicted_output, avg=True)\n","    bleu_c = sentence_bleu([actual_output.split()], predicted_output.split(), weights=(0.25, 0.25, 0.25, 0.25))\n","    bleu_4 = sentence_bleu([actual_output.split()], predicted_output.split(), weights=(0, 0, 0, 1))\n","\n","    return precision_score, recall_score, f1_score, bleu_c, meteor, ro, bleu_4\n","\n","def run_eval(predictions, quer):\n","    predictions = [format_text(i) for i in predictions]\n","    quer = [format_text(i) for i in quer]\n","\n","    precision, recall, f1_score, bleu_score_c, meteor_score, rog_score, bleu_score_4 = [], [], [], [], [], [], []\n","\n","    for i, j in zip(predictions, quer):\n","        prec, rec, f1, bleuc, met, rog, bleu4 = evaluate(i, j)\n","        precision.append(prec)\n","        recall.append(rec)\n","        f1_score.append(f1)\n","        bleu_score_c.append(bleuc)\n","        meteor_score.append(met)\n","        rog_score.append(rog)\n","        bleu_score_4.append(bleu4)\n","\n","    print(f'Precision: {sum(precision)/len(precision)}, Recall : {sum(recall)/len(recall)}, F1 Score: {sum(f1_score)/len(f1_score)}, Blue 4: {sum(bleu_score_4)/len(bleu_score_4)}, Bleu Score Cumulative: {sum(bleu_score_c)/len(bleu_score_c)}, Meteor Score: {sum(meteor_score)/len(meteor_score)}')\n","\n","    rouge_1_avg, rouge_2_avg, rouge_l_avg = rogue_score(rog_score)\n","    print(f'Rouge-1: {rouge_1_avg}, Rouge-2: {rouge_2_avg}, Rouge-L: {rouge_l_avg}')\n","    return {\"Precision\": sum(precision)/len(precision),\n","            \"Recall\": sum(recall)/len(recall),\n","            \"F1_Score\": sum(f1_score)/len(f1_score),\n","            \"Blue_4\": sum(bleu_score_4)/len(bleu_score_4),\n","            \"Bleu_Score_Cumulative\": sum(bleu_score_c) / len(bleu_score_c),\n","            \"Meteor_Score\": sum(meteor_score) / len(meteor_score),\n","            \"Rouge_1\": rouge_1_avg,\n","            \"Rouge_2\": rouge_2_avg,\n","            \"Rouge_L\": rouge_l_avg\n","            }\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11961,"status":"ok","timestamp":1692297732261,"user":{"displayName":"Antonello","userId":"01962207529893687178"},"user_tz":-120},"id":"3XkE7sB5rvlJ","outputId":"0d41ecfb-3d1b-460f-ea70-0ff68462df9d"},"outputs":[],"source":["import csv\n","import json\n","import os.path\n","\n","\n","def load_json(file__name):\n","    data_file = open(file__name, \"r\", encoding='utf-8')\n","    file_data = json.loads(data_file.read())\n","    data_file.close()\n","    return file_data\n","\n","\n","def write_json(file__name, content):\n","    with open(file__name, \"w\", encoding=\"utf-8\") as text_file:\n","        print(json.dumps(content), file=text_file)\n","\n","\n","def run_tests(shots=1,threshold=0.95):\n","  results = {}\n","  prefix = \"json/\"\n","  filename = prefix + \"nlp_dolly_\" + str(shots) + \"_shot_results_cleaned.json\"\n","  if not os.path.isfile(filename):\n","    return {}\n","  data = load_json(filename)\n","  # print(len(data[\"suggestions\"]))\n","  results[\"shots\"] = shots\n","  results[\"Generated\"] = len(data[\"suggestions\"])\n","  results[\"threshold\"] = threshold\n","  sim_mean = 0\n","  generated =[]\n","  sparql = []\n","  for i, sample in enumerate(data[\"suggestions\"]):\n","    elem_sim = 0\n","    r_list = sample[0]\n","    r = sample[1]\n","    for r_elem in r_list:\n","      if r_elem[1] == r:\n","        sim_mean += 1 / len(r_list)\n","        elem_sim += 1 / len(r_list)\n","        # print(r_elem[1], r)\n","    if elem_sim >= threshold:\n","      generated.append(data[\"cleaned_sparql\"][i])\n","      sparql.append(data[\"sparql\"][i])\n","  results[\"samples_above_theshold\"] = len(generated)\n","  results[\"sim_mean_n\"] = sim_mean\n","  results[\"sim_mean_%\"] =  sim_mean/len(data[\"suggestions\"])*100\n","\n","  metrics = run_eval(generated,sparql)\n","  for key in metrics:\n","    results[key] = metrics.get(key)\n","  return results\n","\n","def write_csv(filename_,content):\n","    with open(filename_, 'w', newline='', encoding=\"utf-8\") as file:\n","        writer = csv.writer(file, delimiter='\\t')\n","        writer.writerows(content)\n","\n","\n","def main():\n","  res = []\n","  for i in range(8):\n","    if i == 0:\n","      continue\n","    res.append(run_tests(shots=i))\n","  print(json.dumps(res))\n","  table = {}\n","  for row in res:\n","    for key in row:\n","      if key in table:\n","        table[key].append(row.get(key))\n","      else:\n","        table[key]=[row.get(key)]\n","  print(table)\n","  rows = []\n","  for key in table:\n","    rows.append([key] + table.get(key))\n","  write_csv(\"nl_similarity_results.csv\",rows)\n","\n","\n","main()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO3xupkoXiV8cduIl7Hr5tu","provenance":[]},"kernelspec":{"display_name":"Python 3.9.9 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.9"},"vscode":{"interpreter":{"hash":"11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"}}},"nbformat":4,"nbformat_minor":0}
